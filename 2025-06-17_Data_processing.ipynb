{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c9612c",
   "metadata": {},
   "source": [
    "#### QGIS -> demand \n",
    "노선별로 경로 생성\n",
    "distance 데이터 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab9b4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 노선별 단일 경로 (방향 무시)\n",
      "KTX강릉선: [22, 23, 34, 51]\n",
      "경부고속철도: [4, 3, 1, 2, 13, 18, 28, 42, 60, 72, 75, 79]\n",
      "경부선: [79, 77, 76, 73, 70, 63, 60, 59, 46, 41, 28, 17, 14, 9, 7, 1, 4]\n",
      "경북선: [41, 38, 36, 40, 43]\n",
      "경전선: [48, 57, 64, 65, 62, 66, 71, 73]\n",
      "동해선: [55, 58, 69, 74, 72]\n",
      "영동선: [51, 55, 54, 50, 43]\n",
      "장항선: [14, 11, 10, 15, 16, 27, 30]\n",
      "전라선: [68, 62, 56, 47, 45, 33, 30]\n",
      "중앙선: [3, 5, 6, 8, 12, 22, 29, 31, 35, 39, 43, 49, 52, 67, 72, 78, 79]\n",
      "충북선: [17, 18, 19, 20, 26, 29]\n",
      "호남고속철도: [48, 37, 30, 21, 18, 13, 2, 1, 3]\n",
      "호남선: [61, 53, 48, 44, 37, 32, 30, 24, 25, 28]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "# ──────────────────────────────\n",
    "# 1. 파일 경로\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "xlsx_path = base_path + r\"\\qgis_export.xlsx\"\n",
    "sheet_name = \"LINE\"\n",
    "# ──────────────────────────────\n",
    "\n",
    "df = pd.read_excel(xlsx_path, sheet_name=sheet_name)\n",
    "df = df.dropna(subset=[\"from_node_\", \"to_node_id\"])\n",
    "df[\"from_node_\"] = df[\"from_node_\"].astype(int)\n",
    "df[\"to_node_id\"] = df[\"to_node_id\"].astype(int)\n",
    "\n",
    "print(\"📌 노선별 단일 경로 (방향 무시)\")\n",
    "for line, group in df.groupby(\"RLWAY_NM\"):\n",
    "    # 양방향 그래프 생성\n",
    "    graph = defaultdict(list)\n",
    "    for u, v in zip(group[\"from_node_\"], group[\"to_node_id\"]):\n",
    "        graph[u].append(v)\n",
    "        graph[v].append(u)\n",
    "\n",
    "    # 노드 연결 상태 진단\n",
    "    degree = {n: len(adj) for n, adj in graph.items()}\n",
    "    endpoints = [n for n, d in degree.items() if d == 1]\n",
    "    if len(endpoints) != 2:\n",
    "        print(f\"⚠️ {line}: 선형 경로 아님 (끝 노드 {len(endpoints)}개)\")\n",
    "        continue\n",
    "\n",
    "    # 한쪽 끝에서부터 BFS로 경로 복원\n",
    "    start = endpoints[0]\n",
    "    visited = set()\n",
    "    path = []\n",
    "\n",
    "    def dfs(u):\n",
    "        visited.add(u)\n",
    "        path.append(u)\n",
    "        for v in graph[u]:\n",
    "            if v not in visited:\n",
    "                dfs(v)\n",
    "\n",
    "    dfs(start)\n",
    "    print(f\"{line}: {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef1b54",
   "metadata": {},
   "source": [
    "#### EDGE timestep 데이터 만들기 위해\n",
    "- distance로 이동시간\n",
    "- 이동시간 기반 time step 계산\n",
    "- EDGE 데이터 .json 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f068c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 완료: time_step 열이 추가된 파일이 저장됨 →\n",
      "D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_time.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ────────────── 설정 ──────────────\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "input_file  = base_path + r\"\\qgis_export.xlsx\"\n",
    "output_file = base_path + r\"\\qgis_export_with_time.xlsx\"\n",
    "sheet_name  = \"EDGE\"\n",
    "# ────────────────────────────────\n",
    "\n",
    "# 1. 원본 엑셀 전체 읽기 (모든 시트 보존 목적)\n",
    "xlsx_all = pd.read_excel(input_file, sheet_name=None)\n",
    "\n",
    "# 2. EDGE 시트만 수정\n",
    "df_edge = xlsx_all[sheet_name]\n",
    "\n",
    "# 3. time_step 계산\n",
    "if 'distance' not in df_edge.columns:\n",
    "    raise ValueError(\"'distance' 열이 EDGE 시트에 없습니다.\")\n",
    "df_edge['time_step'] = df_edge['distance'] / 150 * 60\n",
    "\n",
    "# 4. 수정한 EDGE 시트 다시 넣기\n",
    "xlsx_all[sheet_name] = df_edge\n",
    "\n",
    "# 5. 전체 시트를 새 파일로 저장\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    for sheet, df in xlsx_all.items():\n",
    "        df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "\n",
    "print(f\"✅ 완료: time_step 열이 추가된 파일이 저장됨 →\\n{output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb45211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 완료: 'time_step' 계산 후 저장됨 →\n",
      "D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_step.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# ────────────── 설정 ──────────────\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "input_file  = base_path + r\"\\qgis_export_with_time.xlsx\"\n",
    "output_file = base_path + r\"\\qgis_export_with_step.xlsx\"\n",
    "sheet_name  = \"EDGE\"\n",
    "# ────────────────────────────────\n",
    "\n",
    "# 1. 모든 시트 읽기\n",
    "xlsx_all = pd.read_excel(input_file, sheet_name=None)\n",
    "\n",
    "# 2. EDGE 시트 수정\n",
    "df_edge = xlsx_all[sheet_name]\n",
    "\n",
    "# 3. time_step 계산 (5로 나누고 올림)\n",
    "if 'time(min)' not in df_edge.columns:\n",
    "    raise ValueError(\"'time(min)' 열이 EDGE 시트에 없습니다.\")\n",
    "\n",
    "df_edge['time_step'] = df_edge['time(min)'].apply(lambda x: math.ceil(x / 5))\n",
    "\n",
    "# 4. 덮어쓰기\n",
    "xlsx_all[sheet_name] = df_edge\n",
    "\n",
    "# 5. 새 파일로 저장\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    for sheet, df in xlsx_all.items():\n",
    "        df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "\n",
    "print(f\"✅ 완료: 'time_step' 계산 후 저장됨 →\\n{output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072ab939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 정렬된 edges.json 저장 완료 →\n",
      "D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\edges.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "# ─────────────── 설정 ───────────────\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "input_file  = os.path.join(base_path, \"qgis_export_with_step.xlsx\")\n",
    "sheet_name  = \"EDGE\"\n",
    "output_json = os.path.join(base_path, \"edges.json\")\n",
    "# ───────────────────────────────────\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "df = pd.read_excel(input_file, sheet_name=sheet_name)\n",
    "\n",
    "# 2. 필요한 열 확인\n",
    "required_cols = ['edge_id', 'from_node_id', 'to_node_id', 'time_step']\n",
    "missing = set(required_cols) - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"다음 열이 누락되었습니다: {missing}\")\n",
    "\n",
    "# 3. 정수형 edge_id 기준으로 정렬\n",
    "df = df.dropna(subset=['edge_id'])\n",
    "df['edge_id'] = df['edge_id'].astype(int)\n",
    "df = df.sort_values(by='edge_id')\n",
    "\n",
    "# 4. edge 딕셔너리 생성 (OrderedDict로 순서 유지)\n",
    "edges = OrderedDict()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    eid = f\"e{int(row['edge_id'])}\"\n",
    "    n_from = f\"n{int(row['from_node_id'])}\"\n",
    "    n_to   = f\"n{int(row['to_node_id'])}\"\n",
    "    tstep  = int(row['time_step'])\n",
    "\n",
    "    edges[eid] = (n_from, n_to, tstep)\n",
    "\n",
    "# 5. JSON 저장\n",
    "with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(edges, f, indent=4)\n",
    "\n",
    "print(f\"✅ 정렬된 edges.json 저장 완료 →\\n{output_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0837e648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\routes_nodes.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# ─────────────── 설정 ───────────────\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "xlsx_file = os.path.join(base_path, \"qgis_export_with_step.xlsx\")\n",
    "sheet_name = \"TRAIN\"\n",
    "output_json = os.path.join(base_path, \"routes_nodes.json\")\n",
    "# ───────────────────────────────────\n",
    "\n",
    "# 1. TRAIN 시트 읽기\n",
    "df = pd.read_excel(xlsx_file, sheet_name=sheet_name)\n",
    "\n",
    "# 2. routes_nodes 딕셔너리 생성\n",
    "routes_nodes = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    name = str(row[\"RLWAY_NM\"]).strip()\n",
    "    nodes_str = str(row[\"NODE\"]).strip()\n",
    "\n",
    "    # 노드 문자열 파싱 → ['n4', 'n3', 'n1', ...]\n",
    "    node_list = [f\"n{int(n)}\" for n in nodes_str.split(\"-\") if n.isdigit()]\n",
    "\n",
    "    # 정방향 및 역방향 저장\n",
    "    routes_nodes[f\"{name}1\"] = node_list\n",
    "    routes_nodes[f\"{name}2\"] = node_list[::-1]\n",
    "\n",
    "# 3. JSON 저장\n",
    "with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(routes_nodes, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ 저장 완료: {output_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ea2954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 양방향 edges 저장 완료: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\edges_bidirectional.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "# ─────────────── 설정 ───────────────\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "input_json = os.path.join(base_path, \"edges.json\")\n",
    "output_json = os.path.join(base_path, \"edges_bidirectional.json\")\n",
    "# ───────────────────────────────────\n",
    "\n",
    "# 1. 기존 edges.json 불러오기\n",
    "with open(input_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    edges = json.load(f)\n",
    "\n",
    "# 2. 양방향 딕셔너리 생성 (순서 보존)\n",
    "edges_bidir = OrderedDict()\n",
    "\n",
    "for eid, (n1, n2, t) in edges.items():\n",
    "    # 정방향 edge 추가\n",
    "    edges_bidir[eid] = [n1, n2, t]\n",
    "    \n",
    "    # 역방향 edge 추가\n",
    "    eid_r = f\"{eid}r\"\n",
    "    edges_bidir[eid_r] = [n2, n1, t]\n",
    "\n",
    "# 3. 새 JSON 파일로 저장\n",
    "with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(edges_bidir, f, indent=4)\n",
    "\n",
    "print(f\"✅ 양방향 edges 저장 완료: {output_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9416e8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ demand_template.json 저장 완료 →\n",
      "D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\demand_template.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# ─────────────── 설정 ───────────────\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "routes_json = os.path.join(base_path, \"routes_nodes.json\")\n",
    "output_demand_json = os.path.join(base_path, \"demand_template.json\")\n",
    "# ───────────────────────────────────\n",
    "\n",
    "# 1. routes_nodes.json 불러오기\n",
    "with open(routes_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    routes_nodes = json.load(f)\n",
    "\n",
    "# 2. demand 생성\n",
    "demand = {}\n",
    "\n",
    "for tr, path in routes_nodes.items():\n",
    "    od_list = []\n",
    "    for i in range(len(path)-1):\n",
    "        for j in range(i+1, len(path)):\n",
    "            o, d = path[i], path[j]\n",
    "            od_list.append((o, d, None))  # 수요는 아직 없음\n",
    "    demand[tr] = od_list\n",
    "\n",
    "# 3. 저장\n",
    "with open(output_demand_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(demand, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ demand_template.json 저장 완료 →\\n{output_demand_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42781bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 성공적으로 저장됨 → D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\demand_template_compact.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# ─────────────── 설정 ───────────────\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "input_file  = os.path.join(base_path, \"demand_template.json\")\n",
    "output_file = os.path.join(base_path, \"demand_template_compact.json\")\n",
    "# ───────────────────────────────────\n",
    "\n",
    "# 1. 불러오기\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    demand = json.load(f)\n",
    "\n",
    "# 2. 저장 (수동 문자열 포맷)\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"{\\n\")\n",
    "    for i, (k, od_list) in enumerate(demand.items()):\n",
    "        f.write(f'    \"{k}\": [\\n')\n",
    "        line = \"        \"  # 들여쓰기 시작\n",
    "        for j, od in enumerate(od_list):\n",
    "            # JSON 값으로 인코딩 (ensure null/quote 등 맞춤)\n",
    "            od_json = json.dumps(od, ensure_ascii=False)\n",
    "            line += od_json\n",
    "            if j < len(od_list) - 1:\n",
    "                line += \", \"\n",
    "            if len(line) > 120:\n",
    "                f.write(line + \"\\n\")\n",
    "                line = \"        \"\n",
    "        if line.strip():\n",
    "            f.write(line + \"\\n\")\n",
    "        f.write(\"    ]\")\n",
    "        if i < len(demand) - 1:\n",
    "            f.write(\",\\n\")\n",
    "        else:\n",
    "            f.write(\"\\n\")\n",
    "    f.write(\"}\\n\")\n",
    "\n",
    "print(f\"✅ 성공적으로 저장됨 → {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2836b",
   "metadata": {},
   "source": [
    "#### 역사별 승하차데이터로 임시 journeys demand data 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6238ff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 둘 다 포함된 역 (matched):\n",
      " - 경산역\n",
      " - 계룡역\n",
      " - 곡성역\n",
      " - 공주역\n",
      " - 광명역\n",
      " - 광주송정역\n",
      " - 광천역\n",
      " - 구례구역\n",
      " - 구미역\n",
      " - 구포역\n",
      " - 기장역\n",
      " - 김제역\n",
      " - 김천구미역\n",
      " - 김천역\n",
      " - 나주역\n",
      " - 남원역\n",
      " - 논산역\n",
      " - 능주역\n",
      " - 단양역\n",
      " - 대구역\n",
      " - 대전역\n",
      " - 대천역\n",
      " - 덕소역\n",
      " - 동대구역\n",
      " - 동해역\n",
      " - 마산역\n",
      " - 목포역\n",
      " - 물금역\n",
      " - 밀양역\n",
      " - 벌교역\n",
      " - 보성역\n",
      " - 봉양역\n",
      " - 부산역\n",
      " - 삼랑진역\n",
      " - 상봉역\n",
      " - 상주역\n",
      " - 서울역\n",
      " - 서창역\n",
      " - 수원역\n",
      " - 순천역\n",
      " - 안동역\n",
      " - 양평역\n",
      " - 여수엑스포역\n",
      " - 영덕역\n",
      " - 영등포역\n",
      " - 영주역\n",
      " - 영천역\n",
      " - 예산역\n",
      " - 예천역\n",
      " - 오송역\n",
      " - 온양온천역\n",
      " - 용산역\n",
      " - 울산역\n",
      " - 원주역\n",
      " - 의성역\n",
      " - 익산역\n",
      " - 장성역\n",
      " - 장항역\n",
      " - 전주역\n",
      " - 점촌역\n",
      " - 정동진역\n",
      " - 정읍역\n",
      " - 제천역\n",
      " - 진주역\n",
      " - 천안역\n",
      " - 청량리역\n",
      " - 청주역\n",
      " - 춘양역\n",
      " - 충주역\n",
      " - 태화강역\n",
      " - 평창역\n",
      " - 평택역\n",
      " - 포항역\n",
      " - 풍기역\n",
      " - 횡성역\n",
      "\n",
      "📌 QGIS에는 있으나 승하차 데이터에는 없는 역 (only_in_qgis):\n",
      " - 백산역\n",
      " - 보천역\n",
      " - 삼척역\n",
      " - 신경주역\n",
      " - 천안아산역(온양온천)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ─────────────── 경로 설정 ───────────────\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "qgis_path = base_dir / \"qgis_export_with_step.xlsx\"\n",
    "ridership_path = base_dir / \"station_ridership.xlsx\"\n",
    "# ────────────────────────────────────────\n",
    "\n",
    "# 1. QGIS NODE 데이터에서 RLNODE_NM 추출\n",
    "qgis_df = pd.read_excel(qgis_path, sheet_name=\"NODE\")\n",
    "qgis_nodes = qgis_df[\"RLNODE_NM\"].astype(str).str.strip()\n",
    "\n",
    "# 2. 승하차 데이터에서 RLNODE_NM 추출 (E열)\n",
    "ridership_df = pd.read_excel(ridership_path)\n",
    "ridership_nodes = ridership_df[\"RLNODE_NM\"].astype(str).str.strip()\n",
    "\n",
    "# 3. 비교\n",
    "matched = sorted(set(qgis_nodes) & set(ridership_nodes))\n",
    "only_in_qgis = sorted(set(qgis_nodes) - set(ridership_nodes))\n",
    "\n",
    "# 4. 출력\n",
    "print(\"📌 둘 다 포함된 역 (matched):\")\n",
    "for name in matched:\n",
    "    print(f\" - {name}\")\n",
    "\n",
    "print(\"\\n📌 QGIS에는 있으나 승하차 데이터에는 없는 역 (only_in_qgis):\")\n",
    "for name in only_in_qgis:\n",
    "    print(f\" - {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4518b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ 저장 완료: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_ridership.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ─────────────── 경로 설정 ───────────────\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "xlsx_path = base_dir / \"qgis_export_with_step.xlsx\"\n",
    "output_path = base_dir / \"qgis_export_with_ridership.xlsx\"\n",
    "# ────────────────────────────────────────\n",
    "\n",
    "# 1. NODE 시트 불러오기\n",
    "node_df = pd.read_excel(xlsx_path, sheet_name=\"NODE\")\n",
    "\n",
    "# 2. BOARD,ALIGHT 시트 불러오기\n",
    "ridership_df = pd.read_excel(xlsx_path, sheet_name=\"BOARD,ALIGHT\")\n",
    "\n",
    "# 3. RLNODE_NM 기준 병합\n",
    "merged_df = node_df.merge(\n",
    "    ridership_df[[\"RLNODE_NM\", \"board_1d\", \"alight_1d\"]],\n",
    "    on=\"RLNODE_NM\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 4. 새로운 파일로 저장\n",
    "merged_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"✔️ 저장 완료: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13186668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ 저장 완료: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_timestep.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ───────────── 경로 설정 ─────────────\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "xlsx_path = base_dir / \"qgis_export.xlsx\"\n",
    "output_path = base_dir / \"qgis_export_with_timestep.xlsx\"\n",
    "# ─────────────────────────────────────\n",
    "\n",
    "# 1. 엣지 정보 읽기\n",
    "edge_df = pd.read_excel(xlsx_path, sheet_name=\"EDGE\")\n",
    "edge_df[\"from_node_id\"] = edge_df[\"from_node_id\"].astype(str).str.lower()\n",
    "edge_df[\"to_node_id\"] = edge_df[\"to_node_id\"].astype(str).str.lower()\n",
    "\n",
    "# 2. demand 탭 읽기\n",
    "demand_df = pd.read_excel(xlsx_path, sheet_name=\"DEMAND\")\n",
    "\n",
    "# 3. Route 기반 Timestep 계산 함수\n",
    "def compute_total_timestep(route_str):\n",
    "    if pd.isna(route_str):\n",
    "        return None\n",
    "    nodes = route_str.strip().split(\"-\")\n",
    "    total_time = 0\n",
    "    for i in range(len(nodes) - 1):\n",
    "        from_n = nodes[i].replace(\"n\", \"\")\n",
    "        to_n = nodes[i+1].replace(\"n\", \"\")\n",
    "\n",
    "        # 해당 from↔to에 해당하는 time_step 찾기\n",
    "        match = edge_df[\n",
    "            ((edge_df[\"from_node_id\"] == from_n) & (edge_df[\"to_node_id\"] == to_n)) |\n",
    "            ((edge_df[\"from_node_id\"] == to_n) & (edge_df[\"to_node_id\"] == from_n))\n",
    "        ]\n",
    "\n",
    "        if match.empty:\n",
    "            return None  # 해당 구간 정보 없음\n",
    "        total_time += match.iloc[0][\"time_step\"]\n",
    "    return total_time\n",
    "\n",
    "# 4. Timestep 계산 및 열 추가\n",
    "demand_df[\"Timestep\"] = demand_df[\"Route\"].apply(compute_total_timestep)\n",
    "\n",
    "# 5. 저장\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "    demand_df.to_excel(writer, sheet_name=\"DEMAND\", index=False)\n",
    "\n",
    "print(f\"✔️ 저장 완료: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3eb01c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\demand_with_route_filled.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 파일 경로\n",
    "base_path = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "file_path = base_path / \"qgis_export.xlsx\"\n",
    "\n",
    "# 엑셀 파일 읽기\n",
    "train_df = pd.read_excel(file_path, sheet_name=\"TRAIN\")\n",
    "demand_df = pd.read_excel(file_path, sheet_name=\"DEMAND\")\n",
    "\n",
    "# 노선 이름 → 노드 경로 dict (n 접두어 붙이기)\n",
    "line_routes = {}\n",
    "for _, row in train_df.iterrows():\n",
    "    line_name = row[\"RLWAY_NM\"].strip()\n",
    "    node_seq = [f\"n{n.strip()}\" for n in str(row[\"NODE\"]).split(\"-\")]\n",
    "    line_routes[line_name] = node_seq\n",
    "\n",
    "# 노선 이름에서 숫자 제거해서 base name으로 매핑\n",
    "def get_base_line(line):\n",
    "    return ''.join(filter(lambda x: not x.isdigit(), line)).strip()\n",
    "\n",
    "# OD에 대해 Route 생성 함수\n",
    "def extract_route(line, origin, destination):\n",
    "    base_line = get_base_line(line)\n",
    "    nodes = line_routes.get(base_line)\n",
    "    if not nodes:\n",
    "        return None\n",
    "    if origin not in nodes or destination not in nodes:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        idx_o = nodes.index(origin)\n",
    "        idx_d = nodes.index(destination)\n",
    "        # 정방향 또는 역방향 슬라이싱\n",
    "        if idx_o <= idx_d:\n",
    "            path = nodes[idx_o:idx_d + 1]\n",
    "        else:\n",
    "            path = nodes[idx_o:idx_d - 1:-1]  # 역방향\n",
    "        return \"-\".join(path)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Route 열 추가\n",
    "demand_df[\"Route\"] = demand_df.apply(\n",
    "    lambda row: extract_route(row[\"Line\"], row[\"Origin\"], row[\"Destination\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 저장\n",
    "output_path = base_path / \"demand_with_route_filled.xlsx\"\n",
    "demand_df.to_excel(output_path, index=False)\n",
    "print(f\"✅ 저장 완료: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fe683ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ 저장 완료: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_node_id.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ───────────── 경로 설정 ─────────────\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "xlsx_path = base_dir / \"qgis_export.xlsx\"\n",
    "output_path = base_dir / \"qgis_export_with_node_id.xlsx\"\n",
    "# ─────────────────────────────────────\n",
    "\n",
    "# 1. NODE 시트 읽기 (참조용)\n",
    "node_df = pd.read_excel(xlsx_path, sheet_name=\"NODE\")\n",
    "node_df = node_df[[\"RLNODE_NM\", \"node_id\"]].dropna()\n",
    "node_df[\"RLNODE_NM\"] = node_df[\"RLNODE_NM\"].astype(str).str.strip()\n",
    "\n",
    "# 2. BOARD_ALIGHT 시트에 node_id 매칭\n",
    "df = pd.read_excel(xlsx_path, sheet_name=\"BOARD_ALIGHT\")\n",
    "df[\"RLNODE_NM\"] = df[\"RLNODE_NM\"].astype(str).str.strip()\n",
    "\n",
    "# 매칭 수행\n",
    "merged_df = df.merge(node_df, on=\"RLNODE_NM\", how=\"left\")\n",
    "\n",
    "# 3. 저장\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    merged_df.to_excel(writer, sheet_name=\"BOARD_ALIGHT\", index=False)\n",
    "\n",
    "print(f\"✔️ 저장 완료: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623d34b2",
   "metadata": {},
   "source": [
    "#### Journeys data 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23df60ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ journeys 열이 채워진 파일: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_journeys.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ────── CONFIG ────────────────────────────────────────────────────────────\n",
    "file_path   = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export.xlsx\")\n",
    "output_path = file_path.with_stem(file_path.stem + \"_with_journeys\")\n",
    "\n",
    "min_board   = 1      # 승차가 0/누락인 역에 부여할 최소 승차 인원\n",
    "min_alight  = 1      # 하차가 0/누락인 역에 부여할 최소 하차 인원\n",
    "epsilon_od  = 1      # 유효 OD(승·하차>0)에 심을 최소 통행량\n",
    "max_iter    = 50\n",
    "eps_conv    = 1e-6\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# 1. 데이터 읽기 -----------------------------------------------------------\n",
    "bal    = pd.read_excel(\n",
    "            file_path, sheet_name=\"BOARD_ALIGHT\",\n",
    "            usecols=[\"node_id\", \"board_1d\", \"alight_1d\"]\n",
    "        )\n",
    "demand = pd.read_excel(file_path, sheet_name=\"DEMAND\")\n",
    "\n",
    "# 1‑a. Origin / Destination ⇒ 정수 node_id\n",
    "demand[\"O_id\"] = demand[\"Origin\"].str.lstrip(\"n\").astype(int)\n",
    "demand[\"D_id\"] = demand[\"Destination\"].str.lstrip(\"n\").astype(int)\n",
    "\n",
    "# 2. BOARD_ALIGHT 누락/중복 처리 ------------------------------------------\n",
    "#   2‑a. 중복 node_id 합산\n",
    "bal_agg = (bal.groupby(\"node_id\", as_index=False)\n",
    "               .agg(board=(\"board_1d\", \"sum\"),\n",
    "                    alight=(\"alight_1d\", \"sum\")))\n",
    "\n",
    "#   2‑b. DEMAND 에 등장하지만 bal 에 없는 노드 추가\n",
    "all_nodes = pd.unique(demand[[\"O_id\", \"D_id\"]].values.ravel())\n",
    "bal_full  = pd.DataFrame({\"node_id\": all_nodes}).merge(\n",
    "                bal_agg, on=\"node_id\", how=\"left\"\n",
    "            )\n",
    "\n",
    "#   2‑c. 승·하차 0/NaN → 최소값 주입\n",
    "bal_full[\"board\"]  = pd.to_numeric(bal_full[\"board\"],  errors=\"coerce\").fillna(0)\n",
    "bal_full[\"alight\"] = pd.to_numeric(bal_full[\"alight\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "bal_full.loc[bal_full[\"board\"]  == 0, \"board\"]  = min_board\n",
    "bal_full.loc[bal_full[\"alight\"] == 0, \"alight\"] = min_alight\n",
    "\n",
    "# 3. 총 승·하차량 매핑 ------------------------------------------------------\n",
    "board_map  = bal_full.set_index(\"node_id\")[\"board\"].to_dict()\n",
    "alight_map = bal_full.set_index(\"node_id\")[\"alight\"].to_dict()\n",
    "\n",
    "demand[\"o_total\"] = demand[\"O_id\"].map(board_map)\n",
    "demand[\"d_total\"] = demand[\"D_id\"].map(alight_map)\n",
    "\n",
    "# 4. 초기 OD 행렬 + ε 주입 ---------------------------------------------------\n",
    "f = 1.0 / demand[\"Timestep\"].replace(0, np.nan)\n",
    "demand[\"T\"] = (demand[\"o_total\"] * demand[\"d_total\"] * f).fillna(0.0)\n",
    "\n",
    "valid_od = (demand[\"o_total\"] > 0) & (demand[\"d_total\"] > 0)\n",
    "demand.loc[valid_od, \"T\"] += epsilon_od      # 최소 통행량 심기\n",
    "\n",
    "# 5. IPF (Iterative Proportional Fitting) ----------------------------------\n",
    "for _ in range(max_iter):\n",
    "    row_sum = demand.groupby(\"O_id\")[\"T\"].transform(\"sum\").replace(0, np.nan)\n",
    "    demand[\"T\"] *= demand[\"o_total\"] / row_sum\n",
    "\n",
    "    col_sum = demand.groupby(\"D_id\")[\"T\"].transform(\"sum\").replace(0, np.nan)\n",
    "    demand[\"T\"] *= demand[\"d_total\"] / col_sum\n",
    "\n",
    "    if max((row_sum - demand[\"o_total\"]).abs().max(),\n",
    "           (col_sum - demand[\"d_total\"]).abs().max()) < eps_conv:\n",
    "        break\n",
    "\n",
    "# 6. journeys 계산 및 후처리 -------------------------------------------------\n",
    "demand[\"journeys\"] = demand[\"T\"].round(0).astype(int)   # 정수(명)로 반올림\n",
    "out = demand.drop(columns=[\"O_id\", \"D_id\", \"o_total\", \"d_total\", \"T\"])\n",
    "\n",
    "# 7. 결과 저장 --------------------------------------------------------------\n",
    "if output_path.exists():\n",
    "    mode, sheet_opt = \"a\", \"overlay\"\n",
    "else:\n",
    "    mode, sheet_opt = \"w\", None                 # 새 파일 — 시트 존재 안 하므로 옵션 불필요\n",
    "\n",
    "with pd.ExcelWriter(output_path,\n",
    "                    engine=\"openpyxl\",\n",
    "                    mode=mode,\n",
    "                    if_sheet_exists=sheet_opt) as wr:\n",
    "    out.to_excel(wr, sheet_name=\"DEMAND\", index=False)\n",
    "\n",
    "print(\"✅ journeys 열이 채워진 파일:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b83a59b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modified file saved to: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_journeys_fixed.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 파일 경로\n",
    "file_path = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export.xlsx\")\n",
    "output_path = file_path.with_stem(file_path.stem + \"_journeys_fixed\")\n",
    "\n",
    "# DEMAND 시트 읽기\n",
    "demand = pd.read_excel(file_path, sheet_name=\"DEMAND\")\n",
    "\n",
    "# journeys 열에서 0인 값을 1로 변경\n",
    "demand[\"journeys\"] = demand[\"journeys\"].apply(lambda x: 1 if x == 0 else x)\n",
    "\n",
    "# 새 파일로 저장\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    demand.to_excel(writer, sheet_name=\"DEMAND\", index=False)\n",
    "\n",
    "print(f\"✅ Modified file saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d9a7c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 노선별 최대 탑승 인원 =====\n",
      "   Line  MaxLoad\n",
      "KTX강릉선1      388\n",
      "KTX강릉선2      426\n",
      "경부고속철도1    29781\n",
      "경부고속철도2    29708\n",
      "   경부선1    24630\n",
      "   경부선2    24591\n",
      "   경북선1      113\n",
      "   경북선2      113\n",
      "   경전선1     1655\n",
      "   경전선2     1660\n",
      "   동해선1     1966\n",
      "   동해선2     2113\n",
      "   영동선1       61\n",
      "   영동선2       66\n",
      "   장항선1     1187\n",
      "   장항선2     1184\n",
      "   전라선1     2868\n",
      "   전라선2     2836\n",
      "   중앙선1     5046\n",
      "   중앙선2     4975\n",
      "   충북선1     1191\n",
      "   충북선2     1187\n",
      "호남고속철도1     3031\n",
      "호남고속철도2     3106\n",
      "   호남선1     3479\n",
      "   호남선2     3483\n",
      "\n",
      "===== 최대 탑승 Edge 상세(선택) =====\n",
      "   Line From  To  Load\n",
      "KTX강릉선1  n23 n22   388\n",
      "KTX강릉선2  n22 n23   426\n",
      "경부고속철도1   n4  n3 29781\n",
      "경부고속철도2   n3  n4 29708\n",
      "   경부선1   n4  n1 24630\n",
      "   경부선2   n1  n4 24591\n",
      "   경북선1  n38 n41   113\n",
      "   경북선2  n38 n36   113\n",
      "   경전선1  n66 n71  1655\n",
      "   경전선2  n71 n66  1660\n",
      "   동해선1  n69 n74  1966\n",
      "   동해선2  n72 n74  2113\n",
      "   영동선1  n55 n54    61\n",
      "   영동선2  n54 n55    66\n",
      "   장항선1  n15 n16  1187\n",
      "   장항선2  n16 n15  1184\n",
      "   전라선1  n33 n45  2868\n",
      "   전라선2  n45 n33  2836\n",
      "   중앙선1   n3  n5  5046\n",
      "   중앙선2   n5  n3  4975\n",
      "   충북선1  n19 n18  1191\n",
      "   충북선2  n18 n19  1187\n",
      "호남고속철도1  n13 n18  3031\n",
      "호남고속철도2  n18 n13  3106\n",
      "   호남선1  n48 n53  3479\n",
      "   호남선2  n53 n48  3483\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "# ────────── 1. 입력 경로 및 시트 읽기 ──────────\n",
    "file_path = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export.xlsx\")\n",
    "df = pd.read_excel(file_path, sheet_name=\"DEMAND\",\n",
    "                   usecols=[\"Line\", \"Route\", \"journeys\"])\n",
    "\n",
    "# ────────── 2. Edge‑별 탑승 인원 누적 ──────────\n",
    "edge_load = defaultdict(int)           # {(Line, from, to): 총탑승}\n",
    "\n",
    "for line, route, pax in df.itertuples(index=False):\n",
    "    nodes = route.split(\"-\")           # ex) [\"n4\",\"n3\",\"n1\",...]\n",
    "    for frm, to in zip(nodes[:-1], nodes[1:]):\n",
    "        edge_load[(line, frm, to)] += pax   # 방향 구분 O (필요 없으면 정렬해서 key 통일)\n",
    "\n",
    "# DataFrame 화\n",
    "edge_df = (pd.DataFrame([(l,f,t,c) for (l,f,t),c in edge_load.items()],\n",
    "                        columns=[\"Line\",\"From\",\"To\",\"Load\"]))\n",
    "\n",
    "# ────────── 3. 노선별 최대 탑승 인원 계산 ──────────\n",
    "max_by_line = (edge_df.groupby(\"Line\")[\"Load\"]\n",
    "                        .agg(MaxLoad=\"max\")\n",
    "                        .reset_index())\n",
    "\n",
    "# (선택) 어느 Edge 에서 최대가 나왔는지도 보고 싶다면:\n",
    "idx = edge_df.groupby(\"Line\")[\"Load\"].idxmax()\n",
    "edge_peak = edge_df.loc[idx].reset_index(drop=True)   # Line, From, To, Load\n",
    "\n",
    "# ────────── 4. 결과 저장 or 출력 ──────────\n",
    "print(\"\\n===== 노선별 최대 탑승 인원 =====\")\n",
    "print(max_by_line.to_string(index=False))\n",
    "\n",
    "print(\"\\n===== 최대 탑승 Edge 상세(선택) =====\")\n",
    "print(edge_peak.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc6d082b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 노선별 최대 Edge 탑승·필요 열차 대수 ===\n",
      "KTX강릉선1          최대탑승 =   388명  /  용량 = 381  →  열차 2대\n",
      "KTX강릉선2          최대탑승 =   426명  /  용량 = 381  →  열차 2대\n",
      "경부고속철도1          최대탑승 = 29781명  /  용량 = 515  →  열차 58대\n",
      "경부고속철도2          최대탑승 = 29708명  /  용량 = 515  →  열차 58대\n",
      "경부선1             최대탑승 = 24630명  /  용량 = 410  →  열차 61대\n",
      "경부선2             최대탑승 = 24591명  /  용량 = 410  →  열차 60대\n",
      "경북선1             최대탑승 =   113명  /  용량 = 410  →  열차 1대\n",
      "경북선2             최대탑승 =   113명  /  용량 = 410  →  열차 1대\n",
      "경전선1             최대탑승 =  1655명  /  용량 = 410  →  열차 5대\n",
      "경전선2             최대탑승 =  1660명  /  용량 = 410  →  열차 5대\n",
      "동해선1             최대탑승 =  1966명  /  용량 = 410  →  열차 5대\n",
      "동해선2             최대탑승 =  2113명  /  용량 = 410  →  열차 6대\n",
      "영동선1             최대탑승 =    61명  /  용량 = 410  →  열차 1대\n",
      "영동선2             최대탑승 =    66명  /  용량 = 410  →  열차 1대\n",
      "장항선1             최대탑승 =  1187명  /  용량 = 410  →  열차 3대\n",
      "장항선2             최대탑승 =  1184명  /  용량 = 410  →  열차 3대\n",
      "전라선1             최대탑승 =  2868명  /  용량 = 410  →  열차 7대\n",
      "전라선2             최대탑승 =  2836명  /  용량 = 410  →  열차 7대\n",
      "중앙선1             최대탑승 =  5046명  /  용량 = 410  →  열차 13대\n",
      "중앙선2             최대탑승 =  4975명  /  용량 = 410  →  열차 13대\n",
      "충북선1             최대탑승 =  1191명  /  용량 = 410  →  열차 3대\n",
      "충북선2             최대탑승 =  1187명  /  용량 = 410  →  열차 3대\n",
      "호남고속철도1          최대탑승 =  3031명  /  용량 = 410  →  열차 8대\n",
      "호남고속철도2          최대탑승 =  3106명  /  용량 = 410  →  열차 8대\n",
      "호남선1             최대탑승 =  3479명  /  용량 = 410  →  열차 9대\n",
      "호남선2             최대탑승 =  3483명  /  용량 = 410  →  열차 9대\n",
      "\n",
      "✅ 줄바꿈 최소화된 JSON 저장 완료 → D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\json\\demand_split.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, json, math\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "# ──────────────────────── 경로 설정 ────────────────────────\n",
    "BASE     = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "xlsx_fp  = BASE / \"qgis_export.xlsx\"\n",
    "json_in  = BASE / \"json\" / \"demand.json\"\n",
    "json_out = BASE / \"json\" / \"demand_split.json\"\n",
    "\n",
    "# ───────────────── 1. DEMAND 시트 → Edge 최대 탑승 ─────────────────\n",
    "df = pd.read_excel(xlsx_fp, sheet_name=\"DEMAND\",\n",
    "                   usecols=[\"Line\", \"Route\", \"journeys\"])\n",
    "\n",
    "edge_load = defaultdict(int)          # {(Line, u, v): 승객 누적}\n",
    "\n",
    "for line, route, pax in df.itertuples(index=False):\n",
    "    nodes = route.split(\"-\")\n",
    "    for u, v in zip(nodes[:-1], nodes[1:]):\n",
    "        edge_load[(line, u, v)] += pax\n",
    "\n",
    "edge_df = (pd.DataFrame([(l,u,v,c) for (l,u,v),c in edge_load.items()],\n",
    "                        columns=[\"Line\",\"From\",\"To\",\"Load\"]))\n",
    "\n",
    "max_load = (edge_df.groupby(\"Line\")[\"Load\"]\n",
    "                     .max()\n",
    "                     .to_dict())      # {Line: 최대 Edge 탑승}\n",
    "\n",
    "# ───────────────── 2. 노선별 열차 1편성 최대 좌석수 매핑 ────────────────\n",
    "def train_capacity(line: str) -> int:\n",
    "    \"\"\"노선 이름을 받아 보수적 1편성 최대 좌석수를 반환\"\"\"\n",
    "    if line.startswith(\"KTX강릉선\"):\n",
    "        return 381           # KTX‑Eum\n",
    "    if line.startswith(\"경부고속철도\"):\n",
    "        return 515           # KTX‑청룡 / 산천\n",
    "    # 그 외 일반선·호남고속철도 등 → 산천 보수치\n",
    "    return 410               # KTX‑Sancheon\n",
    "\n",
    "cap_map   = {ln: train_capacity(ln) for ln in max_load}\n",
    "train_cnt = {ln: max(1, math.ceil(max_load[ln] / cap_map[ln]))\n",
    "             for ln in max_load}\n",
    "\n",
    "print(\"\\n=== 노선별 최대 Edge 탑승·필요 열차 대수 ===\")\n",
    "for ln in sorted(train_cnt):\n",
    "    print(f\"{ln:15s}  최대탑승 = {max_load[ln]:5.0f}명  \"\n",
    "          f\"/  용량 = {cap_map[ln]}  →  열차 {train_cnt[ln]}대\")\n",
    "\n",
    "# ───────────────── 3. demand.json 불러와서 쪼개기 ─────────────────\n",
    "with open(json_in, \"r\", encoding=\"utf-8\") as f:\n",
    "    demand_js = json.load(f)\n",
    "\n",
    "split_js = {}   # 새로운 dict\n",
    "\n",
    "for ln, od_list in demand_js.items():\n",
    "    n_train = train_cnt.get(ln, 1)          # 매핑 안 되면 1대\n",
    "    for idx in range(n_train):\n",
    "        key = f\"{ln}_{idx+1}\"\n",
    "        split_js[key] = []\n",
    "    for o, d, j in od_list:\n",
    "        share = round(j / n_train, 2)\n",
    "        for idx in range(n_train):\n",
    "            split_js[f\"{ln}_{idx+1}\"].append([o, d, share])\n",
    "\n",
    "# ───────────────── 4. JSON 저장 (한 노선 = 한 줄) ─────────────────\n",
    "with open(json_out, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"{\\n\")\n",
    "    for i, (line, trips) in enumerate(split_js.items()):\n",
    "        line_str = json.dumps(line, ensure_ascii=False)\n",
    "        trips_str = json.dumps(trips, ensure_ascii=False, separators=(\",\", \":\"))\n",
    "        comma = \",\" if i < len(split_js) - 1 else \"\"\n",
    "        f.write(f\"  {line_str}: {trips_str}{comma}\\n\")\n",
    "    f.write(\"}\\n\")\n",
    "\n",
    "print(f\"\\n✅ 줄바꿈 최소화된 JSON 저장 완료 → {json_out}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed14966d",
   "metadata": {},
   "source": [
    "출발 timestep 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46944202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'time_step_15' 열이 성공적으로 추가되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# 파일 경로\n",
    "file_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export.xlsx\"\n",
    "sheet_name = \"EDGE\"\n",
    "\n",
    "# 엑셀 불러오기\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "# 'time(min)' 열이 있는지 확인\n",
    "if \"time(min)\" not in df.columns:\n",
    "    raise KeyError(\"'time(min)' 열이 존재하지 않습니다.\")\n",
    "\n",
    "# 소숫점 올림하여 time_step_15 계산\n",
    "df[\"time_step_15\"] = df[\"time(min)\"].apply(lambda x: math.ceil(x / 15))\n",
    "\n",
    "# 덮어쓰기 저장\n",
    "with pd.ExcelWriter(file_path, mode=\"a\", if_sheet_exists=\"overlay\", engine=\"openpyxl\") as writer:\n",
    "    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(\"✅ 'time_step_15' 열이 성공적으로 추가되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6fe7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ dep_time.json trimmed and saved (cutoff by rounded threshold).\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 파일 경로\n",
    "base_dir = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\json\"\n",
    "dep_path = os.path.join(base_dir, \"dep_time.json\")\n",
    "demand_path = os.path.join(base_dir, \"demand.json\")\n",
    "routes_path = os.path.join(base_dir, \"routes_nodes.json\")\n",
    "\n",
    "# 1. dep_time.json 로드\n",
    "with open(dep_path, encoding=\"utf-8\") as f:\n",
    "    dep_data = json.load(f)\n",
    "valid_trains = set(dep_data.keys())\n",
    "\n",
    "# 2. demand.json 필터링\n",
    "with open(demand_path, encoding=\"utf-8\") as f:\n",
    "    demand_data = json.load(f)\n",
    "filtered_demand = {k: v for k, v in demand_data.items() if k in valid_trains}\n",
    "\n",
    "# 3. routes_nodes.json 필터링\n",
    "with open(routes_path, encoding=\"utf-8\") as f:\n",
    "    routes_data = json.load(f)\n",
    "filtered_routes = {k: v for k, v in routes_data.items() if k in valid_trains}\n",
    "\n",
    "# 4. 저장 (덮어쓰기)\n",
    "with open(demand_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_demand, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(routes_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_routes, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ demand.json과 routes_nodes.json이 dep_time.json 기준으로 성공적으로 필터링되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99a754a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 줄바꿈 포맷 정리 완료.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 경로 설정\n",
    "base_dir = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\json\"\n",
    "demand_path = os.path.join(base_dir, \"demand_filtered.json\")\n",
    "routes_path = os.path.join(base_dir, \"routes_nodes_filtered.json\")\n",
    "\n",
    "def save_single_line_json(data, filepath):\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"{\\n\")\n",
    "        for i, (k, v) in enumerate(data.items()):\n",
    "            line = f'  \"{k}\": {json.dumps(v, ensure_ascii=False)}'\n",
    "            if i < len(data) - 1:\n",
    "                line += \",\"\n",
    "            f.write(line + \"\\n\")\n",
    "        f.write(\"}\")\n",
    "\n",
    "# 파일 불러오기\n",
    "with open(demand_path, encoding=\"utf-8\") as f:\n",
    "    demand_data = json.load(f)\n",
    "with open(routes_path, encoding=\"utf-8\") as f:\n",
    "    routes_data = json.load(f)\n",
    "\n",
    "# 한 줄당 기차 하나씩 저장\n",
    "save_single_line_json(demand_data, demand_path)\n",
    "save_single_line_json(routes_data, routes_path)\n",
    "\n",
    "print(\"✅ 줄바꿈 포맷 정리 완료.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d2e672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 필터링 전 OD쌍 개수: 12426\n",
      "🔹 필터링 후 OD쌍 개수: 3607\n",
      "🔹 제거된 OD쌍 개수: 8819\n",
      "✅ 저장 완료: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\json\\demand_filtered.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ───────────────────────────────\n",
    "# 1. 파일 경로 설정\n",
    "file_path = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\json\\demand.json\")\n",
    "output_path = file_path.parent / \"demand_filtered.json\"\n",
    "\n",
    "# ───────────────────────────────\n",
    "# 2. 데이터 불러오기\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    demand_data = json.load(f)\n",
    "\n",
    "# ───────────────────────────────\n",
    "# 3. 필터링 및 통계\n",
    "original_count = 0\n",
    "filtered_count = 0\n",
    "\n",
    "filtered_data = {}\n",
    "\n",
    "for train_id, od_list in demand_data.items():\n",
    "    original_count += len(od_list)\n",
    "    \n",
    "    # 수요 10 이상인 OD쌍만 남기기\n",
    "    new_od_list = [od for od in od_list if od[2] >= 10]\n",
    "    filtered_count += len(new_od_list)\n",
    "    \n",
    "    # 결과가 남아있는 경우에만 저장\n",
    "    if new_od_list:\n",
    "        filtered_data[train_id] = new_od_list\n",
    "\n",
    "# ───────────────────────────────\n",
    "# 4. 필터링 결과 저장\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ───────────────────────────────\n",
    "# 5. 결과 출력\n",
    "print(f\"🔹 필터링 전 OD쌍 개수: {original_count}\")\n",
    "print(f\"🔹 필터링 후 OD쌍 개수: {filtered_count}\")\n",
    "print(f\"🔹 제거된 OD쌍 개수: {original_count - filtered_count}\")\n",
    "print(f\"✅ 저장 완료: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15255623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ dep_time 필터링: 122 → 106개 남음\n",
      "✅ routes_nodes 필터링: 122 → 106개 남음\n",
      "\n",
      "📁 저장 완료:\n",
      "→ dep_time_filtered.json\n",
      "→ routes_nodes_filtered.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ───────────────────────────────\n",
    "# 1. 경로 설정\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\json\")\n",
    "dep_time_path = base_dir / \"dep_time.json\"\n",
    "routes_nodes_path = base_dir / \"routes_nodes.json\"\n",
    "dep_time_out = base_dir / \"dep_time_filtered.json\"\n",
    "routes_nodes_out = base_dir / \"routes_nodes_filtered.json\"\n",
    "\n",
    "# ───────────────────────────────\n",
    "# 2. dep_time.json 불러오기 및 필터링 (값이 13 미만인 것만)\n",
    "with open(dep_time_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    dep_time = json.load(f)\n",
    "\n",
    "filtered_dep_time = {k: v for k, v in dep_time.items() if v < 12}\n",
    "print(f\"✅ dep_time 필터링: {len(dep_time)} → {len(filtered_dep_time)}개 남음\")\n",
    "\n",
    "# 저장\n",
    "with open(dep_time_out, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_dep_time, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ───────────────────────────────\n",
    "# 3. routes_nodes.json 불러오기 및 해당 키만 남기기\n",
    "with open(routes_nodes_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    routes_nodes = json.load(f)\n",
    "\n",
    "# dep_time에서 남은 키만 유지\n",
    "filtered_routes_nodes = {k: v for k, v in routes_nodes.items() if k in filtered_dep_time}\n",
    "print(f\"✅ routes_nodes 필터링: {len(routes_nodes)} → {len(filtered_routes_nodes)}개 남음\")\n",
    "\n",
    "# 저장\n",
    "with open(routes_nodes_out, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_routes_nodes, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ───────────────────────────────\n",
    "# 4. 결과 요약\n",
    "print(f\"\\n📁 저장 완료:\")\n",
    "print(f\"→ {dep_time_out.name}\")\n",
    "print(f\"→ {routes_nodes_out.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb134c89",
   "metadata": {},
   "source": [
    "#### Capacity\n",
    "- Demand_data이용해서 엣지마다 흐르는 demand양 계산한 파일: 6.edge_journeys_summary.xlsx\n",
    "- e1 n1-n2 1502241\n",
    "- e2 n2-n1 389459.5\n",
    "- e1,e2,e3,e4, .. 넘버링 qgis와 다름 (양방향 고려)\n",
    "- 양방향 엣지에 대해서는 서로 동일한 capacity를 갖도록 해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060b668f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capacity summary saved → D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\7.edge_capacity_summary.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. 파일 불러오기\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "input_path = base_dir / \"6.edge_journeys_summary.xlsx\"\n",
    "df = pd.read_excel(input_path)\n",
    "\n",
    "# 2. 여유 계수 설정 (예: 1.2배)\n",
    "buffer_ratio = 1.2\n",
    "\n",
    "# 3. (u, v) / (v, u) 형태를 고려해 양방향 키 만들기\n",
    "df[\"pair_key\"] = df.apply(lambda row: tuple(sorted([row[\"from_node_name\"], row[\"to_node_name\"]])), axis=1)\n",
    "\n",
    "# 4. 같은 pair_key 그룹 내에서 최대 journeys 선택\n",
    "grouped = df.groupby(\"pair_key\", as_index=False).agg({\n",
    "    \"journeys\": \"max\"\n",
    "})\n",
    "grouped[\"capacity\"] = grouped[\"journeys\"] * buffer_ratio\n",
    "\n",
    "# 5. 다시 원래 방향성 edge에 capacity 연결\n",
    "df = df.merge(grouped[[\"pair_key\", \"capacity\"]], on=\"pair_key\", how=\"left\")\n",
    "\n",
    "# 6. 컬럼 정리 및 저장\n",
    "df = df.drop(columns=[\"pair_key\"])\n",
    "output_path = base_dir / \"7.edge_capacity_summary.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Capacity summary saved → {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc815f",
   "metadata": {},
   "source": [
    "#### 노선별 승객 수요 데이터 -> 필요한 기차수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01187308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      line  cycles_day  train_sets_needed\n",
      "0   KTX강릉선          24                  1\n",
      "1   KTX동해선          39                  1\n",
      "2      경강선          23                  2\n",
      "3   경부고속철도           8                 23\n",
      "4      경부선           1                 65\n",
      "5      경북선          18                  1\n",
      "6      경의선          46                  1\n",
      "7      경인선          35                  1\n",
      "8      경전선           5                  3\n",
      "9     공항철도          20                  2\n",
      "10     대구선          44                  1\n",
      "11   동해남부선          12                  3\n",
      "12     동해선          16                  1\n",
      "13     삼척선          51                  1\n",
      "14     영동선          12                  2\n",
      "15     장항선          11                  2\n",
      "16     전라선          17                  2\n",
      "17   중부내륙선          36                  1\n",
      "18     중앙선           2                 23\n",
      "19     충북선          11                  1\n",
      "20     태백선          19                  1\n",
      "21  호남고속철도          20                  1\n",
      "22     호남선          10                  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minji Kang\\AppData\\Local\\Temp\\ipykernel_38976\\2930921966.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  result = df.groupby(\"line\").apply(train_stats).reset_index()\n"
     ]
    }
   ],
   "source": [
    "import json, math, pandas as pd, os\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 1. 파일 읽기\n",
    "file_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\5.demand_data_kofull.json\"\n",
    "df = pd.read_json(file_path)\n",
    "df[\"journeys_day\"] = df[\"journeys\"] / 365\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "# 2. 파라미터\n",
    "TARGET_LOAD    = 1.0          # 100 % 탑승률\n",
    "TURNAROUND_MIN = 15           # 종점 버퍼(분)\n",
    "HOURS_PER_DAY  = 17\n",
    "DEFAULT_SEAT   = 400          # seat_map 에 없을 때 임시값\n",
    "\n",
    "# 노선별 좌석수 (앞 글자 매칭용)\n",
    "seat_map = {\n",
    "    # 고속열차\n",
    "    \"KTX강릉선\":    381,   # KTX-이음 (KTX-Eum) 381석 :contentReference[oaicite:2]{index=2}\n",
    "    \"KTX경부선\":    955,   # KTX-I 955석(935~955) :contentReference[oaicite:3]{index=3}\n",
    "    \"KTX호남선\":    955,\n",
    "    \"경부고속철도\":   955,   # KTX-산천\n",
    "    \"경부선\":         900,   # SRT 편성(예시)\n",
    "    # ITX 계열\n",
    "    \"ITX-새마을\":   376,   # ITX-새마을\n",
    "    \"ITX-청춘\":     402,   # ITX-청춘\n",
    "    # 일반열차\n",
    "    \"무궁화호\":     920,   # 좌석+입석 허용, 편성 좌석 920 부근\n",
    "}\n",
    "\n",
    "# ───────────────────────────────────────────────\n",
    "def train_stats(group):\n",
    "    line = group.name\n",
    "    seats = next((v for k, v in seat_map.items() if line.startswith(k)), DEFAULT_SEAT)\n",
    "\n",
    "    total_pax = group[\"journeys_day\"].sum()\n",
    "    single_run = group[\"time_min\"].max()\n",
    "    round_trip = single_run + TURNAROUND_MIN\n",
    "    cycles = max(1, (HOURS_PER_DAY * 60) // round_trip)\n",
    "\n",
    "    cap_per_set = seats * TARGET_LOAD * cycles\n",
    "    sets_needed = math.ceil(total_pax / cap_per_set) if cap_per_set else None\n",
    "\n",
    "    return pd.Series({\n",
    "        \"cycles_day\": cycles,\n",
    "        \"train_sets_needed\": sets_needed\n",
    "    })\n",
    "\n",
    "# 4. 계산\n",
    "result = df.groupby(\"line\").apply(train_stats).reset_index()\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mjkang",
   "language": "python",
   "name": "mjkang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
