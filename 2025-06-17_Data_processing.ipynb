{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c9612c",
   "metadata": {},
   "source": [
    "#### QGIS -> demand \n",
    "ë…¸ì„ ë³„ë¡œ ê²½ë¡œ ìƒì„±\n",
    "distance ë°ì´í„° ë„£ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab9b4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ ë…¸ì„ ë³„ ë‹¨ì¼ ê²½ë¡œ (ë°©í–¥ ë¬´ì‹œ)\n",
      "KTXê°•ë¦‰ì„ : [22, 23, 34, 51]\n",
      "ê²½ë¶€ê³ ì†ì² ë„: [4, 3, 1, 2, 13, 18, 28, 42, 60, 72, 75, 79]\n",
      "ê²½ë¶€ì„ : [79, 77, 76, 73, 70, 63, 60, 59, 46, 41, 28, 17, 14, 9, 7, 1, 4]\n",
      "ê²½ë¶ì„ : [41, 38, 36, 40, 43]\n",
      "ê²½ì „ì„ : [48, 57, 64, 65, 62, 66, 71, 73]\n",
      "ë™í•´ì„ : [55, 58, 69, 74, 72]\n",
      "ì˜ë™ì„ : [51, 55, 54, 50, 43]\n",
      "ì¥í•­ì„ : [14, 11, 10, 15, 16, 27, 30]\n",
      "ì „ë¼ì„ : [68, 62, 56, 47, 45, 33, 30]\n",
      "ì¤‘ì•™ì„ : [3, 5, 6, 8, 12, 22, 29, 31, 35, 39, 43, 49, 52, 67, 72, 78, 79]\n",
      "ì¶©ë¶ì„ : [17, 18, 19, 20, 26, 29]\n",
      "í˜¸ë‚¨ê³ ì†ì² ë„: [48, 37, 30, 21, 18, 13, 2, 1, 3]\n",
      "í˜¸ë‚¨ì„ : [61, 53, 48, 44, 37, 32, 30, 24, 25, 28]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. íŒŒì¼ ê²½ë¡œ\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "xlsx_path = base_path + r\"\\qgis_export.xlsx\"\n",
    "sheet_name = \"LINE\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "df = pd.read_excel(xlsx_path, sheet_name=sheet_name)\n",
    "df = df.dropna(subset=[\"from_node_\", \"to_node_id\"])\n",
    "df[\"from_node_\"] = df[\"from_node_\"].astype(int)\n",
    "df[\"to_node_id\"] = df[\"to_node_id\"].astype(int)\n",
    "\n",
    "print(\"ğŸ“Œ ë…¸ì„ ë³„ ë‹¨ì¼ ê²½ë¡œ (ë°©í–¥ ë¬´ì‹œ)\")\n",
    "for line, group in df.groupby(\"RLWAY_NM\"):\n",
    "    # ì–‘ë°©í–¥ ê·¸ë˜í”„ ìƒì„±\n",
    "    graph = defaultdict(list)\n",
    "    for u, v in zip(group[\"from_node_\"], group[\"to_node_id\"]):\n",
    "        graph[u].append(v)\n",
    "        graph[v].append(u)\n",
    "\n",
    "    # ë…¸ë“œ ì—°ê²° ìƒíƒœ ì§„ë‹¨\n",
    "    degree = {n: len(adj) for n, adj in graph.items()}\n",
    "    endpoints = [n for n, d in degree.items() if d == 1]\n",
    "    if len(endpoints) != 2:\n",
    "        print(f\"âš ï¸ {line}: ì„ í˜• ê²½ë¡œ ì•„ë‹˜ (ë ë…¸ë“œ {len(endpoints)}ê°œ)\")\n",
    "        continue\n",
    "\n",
    "    # í•œìª½ ëì—ì„œë¶€í„° BFSë¡œ ê²½ë¡œ ë³µì›\n",
    "    start = endpoints[0]\n",
    "    visited = set()\n",
    "    path = []\n",
    "\n",
    "    def dfs(u):\n",
    "        visited.add(u)\n",
    "        path.append(u)\n",
    "        for v in graph[u]:\n",
    "            if v not in visited:\n",
    "                dfs(v)\n",
    "\n",
    "    dfs(start)\n",
    "    print(f\"{line}: {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef1b54",
   "metadata": {},
   "source": [
    "#### EDGE timestep ë°ì´í„° ë§Œë“¤ê¸° ìœ„í•´\n",
    "- distanceë¡œ ì´ë™ì‹œê°„\n",
    "- ì´ë™ì‹œê°„ ê¸°ë°˜ time step ê³„ì‚°\n",
    "- EDGE ë°ì´í„° .json íŒŒì¼ë¡œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f068c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì™„ë£Œ: time_step ì—´ì´ ì¶”ê°€ëœ íŒŒì¼ì´ ì €ì¥ë¨ â†’\n",
      "D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_time.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "input_file  = base_path + r\"\\qgis_export.xlsx\"\n",
    "output_file = base_path + r\"\\qgis_export_with_time.xlsx\"\n",
    "sheet_name  = \"EDGE\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. ì›ë³¸ ì—‘ì…€ ì „ì²´ ì½ê¸° (ëª¨ë“  ì‹œíŠ¸ ë³´ì¡´ ëª©ì )\n",
    "xlsx_all = pd.read_excel(input_file, sheet_name=None)\n",
    "\n",
    "# 2. EDGE ì‹œíŠ¸ë§Œ ìˆ˜ì •\n",
    "df_edge = xlsx_all[sheet_name]\n",
    "\n",
    "# 3. time_step ê³„ì‚°\n",
    "if 'distance' not in df_edge.columns:\n",
    "    raise ValueError(\"'distance' ì—´ì´ EDGE ì‹œíŠ¸ì— ì—†ìŠµë‹ˆë‹¤.\")\n",
    "df_edge['time_step'] = df_edge['distance'] / 150 * 60\n",
    "\n",
    "# 4. ìˆ˜ì •í•œ EDGE ì‹œíŠ¸ ë‹¤ì‹œ ë„£ê¸°\n",
    "xlsx_all[sheet_name] = df_edge\n",
    "\n",
    "# 5. ì „ì²´ ì‹œíŠ¸ë¥¼ ìƒˆ íŒŒì¼ë¡œ ì €ì¥\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    for sheet, df in xlsx_all.items():\n",
    "        df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "\n",
    "print(f\"âœ… ì™„ë£Œ: time_step ì—´ì´ ì¶”ê°€ëœ íŒŒì¼ì´ ì €ì¥ë¨ â†’\\n{output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb45211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì™„ë£Œ: 'time_step' ê³„ì‚° í›„ ì €ì¥ë¨ â†’\n",
      "D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_step.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "input_file  = base_path + r\"\\qgis_export_with_time.xlsx\"\n",
    "output_file = base_path + r\"\\qgis_export_with_step.xlsx\"\n",
    "sheet_name  = \"EDGE\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. ëª¨ë“  ì‹œíŠ¸ ì½ê¸°\n",
    "xlsx_all = pd.read_excel(input_file, sheet_name=None)\n",
    "\n",
    "# 2. EDGE ì‹œíŠ¸ ìˆ˜ì •\n",
    "df_edge = xlsx_all[sheet_name]\n",
    "\n",
    "# 3. time_step ê³„ì‚° (5ë¡œ ë‚˜ëˆ„ê³  ì˜¬ë¦¼)\n",
    "if 'time(min)' not in df_edge.columns:\n",
    "    raise ValueError(\"'time(min)' ì—´ì´ EDGE ì‹œíŠ¸ì— ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "df_edge['time_step'] = df_edge['time(min)'].apply(lambda x: math.ceil(x / 5))\n",
    "\n",
    "# 4. ë®ì–´ì“°ê¸°\n",
    "xlsx_all[sheet_name] = df_edge\n",
    "\n",
    "# 5. ìƒˆ íŒŒì¼ë¡œ ì €ì¥\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    for sheet, df in xlsx_all.items():\n",
    "        df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "\n",
    "print(f\"âœ… ì™„ë£Œ: 'time_step' ê³„ì‚° í›„ ì €ì¥ë¨ â†’\\n{output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072ab939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì •ë ¬ëœ edges.json ì €ì¥ ì™„ë£Œ â†’\n",
      "D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\edges.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "input_file  = os.path.join(base_path, \"qgis_export_with_step.xlsx\")\n",
    "sheet_name  = \"EDGE\"\n",
    "output_json = os.path.join(base_path, \"edges.json\")\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_excel(input_file, sheet_name=sheet_name)\n",
    "\n",
    "# 2. í•„ìš”í•œ ì—´ í™•ì¸\n",
    "required_cols = ['edge_id', 'from_node_id', 'to_node_id', 'time_step']\n",
    "missing = set(required_cols) - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"ë‹¤ìŒ ì—´ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing}\")\n",
    "\n",
    "# 3. ì •ìˆ˜í˜• edge_id ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
    "df = df.dropna(subset=['edge_id'])\n",
    "df['edge_id'] = df['edge_id'].astype(int)\n",
    "df = df.sort_values(by='edge_id')\n",
    "\n",
    "# 4. edge ë”•ì…”ë„ˆë¦¬ ìƒì„± (OrderedDictë¡œ ìˆœì„œ ìœ ì§€)\n",
    "edges = OrderedDict()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    eid = f\"e{int(row['edge_id'])}\"\n",
    "    n_from = f\"n{int(row['from_node_id'])}\"\n",
    "    n_to   = f\"n{int(row['to_node_id'])}\"\n",
    "    tstep  = int(row['time_step'])\n",
    "\n",
    "    edges[eid] = (n_from, n_to, tstep)\n",
    "\n",
    "# 5. JSON ì €ì¥\n",
    "with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(edges, f, indent=4)\n",
    "\n",
    "print(f\"âœ… ì •ë ¬ëœ edges.json ì €ì¥ ì™„ë£Œ â†’\\n{output_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0837e648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\routes_nodes.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "xlsx_file = os.path.join(base_path, \"qgis_export_with_step.xlsx\")\n",
    "sheet_name = \"TRAIN\"\n",
    "output_json = os.path.join(base_path, \"routes_nodes.json\")\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. TRAIN ì‹œíŠ¸ ì½ê¸°\n",
    "df = pd.read_excel(xlsx_file, sheet_name=sheet_name)\n",
    "\n",
    "# 2. routes_nodes ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "routes_nodes = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    name = str(row[\"RLWAY_NM\"]).strip()\n",
    "    nodes_str = str(row[\"NODE\"]).strip()\n",
    "\n",
    "    # ë…¸ë“œ ë¬¸ìì—´ íŒŒì‹± â†’ ['n4', 'n3', 'n1', ...]\n",
    "    node_list = [f\"n{int(n)}\" for n in nodes_str.split(\"-\") if n.isdigit()]\n",
    "\n",
    "    # ì •ë°©í–¥ ë° ì—­ë°©í–¥ ì €ì¥\n",
    "    routes_nodes[f\"{name}1\"] = node_list\n",
    "    routes_nodes[f\"{name}2\"] = node_list[::-1]\n",
    "\n",
    "# 3. JSON ì €ì¥\n",
    "with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(routes_nodes, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ: {output_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ea2954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì–‘ë°©í–¥ edges ì €ì¥ ì™„ë£Œ: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\edges_bidirectional.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "input_json = os.path.join(base_path, \"edges.json\")\n",
    "output_json = os.path.join(base_path, \"edges_bidirectional.json\")\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. ê¸°ì¡´ edges.json ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open(input_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    edges = json.load(f)\n",
    "\n",
    "# 2. ì–‘ë°©í–¥ ë”•ì…”ë„ˆë¦¬ ìƒì„± (ìˆœì„œ ë³´ì¡´)\n",
    "edges_bidir = OrderedDict()\n",
    "\n",
    "for eid, (n1, n2, t) in edges.items():\n",
    "    # ì •ë°©í–¥ edge ì¶”ê°€\n",
    "    edges_bidir[eid] = [n1, n2, t]\n",
    "    \n",
    "    # ì—­ë°©í–¥ edge ì¶”ê°€\n",
    "    eid_r = f\"{eid}r\"\n",
    "    edges_bidir[eid_r] = [n2, n1, t]\n",
    "\n",
    "# 3. ìƒˆ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(edges_bidir, f, indent=4)\n",
    "\n",
    "print(f\"âœ… ì–‘ë°©í–¥ edges ì €ì¥ ì™„ë£Œ: {output_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9416e8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… demand_template.json ì €ì¥ ì™„ë£Œ â†’\n",
      "D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\demand_template.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "routes_json = os.path.join(base_path, \"routes_nodes.json\")\n",
    "output_demand_json = os.path.join(base_path, \"demand_template.json\")\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. routes_nodes.json ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open(routes_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    routes_nodes = json.load(f)\n",
    "\n",
    "# 2. demand ìƒì„±\n",
    "demand = {}\n",
    "\n",
    "for tr, path in routes_nodes.items():\n",
    "    od_list = []\n",
    "    for i in range(len(path)-1):\n",
    "        for j in range(i+1, len(path)):\n",
    "            o, d = path[i], path[j]\n",
    "            od_list.append((o, d, None))  # ìˆ˜ìš”ëŠ” ì•„ì§ ì—†ìŒ\n",
    "    demand[tr] = od_list\n",
    "\n",
    "# 3. ì €ì¥\n",
    "with open(output_demand_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(demand, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… demand_template.json ì €ì¥ ì™„ë£Œ â†’\\n{output_demand_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42781bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë¨ â†’ D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\demand_template_compact.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "input_file  = os.path.join(base_path, \"demand_template.json\")\n",
    "output_file = os.path.join(base_path, \"demand_template_compact.json\")\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    demand = json.load(f)\n",
    "\n",
    "# 2. ì €ì¥ (ìˆ˜ë™ ë¬¸ìì—´ í¬ë§·)\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"{\\n\")\n",
    "    for i, (k, od_list) in enumerate(demand.items()):\n",
    "        f.write(f'    \"{k}\": [\\n')\n",
    "        line = \"        \"  # ë“¤ì—¬ì“°ê¸° ì‹œì‘\n",
    "        for j, od in enumerate(od_list):\n",
    "            # JSON ê°’ìœ¼ë¡œ ì¸ì½”ë”© (ensure null/quote ë“± ë§ì¶¤)\n",
    "            od_json = json.dumps(od, ensure_ascii=False)\n",
    "            line += od_json\n",
    "            if j < len(od_list) - 1:\n",
    "                line += \", \"\n",
    "            if len(line) > 120:\n",
    "                f.write(line + \"\\n\")\n",
    "                line = \"        \"\n",
    "        if line.strip():\n",
    "            f.write(line + \"\\n\")\n",
    "        f.write(\"    ]\")\n",
    "        if i < len(demand) - 1:\n",
    "            f.write(\",\\n\")\n",
    "        else:\n",
    "            f.write(\"\\n\")\n",
    "    f.write(\"}\\n\")\n",
    "\n",
    "print(f\"âœ… ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë¨ â†’ {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2836b",
   "metadata": {},
   "source": [
    "#### ì—­ì‚¬ë³„ ìŠ¹í•˜ì°¨ë°ì´í„°ë¡œ ì„ì‹œ journeys demand data ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6238ff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ ë‘˜ ë‹¤ í¬í•¨ëœ ì—­ (matched):\n",
      " - ê²½ì‚°ì—­\n",
      " - ê³„ë£¡ì—­\n",
      " - ê³¡ì„±ì—­\n",
      " - ê³µì£¼ì—­\n",
      " - ê´‘ëª…ì—­\n",
      " - ê´‘ì£¼ì†¡ì •ì—­\n",
      " - ê´‘ì²œì—­\n",
      " - êµ¬ë¡€êµ¬ì—­\n",
      " - êµ¬ë¯¸ì—­\n",
      " - êµ¬í¬ì—­\n",
      " - ê¸°ì¥ì—­\n",
      " - ê¹€ì œì—­\n",
      " - ê¹€ì²œêµ¬ë¯¸ì—­\n",
      " - ê¹€ì²œì—­\n",
      " - ë‚˜ì£¼ì—­\n",
      " - ë‚¨ì›ì—­\n",
      " - ë…¼ì‚°ì—­\n",
      " - ëŠ¥ì£¼ì—­\n",
      " - ë‹¨ì–‘ì—­\n",
      " - ëŒ€êµ¬ì—­\n",
      " - ëŒ€ì „ì—­\n",
      " - ëŒ€ì²œì—­\n",
      " - ë•ì†Œì—­\n",
      " - ë™ëŒ€êµ¬ì—­\n",
      " - ë™í•´ì—­\n",
      " - ë§ˆì‚°ì—­\n",
      " - ëª©í¬ì—­\n",
      " - ë¬¼ê¸ˆì—­\n",
      " - ë°€ì–‘ì—­\n",
      " - ë²Œêµì—­\n",
      " - ë³´ì„±ì—­\n",
      " - ë´‰ì–‘ì—­\n",
      " - ë¶€ì‚°ì—­\n",
      " - ì‚¼ë‘ì§„ì—­\n",
      " - ìƒë´‰ì—­\n",
      " - ìƒì£¼ì—­\n",
      " - ì„œìš¸ì—­\n",
      " - ì„œì°½ì—­\n",
      " - ìˆ˜ì›ì—­\n",
      " - ìˆœì²œì—­\n",
      " - ì•ˆë™ì—­\n",
      " - ì–‘í‰ì—­\n",
      " - ì—¬ìˆ˜ì—‘ìŠ¤í¬ì—­\n",
      " - ì˜ë•ì—­\n",
      " - ì˜ë“±í¬ì—­\n",
      " - ì˜ì£¼ì—­\n",
      " - ì˜ì²œì—­\n",
      " - ì˜ˆì‚°ì—­\n",
      " - ì˜ˆì²œì—­\n",
      " - ì˜¤ì†¡ì—­\n",
      " - ì˜¨ì–‘ì˜¨ì²œì—­\n",
      " - ìš©ì‚°ì—­\n",
      " - ìš¸ì‚°ì—­\n",
      " - ì›ì£¼ì—­\n",
      " - ì˜ì„±ì—­\n",
      " - ìµì‚°ì—­\n",
      " - ì¥ì„±ì—­\n",
      " - ì¥í•­ì—­\n",
      " - ì „ì£¼ì—­\n",
      " - ì ì´Œì—­\n",
      " - ì •ë™ì§„ì—­\n",
      " - ì •ìì—­\n",
      " - ì œì²œì—­\n",
      " - ì§„ì£¼ì—­\n",
      " - ì²œì•ˆì—­\n",
      " - ì²­ëŸ‰ë¦¬ì—­\n",
      " - ì²­ì£¼ì—­\n",
      " - ì¶˜ì–‘ì—­\n",
      " - ì¶©ì£¼ì—­\n",
      " - íƒœí™”ê°•ì—­\n",
      " - í‰ì°½ì—­\n",
      " - í‰íƒì—­\n",
      " - í¬í•­ì—­\n",
      " - í’ê¸°ì—­\n",
      " - íš¡ì„±ì—­\n",
      "\n",
      "ğŸ“Œ QGISì—ëŠ” ìˆìœ¼ë‚˜ ìŠ¹í•˜ì°¨ ë°ì´í„°ì—ëŠ” ì—†ëŠ” ì—­ (only_in_qgis):\n",
      " - ë°±ì‚°ì—­\n",
      " - ë³´ì²œì—­\n",
      " - ì‚¼ì²™ì—­\n",
      " - ì‹ ê²½ì£¼ì—­\n",
      " - ì²œì•ˆì•„ì‚°ì—­(ì˜¨ì–‘ì˜¨ì²œ)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "qgis_path = base_dir / \"qgis_export_with_step.xlsx\"\n",
    "ridership_path = base_dir / \"station_ridership.xlsx\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. QGIS NODE ë°ì´í„°ì—ì„œ RLNODE_NM ì¶”ì¶œ\n",
    "qgis_df = pd.read_excel(qgis_path, sheet_name=\"NODE\")\n",
    "qgis_nodes = qgis_df[\"RLNODE_NM\"].astype(str).str.strip()\n",
    "\n",
    "# 2. ìŠ¹í•˜ì°¨ ë°ì´í„°ì—ì„œ RLNODE_NM ì¶”ì¶œ (Eì—´)\n",
    "ridership_df = pd.read_excel(ridership_path)\n",
    "ridership_nodes = ridership_df[\"RLNODE_NM\"].astype(str).str.strip()\n",
    "\n",
    "# 3. ë¹„êµ\n",
    "matched = sorted(set(qgis_nodes) & set(ridership_nodes))\n",
    "only_in_qgis = sorted(set(qgis_nodes) - set(ridership_nodes))\n",
    "\n",
    "# 4. ì¶œë ¥\n",
    "print(\"ğŸ“Œ ë‘˜ ë‹¤ í¬í•¨ëœ ì—­ (matched):\")\n",
    "for name in matched:\n",
    "    print(f\" - {name}\")\n",
    "\n",
    "print(\"\\nğŸ“Œ QGISì—ëŠ” ìˆìœ¼ë‚˜ ìŠ¹í•˜ì°¨ ë°ì´í„°ì—ëŠ” ì—†ëŠ” ì—­ (only_in_qgis):\")\n",
    "for name in only_in_qgis:\n",
    "    print(f\" - {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4518b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ”ï¸ ì €ì¥ ì™„ë£Œ: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_ridership.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "xlsx_path = base_dir / \"qgis_export_with_step.xlsx\"\n",
    "output_path = base_dir / \"qgis_export_with_ridership.xlsx\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. NODE ì‹œíŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "node_df = pd.read_excel(xlsx_path, sheet_name=\"NODE\")\n",
    "\n",
    "# 2. BOARD,ALIGHT ì‹œíŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "ridership_df = pd.read_excel(xlsx_path, sheet_name=\"BOARD,ALIGHT\")\n",
    "\n",
    "# 3. RLNODE_NM ê¸°ì¤€ ë³‘í•©\n",
    "merged_df = node_df.merge(\n",
    "    ridership_df[[\"RLNODE_NM\", \"board_1d\", \"alight_1d\"]],\n",
    "    on=\"RLNODE_NM\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 4. ìƒˆë¡œìš´ íŒŒì¼ë¡œ ì €ì¥\n",
    "merged_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"âœ”ï¸ ì €ì¥ ì™„ë£Œ: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13186668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ”ï¸ ì €ì¥ ì™„ë£Œ: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_timestep.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "xlsx_path = base_dir / \"qgis_export.xlsx\"\n",
    "output_path = base_dir / \"qgis_export_with_timestep.xlsx\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. ì—£ì§€ ì •ë³´ ì½ê¸°\n",
    "edge_df = pd.read_excel(xlsx_path, sheet_name=\"EDGE\")\n",
    "edge_df[\"from_node_id\"] = edge_df[\"from_node_id\"].astype(str).str.lower()\n",
    "edge_df[\"to_node_id\"] = edge_df[\"to_node_id\"].astype(str).str.lower()\n",
    "\n",
    "# 2. demand íƒ­ ì½ê¸°\n",
    "demand_df = pd.read_excel(xlsx_path, sheet_name=\"DEMAND\")\n",
    "\n",
    "# 3. Route ê¸°ë°˜ Timestep ê³„ì‚° í•¨ìˆ˜\n",
    "def compute_total_timestep(route_str):\n",
    "    if pd.isna(route_str):\n",
    "        return None\n",
    "    nodes = route_str.strip().split(\"-\")\n",
    "    total_time = 0\n",
    "    for i in range(len(nodes) - 1):\n",
    "        from_n = nodes[i].replace(\"n\", \"\")\n",
    "        to_n = nodes[i+1].replace(\"n\", \"\")\n",
    "\n",
    "        # í•´ë‹¹ fromâ†”toì— í•´ë‹¹í•˜ëŠ” time_step ì°¾ê¸°\n",
    "        match = edge_df[\n",
    "            ((edge_df[\"from_node_id\"] == from_n) & (edge_df[\"to_node_id\"] == to_n)) |\n",
    "            ((edge_df[\"from_node_id\"] == to_n) & (edge_df[\"to_node_id\"] == from_n))\n",
    "        ]\n",
    "\n",
    "        if match.empty:\n",
    "            return None  # í•´ë‹¹ êµ¬ê°„ ì •ë³´ ì—†ìŒ\n",
    "        total_time += match.iloc[0][\"time_step\"]\n",
    "    return total_time\n",
    "\n",
    "# 4. Timestep ê³„ì‚° ë° ì—´ ì¶”ê°€\n",
    "demand_df[\"Timestep\"] = demand_df[\"Route\"].apply(compute_total_timestep)\n",
    "\n",
    "# 5. ì €ì¥\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "    demand_df.to_excel(writer, sheet_name=\"DEMAND\", index=False)\n",
    "\n",
    "print(f\"âœ”ï¸ ì €ì¥ ì™„ë£Œ: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3eb01c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\demand_with_route_filled.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "base_path = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "file_path = base_path / \"qgis_export.xlsx\"\n",
    "\n",
    "# ì—‘ì…€ íŒŒì¼ ì½ê¸°\n",
    "train_df = pd.read_excel(file_path, sheet_name=\"TRAIN\")\n",
    "demand_df = pd.read_excel(file_path, sheet_name=\"DEMAND\")\n",
    "\n",
    "# ë…¸ì„  ì´ë¦„ â†’ ë…¸ë“œ ê²½ë¡œ dict (n ì ‘ë‘ì–´ ë¶™ì´ê¸°)\n",
    "line_routes = {}\n",
    "for _, row in train_df.iterrows():\n",
    "    line_name = row[\"RLWAY_NM\"].strip()\n",
    "    node_seq = [f\"n{n.strip()}\" for n in str(row[\"NODE\"]).split(\"-\")]\n",
    "    line_routes[line_name] = node_seq\n",
    "\n",
    "# ë…¸ì„  ì´ë¦„ì—ì„œ ìˆ«ì ì œê±°í•´ì„œ base nameìœ¼ë¡œ ë§¤í•‘\n",
    "def get_base_line(line):\n",
    "    return ''.join(filter(lambda x: not x.isdigit(), line)).strip()\n",
    "\n",
    "# ODì— ëŒ€í•´ Route ìƒì„± í•¨ìˆ˜\n",
    "def extract_route(line, origin, destination):\n",
    "    base_line = get_base_line(line)\n",
    "    nodes = line_routes.get(base_line)\n",
    "    if not nodes:\n",
    "        return None\n",
    "    if origin not in nodes or destination not in nodes:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        idx_o = nodes.index(origin)\n",
    "        idx_d = nodes.index(destination)\n",
    "        # ì •ë°©í–¥ ë˜ëŠ” ì—­ë°©í–¥ ìŠ¬ë¼ì´ì‹±\n",
    "        if idx_o <= idx_d:\n",
    "            path = nodes[idx_o:idx_d + 1]\n",
    "        else:\n",
    "            path = nodes[idx_o:idx_d - 1:-1]  # ì—­ë°©í–¥\n",
    "        return \"-\".join(path)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Route ì—´ ì¶”ê°€\n",
    "demand_df[\"Route\"] = demand_df.apply(\n",
    "    lambda row: extract_route(row[\"Line\"], row[\"Origin\"], row[\"Destination\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ì €ì¥\n",
    "output_path = base_path / \"demand_with_route_filled.xlsx\"\n",
    "demand_df.to_excel(output_path, index=False)\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fe683ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ”ï¸ ì €ì¥ ì™„ë£Œ: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_node_id.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "xlsx_path = base_dir / \"qgis_export.xlsx\"\n",
    "output_path = base_dir / \"qgis_export_with_node_id.xlsx\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. NODE ì‹œíŠ¸ ì½ê¸° (ì°¸ì¡°ìš©)\n",
    "node_df = pd.read_excel(xlsx_path, sheet_name=\"NODE\")\n",
    "node_df = node_df[[\"RLNODE_NM\", \"node_id\"]].dropna()\n",
    "node_df[\"RLNODE_NM\"] = node_df[\"RLNODE_NM\"].astype(str).str.strip()\n",
    "\n",
    "# 2. BOARD_ALIGHT ì‹œíŠ¸ì— node_id ë§¤ì¹­\n",
    "df = pd.read_excel(xlsx_path, sheet_name=\"BOARD_ALIGHT\")\n",
    "df[\"RLNODE_NM\"] = df[\"RLNODE_NM\"].astype(str).str.strip()\n",
    "\n",
    "# ë§¤ì¹­ ìˆ˜í–‰\n",
    "merged_df = df.merge(node_df, on=\"RLNODE_NM\", how=\"left\")\n",
    "\n",
    "# 3. ì €ì¥\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    merged_df.to_excel(writer, sheet_name=\"BOARD_ALIGHT\", index=False)\n",
    "\n",
    "print(f\"âœ”ï¸ ì €ì¥ ì™„ë£Œ: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623d34b2",
   "metadata": {},
   "source": [
    "#### Journeys data ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23df60ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… journeys ì—´ì´ ì±„ì›Œì§„ íŒŒì¼: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_journeys.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "file_path   = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export.xlsx\")\n",
    "output_path = file_path.with_stem(file_path.stem + \"_with_journeys\")\n",
    "\n",
    "min_board   = 1      # ìŠ¹ì°¨ê°€ 0/ëˆ„ë½ì¸ ì—­ì— ë¶€ì—¬í•  ìµœì†Œ ìŠ¹ì°¨ ì¸ì›\n",
    "min_alight  = 1      # í•˜ì°¨ê°€ 0/ëˆ„ë½ì¸ ì—­ì— ë¶€ì—¬í•  ìµœì†Œ í•˜ì°¨ ì¸ì›\n",
    "epsilon_od  = 1      # ìœ íš¨ OD(ìŠ¹Â·í•˜ì°¨>0)ì— ì‹¬ì„ ìµœì†Œ í†µí–‰ëŸ‰\n",
    "max_iter    = 50\n",
    "eps_conv    = 1e-6\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. ë°ì´í„° ì½ê¸° -----------------------------------------------------------\n",
    "bal    = pd.read_excel(\n",
    "            file_path, sheet_name=\"BOARD_ALIGHT\",\n",
    "            usecols=[\"node_id\", \"board_1d\", \"alight_1d\"]\n",
    "        )\n",
    "demand = pd.read_excel(file_path, sheet_name=\"DEMAND\")\n",
    "\n",
    "# 1â€‘a. Origin / Destination â‡’ ì •ìˆ˜ node_id\n",
    "demand[\"O_id\"] = demand[\"Origin\"].str.lstrip(\"n\").astype(int)\n",
    "demand[\"D_id\"] = demand[\"Destination\"].str.lstrip(\"n\").astype(int)\n",
    "\n",
    "# 2. BOARD_ALIGHT ëˆ„ë½/ì¤‘ë³µ ì²˜ë¦¬ ------------------------------------------\n",
    "#   2â€‘a. ì¤‘ë³µ node_id í•©ì‚°\n",
    "bal_agg = (bal.groupby(\"node_id\", as_index=False)\n",
    "               .agg(board=(\"board_1d\", \"sum\"),\n",
    "                    alight=(\"alight_1d\", \"sum\")))\n",
    "\n",
    "#   2â€‘b. DEMAND ì— ë“±ì¥í•˜ì§€ë§Œ bal ì— ì—†ëŠ” ë…¸ë“œ ì¶”ê°€\n",
    "all_nodes = pd.unique(demand[[\"O_id\", \"D_id\"]].values.ravel())\n",
    "bal_full  = pd.DataFrame({\"node_id\": all_nodes}).merge(\n",
    "                bal_agg, on=\"node_id\", how=\"left\"\n",
    "            )\n",
    "\n",
    "#   2â€‘c. ìŠ¹Â·í•˜ì°¨ 0/NaN â†’ ìµœì†Œê°’ ì£¼ì…\n",
    "bal_full[\"board\"]  = pd.to_numeric(bal_full[\"board\"],  errors=\"coerce\").fillna(0)\n",
    "bal_full[\"alight\"] = pd.to_numeric(bal_full[\"alight\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "bal_full.loc[bal_full[\"board\"]  == 0, \"board\"]  = min_board\n",
    "bal_full.loc[bal_full[\"alight\"] == 0, \"alight\"] = min_alight\n",
    "\n",
    "# 3. ì´ ìŠ¹Â·í•˜ì°¨ëŸ‰ ë§¤í•‘ ------------------------------------------------------\n",
    "board_map  = bal_full.set_index(\"node_id\")[\"board\"].to_dict()\n",
    "alight_map = bal_full.set_index(\"node_id\")[\"alight\"].to_dict()\n",
    "\n",
    "demand[\"o_total\"] = demand[\"O_id\"].map(board_map)\n",
    "demand[\"d_total\"] = demand[\"D_id\"].map(alight_map)\n",
    "\n",
    "# 4. ì´ˆê¸° OD í–‰ë ¬ + Îµ ì£¼ì… ---------------------------------------------------\n",
    "f = 1.0 / demand[\"Timestep\"].replace(0, np.nan)\n",
    "demand[\"T\"] = (demand[\"o_total\"] * demand[\"d_total\"] * f).fillna(0.0)\n",
    "\n",
    "valid_od = (demand[\"o_total\"] > 0) & (demand[\"d_total\"] > 0)\n",
    "demand.loc[valid_od, \"T\"] += epsilon_od      # ìµœì†Œ í†µí–‰ëŸ‰ ì‹¬ê¸°\n",
    "\n",
    "# 5. IPF (Iterative Proportional Fitting) ----------------------------------\n",
    "for _ in range(max_iter):\n",
    "    row_sum = demand.groupby(\"O_id\")[\"T\"].transform(\"sum\").replace(0, np.nan)\n",
    "    demand[\"T\"] *= demand[\"o_total\"] / row_sum\n",
    "\n",
    "    col_sum = demand.groupby(\"D_id\")[\"T\"].transform(\"sum\").replace(0, np.nan)\n",
    "    demand[\"T\"] *= demand[\"d_total\"] / col_sum\n",
    "\n",
    "    if max((row_sum - demand[\"o_total\"]).abs().max(),\n",
    "           (col_sum - demand[\"d_total\"]).abs().max()) < eps_conv:\n",
    "        break\n",
    "\n",
    "# 6. journeys ê³„ì‚° ë° í›„ì²˜ë¦¬ -------------------------------------------------\n",
    "demand[\"journeys\"] = demand[\"T\"].round(0).astype(int)   # ì •ìˆ˜(ëª…)ë¡œ ë°˜ì˜¬ë¦¼\n",
    "out = demand.drop(columns=[\"O_id\", \"D_id\", \"o_total\", \"d_total\", \"T\"])\n",
    "\n",
    "# 7. ê²°ê³¼ ì €ì¥ --------------------------------------------------------------\n",
    "if output_path.exists():\n",
    "    mode, sheet_opt = \"a\", \"overlay\"\n",
    "else:\n",
    "    mode, sheet_opt = \"w\", None                 # ìƒˆ íŒŒì¼ â€” ì‹œíŠ¸ ì¡´ì¬ ì•ˆ í•˜ë¯€ë¡œ ì˜µì…˜ ë¶ˆí•„ìš”\n",
    "\n",
    "with pd.ExcelWriter(output_path,\n",
    "                    engine=\"openpyxl\",\n",
    "                    mode=mode,\n",
    "                    if_sheet_exists=sheet_opt) as wr:\n",
    "    out.to_excel(wr, sheet_name=\"DEMAND\", index=False)\n",
    "\n",
    "print(\"âœ… journeys ì—´ì´ ì±„ì›Œì§„ íŒŒì¼:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b83a59b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modified file saved to: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_journeys_fixed.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "file_path = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export.xlsx\")\n",
    "output_path = file_path.with_stem(file_path.stem + \"_journeys_fixed\")\n",
    "\n",
    "# DEMAND ì‹œíŠ¸ ì½ê¸°\n",
    "demand = pd.read_excel(file_path, sheet_name=\"DEMAND\")\n",
    "\n",
    "# journeys ì—´ì—ì„œ 0ì¸ ê°’ì„ 1ë¡œ ë³€ê²½\n",
    "demand[\"journeys\"] = demand[\"journeys\"].apply(lambda x: 1 if x == 0 else x)\n",
    "\n",
    "# ìƒˆ íŒŒì¼ë¡œ ì €ì¥\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    demand.to_excel(writer, sheet_name=\"DEMAND\", index=False)\n",
    "\n",
    "print(f\"âœ… Modified file saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf76e38",
   "metadata": {},
   "source": [
    "#### Convert to demand_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd98866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved successfully â†’ D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\5.demand_data_kofull.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "base_dir   = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "excel_path = base_dir / \"2.demand_data_with_journeys.xlsx\"\n",
    "json_path  = base_dir / \"5.demand_data_kofull.json\"\n",
    "\n",
    "cols = [\n",
    "    \"line\",          \n",
    "    \"origin\", \"destination\",\n",
    "    \"distance\", \"journeys\",\n",
    "    \"origin_name\", \"destination_name\"\n",
    "]\n",
    "\n",
    "df = pd.read_excel(excel_path, usecols=cols)\n",
    "\n",
    "df[\"distance\"] = df[\"distance\"].astype(float)\n",
    "df[\"journeys\"] = df[\"journeys\"].astype(float)\n",
    "\n",
    "records = df.to_dict(orient=\"records\")\n",
    "\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved successfully â†’ {json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4923f0e",
   "metadata": {},
   "source": [
    "#### Edgeë§ˆë‹¤ ê±¸ë¦¬ëŠ” ì‹œê°„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ca6d724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "travel time(minutes) ì¶”ê°€ í›„ ì €ì¥ ì™„ë£Œ â†’ D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\5.demand_data_kofull.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "base_dir   = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "json_path  = base_dir / \"5.demand_data_kofull.json\"\n",
    "\n",
    "speed_map = {\n",
    "    \"ê²½ê°•ì„ \": 250, \"ê²½ë¶€ê³ ì†ì² ë„\": 250, \"ê²½ë¶€ì„ \": 200, \"ê²½ë¶ì„ \": 150,\n",
    "    \"ê²½ì˜ì„ \": 110, \"ê²½ì¸ì„ \": 110, \"ê²½ì „ì„ \": 230, \"ê³µí•­ì² ë„\": 110,\n",
    "    \"ëŒ€êµ¬ì„ \": 230, \"ë™í•´ë‚¨ë¶€ì„ \": 110, \"ë™í•´ì„ \": 200, \"ì‚¼ì²™ì„ \": 110,\n",
    "    \"ì˜ë™ì„ \": 110, \"ì¥í•­ì„ \": 110, \"ì „ë¼ì„ \": 230, \"ì¤‘ë¶€ë‚´ë¥™ì„ \": 230,\n",
    "    \"ì¤‘ì•™ì„ \": 110, \"ì¶©ë¶ì„ \": 150, \"íƒœë°±ì„ \": 110, \"í˜¸ë‚¨ê³ ì†ì² ë„\": 300,\n",
    "    \"í˜¸ë‚¨ì„ \": 150, \"KTXê°•ë¦‰ì„ \": 250, \"KTXë™í•´ì„ \": 200\n",
    "}  # km/h\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    records = json.load(f)\n",
    "\n",
    "for rec in records:\n",
    "    line = rec[\"line\"].replace(\" \", \"\")        \n",
    "    v_kmh = speed_map.get(line, None)\n",
    "    if v_kmh is None:\n",
    "        raise KeyError(f\"ì†ë„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {line}\")\n",
    "    rec[\"time_min\"] = int(round(rec[\"distance\"] * 60 / (v_kmh * 1000)))\n",
    "\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"travel time(minutes) ì¶”ê°€ í›„ ì €ì¥ ì™„ë£Œ â†’ {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e82bbb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ 'time_min' ë²”ìœ„: 1 ~ 770 ë¶„\n",
      "ğŸ“Š 60ë¶„ ë‹¨ìœ„ êµ¬ê°„ ë¹ˆë„:\n",
      "[0, 60)       : 524ê°œ\n",
      "[60, 120)     : 196ê°œ\n",
      "[120, 180)    : 82ê°œ\n",
      "[180, 240)    : 38ê°œ\n",
      "[240, 300)    : 36ê°œ\n",
      "[300, 360)    : 32ê°œ\n",
      "[360, 420)    : 32ê°œ\n",
      "[420, 480)    : 26ê°œ\n",
      "[480, 540)    : 20ê°œ\n",
      "[540, 600)    : 14ê°œ\n",
      "[600, 660)    : 10ê°œ\n",
      "[660, 720)    : 8ê°œ\n",
      "[720, 780)    : 4ê°œ\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "file_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\5.demand_data_kofull.json\"\n",
    "\n",
    "# JSON ë¡œë“œ â†’ DataFrame\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    records = json.load(f)\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# ìµœì†ŒÂ·ìµœëŒ€ time_min\n",
    "t_min = df[\"time_min\"].min()\n",
    "t_max = df[\"time_min\"].max()\n",
    "\n",
    "# 0, 60, 120, â€¦, (ceil(t_max/60)+1)*60\n",
    "upper_bound = int(math.ceil(t_max / 60) * 60)\n",
    "bin_edges = list(range(0, upper_bound + 60, 60))  # 0â€†,60â€†,â€¦,upper_bound+60\n",
    "\n",
    "# êµ¬ê°„ ìë¥´ê¸°\n",
    "df[\"time_bin\"] = pd.cut(df[\"time_min\"], bins=bin_edges, right=False)  # [ ) í˜•íƒœ\n",
    "\n",
    "# ë¹ˆë„ìˆ˜\n",
    "hist = df[\"time_bin\"].value_counts().sort_index()\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ğŸ”¹ 'time_min' ë²”ìœ„: {t_min} ~ {t_max} ë¶„\")\n",
    "print(\"ğŸ“Š 60ë¶„ ë‹¨ìœ„ êµ¬ê°„ ë¹ˆë„:\")\n",
    "for interval, count in hist.items():\n",
    "    print(f\"{str(interval).ljust(14)}: {count}ê°œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb134c89",
   "metadata": {},
   "source": [
    "#### Capacity\n",
    "- Demand_dataì´ìš©í•´ì„œ ì—£ì§€ë§ˆë‹¤ íë¥´ëŠ” demandì–‘ ê³„ì‚°í•œ íŒŒì¼: 6.edge_journeys_summary.xlsx\n",
    "- e1 n1-n2 1502241\n",
    "- e2 n2-n1 389459.5\n",
    "- e1,e2,e3,e4, .. ë„˜ë²„ë§ qgisì™€ ë‹¤ë¦„ (ì–‘ë°©í–¥ ê³ ë ¤)\n",
    "- ì–‘ë°©í–¥ ì—£ì§€ì— ëŒ€í•´ì„œëŠ” ì„œë¡œ ë™ì¼í•œ capacityë¥¼ ê°–ë„ë¡ í•´ì•¼í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060b668f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capacity summary saved â†’ D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\7.edge_capacity_summary.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "input_path = base_dir / \"6.edge_journeys_summary.xlsx\"\n",
    "df = pd.read_excel(input_path)\n",
    "\n",
    "# 2. ì—¬ìœ  ê³„ìˆ˜ ì„¤ì • (ì˜ˆ: 1.2ë°°)\n",
    "buffer_ratio = 1.2\n",
    "\n",
    "# 3. (u, v) / (v, u) í˜•íƒœë¥¼ ê³ ë ¤í•´ ì–‘ë°©í–¥ í‚¤ ë§Œë“¤ê¸°\n",
    "df[\"pair_key\"] = df.apply(lambda row: tuple(sorted([row[\"from_node_name\"], row[\"to_node_name\"]])), axis=1)\n",
    "\n",
    "# 4. ê°™ì€ pair_key ê·¸ë£¹ ë‚´ì—ì„œ ìµœëŒ€ journeys ì„ íƒ\n",
    "grouped = df.groupby(\"pair_key\", as_index=False).agg({\n",
    "    \"journeys\": \"max\"\n",
    "})\n",
    "grouped[\"capacity\"] = grouped[\"journeys\"] * buffer_ratio\n",
    "\n",
    "# 5. ë‹¤ì‹œ ì›ë˜ ë°©í–¥ì„± edgeì— capacity ì—°ê²°\n",
    "df = df.merge(grouped[[\"pair_key\", \"capacity\"]], on=\"pair_key\", how=\"left\")\n",
    "\n",
    "# 6. ì»¬ëŸ¼ ì •ë¦¬ ë° ì €ì¥\n",
    "df = df.drop(columns=[\"pair_key\"])\n",
    "output_path = base_dir / \"7.edge_capacity_summary.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Capacity summary saved â†’ {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc815f",
   "metadata": {},
   "source": [
    "#### ë…¸ì„ ë³„ ìŠ¹ê° ìˆ˜ìš” ë°ì´í„° -> í•„ìš”í•œ ê¸°ì°¨ìˆ˜ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01187308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      line  cycles_day  train_sets_needed\n",
      "0   KTXê°•ë¦‰ì„           24                  1\n",
      "1   KTXë™í•´ì„           39                  1\n",
      "2      ê²½ê°•ì„           23                  2\n",
      "3   ê²½ë¶€ê³ ì†ì² ë„           8                 23\n",
      "4      ê²½ë¶€ì„            1                 65\n",
      "5      ê²½ë¶ì„           18                  1\n",
      "6      ê²½ì˜ì„           46                  1\n",
      "7      ê²½ì¸ì„           35                  1\n",
      "8      ê²½ì „ì„            5                  3\n",
      "9     ê³µí•­ì² ë„          20                  2\n",
      "10     ëŒ€êµ¬ì„           44                  1\n",
      "11   ë™í•´ë‚¨ë¶€ì„           12                  3\n",
      "12     ë™í•´ì„           16                  1\n",
      "13     ì‚¼ì²™ì„           51                  1\n",
      "14     ì˜ë™ì„           12                  2\n",
      "15     ì¥í•­ì„           11                  2\n",
      "16     ì „ë¼ì„           17                  2\n",
      "17   ì¤‘ë¶€ë‚´ë¥™ì„           36                  1\n",
      "18     ì¤‘ì•™ì„            2                 23\n",
      "19     ì¶©ë¶ì„           11                  1\n",
      "20     íƒœë°±ì„           19                  1\n",
      "21  í˜¸ë‚¨ê³ ì†ì² ë„          20                  1\n",
      "22     í˜¸ë‚¨ì„           10                  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minji Kang\\AppData\\Local\\Temp\\ipykernel_38976\\2930921966.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  result = df.groupby(\"line\").apply(train_stats).reset_index()\n"
     ]
    }
   ],
   "source": [
    "import json, math, pandas as pd, os\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. íŒŒì¼ ì½ê¸°\n",
    "file_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\5.demand_data_kofull.json\"\n",
    "df = pd.read_json(file_path)\n",
    "df[\"journeys_day\"] = df[\"journeys\"] / 365\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. íŒŒë¼ë¯¸í„°\n",
    "TARGET_LOAD    = 1.0          # 100 % íƒ‘ìŠ¹ë¥ \n",
    "TURNAROUND_MIN = 15           # ì¢…ì  ë²„í¼(ë¶„)\n",
    "HOURS_PER_DAY  = 17\n",
    "DEFAULT_SEAT   = 400          # seat_map ì— ì—†ì„ ë•Œ ì„ì‹œê°’\n",
    "\n",
    "# ë…¸ì„ ë³„ ì¢Œì„ìˆ˜ (ì• ê¸€ì ë§¤ì¹­ìš©)\n",
    "seat_map = {\n",
    "    # ê³ ì†ì—´ì°¨\n",
    "    \"KTXê°•ë¦‰ì„ \":    381,   # KTX-ì´ìŒ (KTX-Eum) 381ì„ :contentReference[oaicite:2]{index=2}\n",
    "    \"KTXê²½ë¶€ì„ \":    955,   # KTX-I 955ì„(935~955) :contentReference[oaicite:3]{index=3}\n",
    "    \"KTXí˜¸ë‚¨ì„ \":    955,\n",
    "    \"ê²½ë¶€ê³ ì†ì² ë„\":   955,   # KTX-ì‚°ì²œ\n",
    "    \"ê²½ë¶€ì„ \":         900,   # SRT í¸ì„±(ì˜ˆì‹œ)\n",
    "    # ITX ê³„ì—´\n",
    "    \"ITX-ìƒˆë§ˆì„\":   376,   # ITX-ìƒˆë§ˆì„\n",
    "    \"ITX-ì²­ì¶˜\":     402,   # ITX-ì²­ì¶˜\n",
    "    # ì¼ë°˜ì—´ì°¨\n",
    "    \"ë¬´ê¶í™”í˜¸\":     920,   # ì¢Œì„+ì…ì„ í—ˆìš©, í¸ì„± ì¢Œì„ 920 ë¶€ê·¼\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def train_stats(group):\n",
    "    line = group.name\n",
    "    seats = next((v for k, v in seat_map.items() if line.startswith(k)), DEFAULT_SEAT)\n",
    "\n",
    "    total_pax = group[\"journeys_day\"].sum()\n",
    "    single_run = group[\"time_min\"].max()\n",
    "    round_trip = single_run + TURNAROUND_MIN\n",
    "    cycles = max(1, (HOURS_PER_DAY * 60) // round_trip)\n",
    "\n",
    "    cap_per_set = seats * TARGET_LOAD * cycles\n",
    "    sets_needed = math.ceil(total_pax / cap_per_set) if cap_per_set else None\n",
    "\n",
    "    return pd.Series({\n",
    "        \"cycles_day\": cycles,\n",
    "        \"train_sets_needed\": sets_needed\n",
    "    })\n",
    "\n",
    "# 4. ê³„ì‚°\n",
    "result = df.groupby(\"line\").apply(train_stats).reset_index()\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mjkang",
   "language": "python",
   "name": "mjkang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
