{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c9612c",
   "metadata": {},
   "source": [
    "#### QGIS -> demand \n",
    "ë…¸ì„ ë³„ë¡œ ê²½ë¡œ ìƒì„±\n",
    "distance ë°ì´í„° ë„£ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab9b4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ ë…¸ì„ ë³„ ë‹¨ì¼ ê²½ë¡œ (ë°©í–¥ ë¬´ì‹œ)\n",
      "KTXê°•ë¦‰ì„ : [22, 23, 34, 51]\n",
      "ê²½ë¶€ê³ ì†ì² ë„: [4, 3, 1, 2, 13, 18, 28, 42, 60, 72, 75, 79]\n",
      "ê²½ë¶€ì„ : [79, 77, 76, 73, 70, 63, 60, 59, 46, 41, 28, 17, 14, 9, 7, 1, 4]\n",
      "ê²½ë¶ì„ : [41, 38, 36, 40, 43]\n",
      "ê²½ì „ì„ : [48, 57, 64, 65, 62, 66, 71, 73]\n",
      "ë™í•´ì„ : [55, 58, 69, 74, 72]\n",
      "ì˜ë™ì„ : [51, 55, 54, 50, 43]\n",
      "ì¥í•­ì„ : [14, 11, 10, 15, 16, 27, 30]\n",
      "ì „ë¼ì„ : [68, 62, 56, 47, 45, 33, 30]\n",
      "ì¤‘ì•™ì„ : [3, 5, 6, 8, 12, 22, 29, 31, 35, 39, 43, 49, 52, 67, 72, 78, 79]\n",
      "ì¶©ë¶ì„ : [17, 18, 19, 20, 26, 29]\n",
      "í˜¸ë‚¨ê³ ì†ì² ë„: [48, 37, 30, 21, 18, 13, 2, 1, 3]\n",
      "í˜¸ë‚¨ì„ : [61, 53, 48, 44, 37, 32, 30, 24, 25, 28]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. íŒŒì¼ ê²½ë¡œ\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "xlsx_path = base_path + r\"\\qgis_export.xlsx\"\n",
    "sheet_name = \"LINE\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "df = pd.read_excel(xlsx_path, sheet_name=sheet_name)\n",
    "df = df.dropna(subset=[\"from_node_\", \"to_node_id\"])\n",
    "df[\"from_node_\"] = df[\"from_node_\"].astype(int)\n",
    "df[\"to_node_id\"] = df[\"to_node_id\"].astype(int)\n",
    "\n",
    "print(\"ğŸ“Œ ë…¸ì„ ë³„ ë‹¨ì¼ ê²½ë¡œ (ë°©í–¥ ë¬´ì‹œ)\")\n",
    "for line, group in df.groupby(\"RLWAY_NM\"):\n",
    "    # ì–‘ë°©í–¥ ê·¸ë˜í”„ ìƒì„±\n",
    "    graph = defaultdict(list)\n",
    "    for u, v in zip(group[\"from_node_\"], group[\"to_node_id\"]):\n",
    "        graph[u].append(v)\n",
    "        graph[v].append(u)\n",
    "\n",
    "    # ë…¸ë“œ ì—°ê²° ìƒíƒœ ì§„ë‹¨\n",
    "    degree = {n: len(adj) for n, adj in graph.items()}\n",
    "    endpoints = [n for n, d in degree.items() if d == 1]\n",
    "    if len(endpoints) != 2:\n",
    "        print(f\"âš ï¸ {line}: ì„ í˜• ê²½ë¡œ ì•„ë‹˜ (ë ë…¸ë“œ {len(endpoints)}ê°œ)\")\n",
    "        continue\n",
    "\n",
    "    # í•œìª½ ëì—ì„œë¶€í„° BFSë¡œ ê²½ë¡œ ë³µì›\n",
    "    start = endpoints[0]\n",
    "    visited = set()\n",
    "    path = []\n",
    "\n",
    "    def dfs(u):\n",
    "        visited.add(u)\n",
    "        path.append(u)\n",
    "        for v in graph[u]:\n",
    "            if v not in visited:\n",
    "                dfs(v)\n",
    "\n",
    "    dfs(start)\n",
    "    print(f\"{line}: {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef1b54",
   "metadata": {},
   "source": [
    "#### EDGE timestep ë°ì´í„° ë§Œë“¤ê¸° ìœ„í•´\n",
    "- distanceë¡œ ì´ë™ì‹œê°„\n",
    "- ì´ë™ì‹œê°„ ê¸°ë°˜ time step ê³„ì‚°\n",
    "- EDGE ë°ì´í„° .json íŒŒì¼ë¡œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f068c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì™„ë£Œ: time_step ì—´ì´ ì¶”ê°€ëœ íŒŒì¼ì´ ì €ì¥ë¨ â†’\n",
      "D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_time.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "input_file  = base_path + r\"\\qgis_export.xlsx\"\n",
    "output_file = base_path + r\"\\qgis_export_with_time.xlsx\"\n",
    "sheet_name  = \"EDGE\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. ì›ë³¸ ì—‘ì…€ ì „ì²´ ì½ê¸° (ëª¨ë“  ì‹œíŠ¸ ë³´ì¡´ ëª©ì )\n",
    "xlsx_all = pd.read_excel(input_file, sheet_name=None)\n",
    "\n",
    "# 2. EDGE ì‹œíŠ¸ë§Œ ìˆ˜ì •\n",
    "df_edge = xlsx_all[sheet_name]\n",
    "\n",
    "# 3. time_step ê³„ì‚°\n",
    "if 'distance' not in df_edge.columns:\n",
    "    raise ValueError(\"'distance' ì—´ì´ EDGE ì‹œíŠ¸ì— ì—†ìŠµë‹ˆë‹¤.\")\n",
    "df_edge['time_step'] = df_edge['distance'] / 150 * 60\n",
    "\n",
    "# 4. ìˆ˜ì •í•œ EDGE ì‹œíŠ¸ ë‹¤ì‹œ ë„£ê¸°\n",
    "xlsx_all[sheet_name] = df_edge\n",
    "\n",
    "# 5. ì „ì²´ ì‹œíŠ¸ë¥¼ ìƒˆ íŒŒì¼ë¡œ ì €ì¥\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    for sheet, df in xlsx_all.items():\n",
    "        df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "\n",
    "print(f\"âœ… ì™„ë£Œ: time_step ì—´ì´ ì¶”ê°€ëœ íŒŒì¼ì´ ì €ì¥ë¨ â†’\\n{output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb45211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì™„ë£Œ: 'time_step' ê³„ì‚° í›„ ì €ì¥ë¨ â†’\n",
      "D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_step.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "input_file  = base_path + r\"\\qgis_export_with_time.xlsx\"\n",
    "output_file = base_path + r\"\\qgis_export_with_step.xlsx\"\n",
    "sheet_name  = \"EDGE\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. ëª¨ë“  ì‹œíŠ¸ ì½ê¸°\n",
    "xlsx_all = pd.read_excel(input_file, sheet_name=None)\n",
    "\n",
    "# 2. EDGE ì‹œíŠ¸ ìˆ˜ì •\n",
    "df_edge = xlsx_all[sheet_name]\n",
    "\n",
    "# 3. time_step ê³„ì‚° (5ë¡œ ë‚˜ëˆ„ê³  ì˜¬ë¦¼)\n",
    "if 'time(min)' not in df_edge.columns:\n",
    "    raise ValueError(\"'time(min)' ì—´ì´ EDGE ì‹œíŠ¸ì— ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "df_edge['time_step'] = df_edge['time(min)'].apply(lambda x: math.ceil(x / 5))\n",
    "\n",
    "# 4. ë®ì–´ì“°ê¸°\n",
    "xlsx_all[sheet_name] = df_edge\n",
    "\n",
    "# 5. ìƒˆ íŒŒì¼ë¡œ ì €ì¥\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    for sheet, df in xlsx_all.items():\n",
    "        df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "\n",
    "print(f\"âœ… ì™„ë£Œ: 'time_step' ê³„ì‚° í›„ ì €ì¥ë¨ â†’\\n{output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072ab939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì •ë ¬ëœ edges.json ì €ì¥ ì™„ë£Œ â†’\n",
      "D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\edges.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "input_file  = os.path.join(base_path, \"qgis_export_with_step.xlsx\")\n",
    "sheet_name  = \"EDGE\"\n",
    "output_json = os.path.join(base_path, \"edges.json\")\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_excel(input_file, sheet_name=sheet_name)\n",
    "\n",
    "# 2. í•„ìš”í•œ ì—´ í™•ì¸\n",
    "required_cols = ['edge_id', 'from_node_id', 'to_node_id', 'time_step']\n",
    "missing = set(required_cols) - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"ë‹¤ìŒ ì—´ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing}\")\n",
    "\n",
    "# 3. ì •ìˆ˜í˜• edge_id ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
    "df = df.dropna(subset=['edge_id'])\n",
    "df['edge_id'] = df['edge_id'].astype(int)\n",
    "df = df.sort_values(by='edge_id')\n",
    "\n",
    "# 4. edge ë”•ì…”ë„ˆë¦¬ ìƒì„± (OrderedDictë¡œ ìˆœì„œ ìœ ì§€)\n",
    "edges = OrderedDict()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    eid = f\"e{int(row['edge_id'])}\"\n",
    "    n_from = f\"n{int(row['from_node_id'])}\"\n",
    "    n_to   = f\"n{int(row['to_node_id'])}\"\n",
    "    tstep  = int(row['time_step'])\n",
    "\n",
    "    edges[eid] = (n_from, n_to, tstep)\n",
    "\n",
    "# 5. JSON ì €ì¥\n",
    "with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(edges, f, indent=4)\n",
    "\n",
    "print(f\"âœ… ì •ë ¬ëœ edges.json ì €ì¥ ì™„ë£Œ â†’\\n{output_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0837e648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\routes_nodes.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "xlsx_file = os.path.join(base_path, \"qgis_export_with_step.xlsx\")\n",
    "sheet_name = \"TRAIN\"\n",
    "output_json = os.path.join(base_path, \"routes_nodes.json\")\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. TRAIN ì‹œíŠ¸ ì½ê¸°\n",
    "df = pd.read_excel(xlsx_file, sheet_name=sheet_name)\n",
    "\n",
    "# 2. routes_nodes ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "routes_nodes = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    name = str(row[\"RLWAY_NM\"]).strip()\n",
    "    nodes_str = str(row[\"NODE\"]).strip()\n",
    "\n",
    "    # ë…¸ë“œ ë¬¸ìì—´ íŒŒì‹± â†’ ['n4', 'n3', 'n1', ...]\n",
    "    node_list = [f\"n{int(n)}\" for n in nodes_str.split(\"-\") if n.isdigit()]\n",
    "\n",
    "    # ì •ë°©í–¥ ë° ì—­ë°©í–¥ ì €ì¥\n",
    "    routes_nodes[f\"{name}1\"] = node_list\n",
    "    routes_nodes[f\"{name}2\"] = node_list[::-1]\n",
    "\n",
    "# 3. JSON ì €ì¥\n",
    "with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(routes_nodes, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ: {output_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ea2954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì–‘ë°©í–¥ edges ì €ì¥ ì™„ë£Œ: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\edges_bidirectional.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "input_json = os.path.join(base_path, \"edges.json\")\n",
    "output_json = os.path.join(base_path, \"edges_bidirectional.json\")\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. ê¸°ì¡´ edges.json ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open(input_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    edges = json.load(f)\n",
    "\n",
    "# 2. ì–‘ë°©í–¥ ë”•ì…”ë„ˆë¦¬ ìƒì„± (ìˆœì„œ ë³´ì¡´)\n",
    "edges_bidir = OrderedDict()\n",
    "\n",
    "for eid, (n1, n2, t) in edges.items():\n",
    "    # ì •ë°©í–¥ edge ì¶”ê°€\n",
    "    edges_bidir[eid] = [n1, n2, t]\n",
    "    \n",
    "    # ì—­ë°©í–¥ edge ì¶”ê°€\n",
    "    eid_r = f\"{eid}r\"\n",
    "    edges_bidir[eid_r] = [n2, n1, t]\n",
    "\n",
    "# 3. ìƒˆ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(edges_bidir, f, indent=4)\n",
    "\n",
    "print(f\"âœ… ì–‘ë°©í–¥ edges ì €ì¥ ì™„ë£Œ: {output_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9416e8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… demand_template.json ì €ì¥ ì™„ë£Œ â†’\n",
      "D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\demand_template.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "routes_json = os.path.join(base_path, \"routes_nodes.json\")\n",
    "output_demand_json = os.path.join(base_path, \"demand_template.json\")\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. routes_nodes.json ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open(routes_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    routes_nodes = json.load(f)\n",
    "\n",
    "# 2. demand ìƒì„±\n",
    "demand = {}\n",
    "\n",
    "for tr, path in routes_nodes.items():\n",
    "    od_list = []\n",
    "    for i in range(len(path)-1):\n",
    "        for j in range(i+1, len(path)):\n",
    "            o, d = path[i], path[j]\n",
    "            od_list.append((o, d, None))  # ìˆ˜ìš”ëŠ” ì•„ì§ ì—†ìŒ\n",
    "    demand[tr] = od_list\n",
    "\n",
    "# 3. ì €ì¥\n",
    "with open(output_demand_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(demand, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… demand_template.json ì €ì¥ ì™„ë£Œ â†’\\n{output_demand_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42781bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë¨ â†’ D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\demand_template_compact.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\"\n",
    "input_file  = os.path.join(base_path, \"demand_template.json\")\n",
    "output_file = os.path.join(base_path, \"demand_template_compact.json\")\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    demand = json.load(f)\n",
    "\n",
    "# 2. ì €ì¥ (ìˆ˜ë™ ë¬¸ìì—´ í¬ë§·)\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"{\\n\")\n",
    "    for i, (k, od_list) in enumerate(demand.items()):\n",
    "        f.write(f'    \"{k}\": [\\n')\n",
    "        line = \"        \"  # ë“¤ì—¬ì“°ê¸° ì‹œì‘\n",
    "        for j, od in enumerate(od_list):\n",
    "            # JSON ê°’ìœ¼ë¡œ ì¸ì½”ë”© (ensure null/quote ë“± ë§ì¶¤)\n",
    "            od_json = json.dumps(od, ensure_ascii=False)\n",
    "            line += od_json\n",
    "            if j < len(od_list) - 1:\n",
    "                line += \", \"\n",
    "            if len(line) > 120:\n",
    "                f.write(line + \"\\n\")\n",
    "                line = \"        \"\n",
    "        if line.strip():\n",
    "            f.write(line + \"\\n\")\n",
    "        f.write(\"    ]\")\n",
    "        if i < len(demand) - 1:\n",
    "            f.write(\",\\n\")\n",
    "        else:\n",
    "            f.write(\"\\n\")\n",
    "    f.write(\"}\\n\")\n",
    "\n",
    "print(f\"âœ… ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë¨ â†’ {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2836b",
   "metadata": {},
   "source": [
    "#### ì—­ì‚¬ë³„ ìŠ¹í•˜ì°¨ë°ì´í„°ë¡œ ì„ì‹œ journeys demand data ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6238ff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ ë‘˜ ë‹¤ í¬í•¨ëœ ì—­ (matched):\n",
      " - ê²½ì‚°ì—­\n",
      " - ê³„ë£¡ì—­\n",
      " - ê³¡ì„±ì—­\n",
      " - ê³µì£¼ì—­\n",
      " - ê´‘ëª…ì—­\n",
      " - ê´‘ì£¼ì†¡ì •ì—­\n",
      " - ê´‘ì²œì—­\n",
      " - êµ¬ë¡€êµ¬ì—­\n",
      " - êµ¬ë¯¸ì—­\n",
      " - êµ¬í¬ì—­\n",
      " - ê¸°ì¥ì—­\n",
      " - ê¹€ì œì—­\n",
      " - ê¹€ì²œêµ¬ë¯¸ì—­\n",
      " - ê¹€ì²œì—­\n",
      " - ë‚˜ì£¼ì—­\n",
      " - ë‚¨ì›ì—­\n",
      " - ë…¼ì‚°ì—­\n",
      " - ëŠ¥ì£¼ì—­\n",
      " - ë‹¨ì–‘ì—­\n",
      " - ëŒ€êµ¬ì—­\n",
      " - ëŒ€ì „ì—­\n",
      " - ëŒ€ì²œì—­\n",
      " - ë•ì†Œì—­\n",
      " - ë™ëŒ€êµ¬ì—­\n",
      " - ë™í•´ì—­\n",
      " - ë§ˆì‚°ì—­\n",
      " - ëª©í¬ì—­\n",
      " - ë¬¼ê¸ˆì—­\n",
      " - ë°€ì–‘ì—­\n",
      " - ë²Œêµì—­\n",
      " - ë³´ì„±ì—­\n",
      " - ë´‰ì–‘ì—­\n",
      " - ë¶€ì‚°ì—­\n",
      " - ì‚¼ë‘ì§„ì—­\n",
      " - ìƒë´‰ì—­\n",
      " - ìƒì£¼ì—­\n",
      " - ì„œìš¸ì—­\n",
      " - ì„œì°½ì—­\n",
      " - ìˆ˜ì›ì—­\n",
      " - ìˆœì²œì—­\n",
      " - ì•ˆë™ì—­\n",
      " - ì–‘í‰ì—­\n",
      " - ì—¬ìˆ˜ì—‘ìŠ¤í¬ì—­\n",
      " - ì˜ë•ì—­\n",
      " - ì˜ë“±í¬ì—­\n",
      " - ì˜ì£¼ì—­\n",
      " - ì˜ì²œì—­\n",
      " - ì˜ˆì‚°ì—­\n",
      " - ì˜ˆì²œì—­\n",
      " - ì˜¤ì†¡ì—­\n",
      " - ì˜¨ì–‘ì˜¨ì²œì—­\n",
      " - ìš©ì‚°ì—­\n",
      " - ìš¸ì‚°ì—­\n",
      " - ì›ì£¼ì—­\n",
      " - ì˜ì„±ì—­\n",
      " - ìµì‚°ì—­\n",
      " - ì¥ì„±ì—­\n",
      " - ì¥í•­ì—­\n",
      " - ì „ì£¼ì—­\n",
      " - ì ì´Œì—­\n",
      " - ì •ë™ì§„ì—­\n",
      " - ì •ìì—­\n",
      " - ì œì²œì—­\n",
      " - ì§„ì£¼ì—­\n",
      " - ì²œì•ˆì—­\n",
      " - ì²­ëŸ‰ë¦¬ì—­\n",
      " - ì²­ì£¼ì—­\n",
      " - ì¶˜ì–‘ì—­\n",
      " - ì¶©ì£¼ì—­\n",
      " - íƒœí™”ê°•ì—­\n",
      " - í‰ì°½ì—­\n",
      " - í‰íƒì—­\n",
      " - í¬í•­ì—­\n",
      " - í’ê¸°ì—­\n",
      " - íš¡ì„±ì—­\n",
      "\n",
      "ğŸ“Œ QGISì—ëŠ” ìˆìœ¼ë‚˜ ìŠ¹í•˜ì°¨ ë°ì´í„°ì—ëŠ” ì—†ëŠ” ì—­ (only_in_qgis):\n",
      " - ë°±ì‚°ì—­\n",
      " - ë³´ì²œì—­\n",
      " - ì‚¼ì²™ì—­\n",
      " - ì‹ ê²½ì£¼ì—­\n",
      " - ì²œì•ˆì•„ì‚°ì—­(ì˜¨ì–‘ì˜¨ì²œ)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "qgis_path = base_dir / \"qgis_export_with_step.xlsx\"\n",
    "ridership_path = base_dir / \"station_ridership.xlsx\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. QGIS NODE ë°ì´í„°ì—ì„œ RLNODE_NM ì¶”ì¶œ\n",
    "qgis_df = pd.read_excel(qgis_path, sheet_name=\"NODE\")\n",
    "qgis_nodes = qgis_df[\"RLNODE_NM\"].astype(str).str.strip()\n",
    "\n",
    "# 2. ìŠ¹í•˜ì°¨ ë°ì´í„°ì—ì„œ RLNODE_NM ì¶”ì¶œ (Eì—´)\n",
    "ridership_df = pd.read_excel(ridership_path)\n",
    "ridership_nodes = ridership_df[\"RLNODE_NM\"].astype(str).str.strip()\n",
    "\n",
    "# 3. ë¹„êµ\n",
    "matched = sorted(set(qgis_nodes) & set(ridership_nodes))\n",
    "only_in_qgis = sorted(set(qgis_nodes) - set(ridership_nodes))\n",
    "\n",
    "# 4. ì¶œë ¥\n",
    "print(\"ğŸ“Œ ë‘˜ ë‹¤ í¬í•¨ëœ ì—­ (matched):\")\n",
    "for name in matched:\n",
    "    print(f\" - {name}\")\n",
    "\n",
    "print(\"\\nğŸ“Œ QGISì—ëŠ” ìˆìœ¼ë‚˜ ìŠ¹í•˜ì°¨ ë°ì´í„°ì—ëŠ” ì—†ëŠ” ì—­ (only_in_qgis):\")\n",
    "for name in only_in_qgis:\n",
    "    print(f\" - {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4518b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ”ï¸ ì €ì¥ ì™„ë£Œ: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_ridership.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "xlsx_path = base_dir / \"qgis_export_with_step.xlsx\"\n",
    "output_path = base_dir / \"qgis_export_with_ridership.xlsx\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. NODE ì‹œíŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "node_df = pd.read_excel(xlsx_path, sheet_name=\"NODE\")\n",
    "\n",
    "# 2. BOARD,ALIGHT ì‹œíŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "ridership_df = pd.read_excel(xlsx_path, sheet_name=\"BOARD,ALIGHT\")\n",
    "\n",
    "# 3. RLNODE_NM ê¸°ì¤€ ë³‘í•©\n",
    "merged_df = node_df.merge(\n",
    "    ridership_df[[\"RLNODE_NM\", \"board_1d\", \"alight_1d\"]],\n",
    "    on=\"RLNODE_NM\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 4. ìƒˆë¡œìš´ íŒŒì¼ë¡œ ì €ì¥\n",
    "merged_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"âœ”ï¸ ì €ì¥ ì™„ë£Œ: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13186668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ”ï¸ ì €ì¥ ì™„ë£Œ: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_timestep.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "xlsx_path = base_dir / \"qgis_export.xlsx\"\n",
    "output_path = base_dir / \"qgis_export_with_timestep.xlsx\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. ì—£ì§€ ì •ë³´ ì½ê¸°\n",
    "edge_df = pd.read_excel(xlsx_path, sheet_name=\"EDGE\")\n",
    "edge_df[\"from_node_id\"] = edge_df[\"from_node_id\"].astype(str).str.lower()\n",
    "edge_df[\"to_node_id\"] = edge_df[\"to_node_id\"].astype(str).str.lower()\n",
    "\n",
    "# 2. demand íƒ­ ì½ê¸°\n",
    "demand_df = pd.read_excel(xlsx_path, sheet_name=\"DEMAND\")\n",
    "\n",
    "# 3. Route ê¸°ë°˜ Timestep ê³„ì‚° í•¨ìˆ˜\n",
    "def compute_total_timestep(route_str):\n",
    "    if pd.isna(route_str):\n",
    "        return None\n",
    "    nodes = route_str.strip().split(\"-\")\n",
    "    total_time = 0\n",
    "    for i in range(len(nodes) - 1):\n",
    "        from_n = nodes[i].replace(\"n\", \"\")\n",
    "        to_n = nodes[i+1].replace(\"n\", \"\")\n",
    "\n",
    "        # í•´ë‹¹ fromâ†”toì— í•´ë‹¹í•˜ëŠ” time_step ì°¾ê¸°\n",
    "        match = edge_df[\n",
    "            ((edge_df[\"from_node_id\"] == from_n) & (edge_df[\"to_node_id\"] == to_n)) |\n",
    "            ((edge_df[\"from_node_id\"] == to_n) & (edge_df[\"to_node_id\"] == from_n))\n",
    "        ]\n",
    "\n",
    "        if match.empty:\n",
    "            return None  # í•´ë‹¹ êµ¬ê°„ ì •ë³´ ì—†ìŒ\n",
    "        total_time += match.iloc[0][\"time_step\"]\n",
    "    return total_time\n",
    "\n",
    "# 4. Timestep ê³„ì‚° ë° ì—´ ì¶”ê°€\n",
    "demand_df[\"Timestep\"] = demand_df[\"Route\"].apply(compute_total_timestep)\n",
    "\n",
    "# 5. ì €ì¥\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "    demand_df.to_excel(writer, sheet_name=\"DEMAND\", index=False)\n",
    "\n",
    "print(f\"âœ”ï¸ ì €ì¥ ì™„ë£Œ: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3eb01c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\demand_with_route_filled.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "base_path = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "file_path = base_path / \"qgis_export.xlsx\"\n",
    "\n",
    "# ì—‘ì…€ íŒŒì¼ ì½ê¸°\n",
    "train_df = pd.read_excel(file_path, sheet_name=\"TRAIN\")\n",
    "demand_df = pd.read_excel(file_path, sheet_name=\"DEMAND\")\n",
    "\n",
    "# ë…¸ì„  ì´ë¦„ â†’ ë…¸ë“œ ê²½ë¡œ dict (n ì ‘ë‘ì–´ ë¶™ì´ê¸°)\n",
    "line_routes = {}\n",
    "for _, row in train_df.iterrows():\n",
    "    line_name = row[\"RLWAY_NM\"].strip()\n",
    "    node_seq = [f\"n{n.strip()}\" for n in str(row[\"NODE\"]).split(\"-\")]\n",
    "    line_routes[line_name] = node_seq\n",
    "\n",
    "# ë…¸ì„  ì´ë¦„ì—ì„œ ìˆ«ì ì œê±°í•´ì„œ base nameìœ¼ë¡œ ë§¤í•‘\n",
    "def get_base_line(line):\n",
    "    return ''.join(filter(lambda x: not x.isdigit(), line)).strip()\n",
    "\n",
    "# ODì— ëŒ€í•´ Route ìƒì„± í•¨ìˆ˜\n",
    "def extract_route(line, origin, destination):\n",
    "    base_line = get_base_line(line)\n",
    "    nodes = line_routes.get(base_line)\n",
    "    if not nodes:\n",
    "        return None\n",
    "    if origin not in nodes or destination not in nodes:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        idx_o = nodes.index(origin)\n",
    "        idx_d = nodes.index(destination)\n",
    "        # ì •ë°©í–¥ ë˜ëŠ” ì—­ë°©í–¥ ìŠ¬ë¼ì´ì‹±\n",
    "        if idx_o <= idx_d:\n",
    "            path = nodes[idx_o:idx_d + 1]\n",
    "        else:\n",
    "            path = nodes[idx_o:idx_d - 1:-1]  # ì—­ë°©í–¥\n",
    "        return \"-\".join(path)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Route ì—´ ì¶”ê°€\n",
    "demand_df[\"Route\"] = demand_df.apply(\n",
    "    lambda row: extract_route(row[\"Line\"], row[\"Origin\"], row[\"Destination\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ì €ì¥\n",
    "output_path = base_path / \"demand_with_route_filled.xlsx\"\n",
    "demand_df.to_excel(output_path, index=False)\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fe683ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ”ï¸ ì €ì¥ ì™„ë£Œ: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_node_id.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "xlsx_path = base_dir / \"qgis_export.xlsx\"\n",
    "output_path = base_dir / \"qgis_export_with_node_id.xlsx\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. NODE ì‹œíŠ¸ ì½ê¸° (ì°¸ì¡°ìš©)\n",
    "node_df = pd.read_excel(xlsx_path, sheet_name=\"NODE\")\n",
    "node_df = node_df[[\"RLNODE_NM\", \"node_id\"]].dropna()\n",
    "node_df[\"RLNODE_NM\"] = node_df[\"RLNODE_NM\"].astype(str).str.strip()\n",
    "\n",
    "# 2. BOARD_ALIGHT ì‹œíŠ¸ì— node_id ë§¤ì¹­\n",
    "df = pd.read_excel(xlsx_path, sheet_name=\"BOARD_ALIGHT\")\n",
    "df[\"RLNODE_NM\"] = df[\"RLNODE_NM\"].astype(str).str.strip()\n",
    "\n",
    "# ë§¤ì¹­ ìˆ˜í–‰\n",
    "merged_df = df.merge(node_df, on=\"RLNODE_NM\", how=\"left\")\n",
    "\n",
    "# 3. ì €ì¥\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    merged_df.to_excel(writer, sheet_name=\"BOARD_ALIGHT\", index=False)\n",
    "\n",
    "print(f\"âœ”ï¸ ì €ì¥ ì™„ë£Œ: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623d34b2",
   "metadata": {},
   "source": [
    "#### Journeys data ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23df60ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… journeys ì—´ì´ ì±„ì›Œì§„ íŒŒì¼: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_with_journeys.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "file_path   = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export.xlsx\")\n",
    "output_path = file_path.with_stem(file_path.stem + \"_with_journeys\")\n",
    "\n",
    "min_board   = 1      # ìŠ¹ì°¨ê°€ 0/ëˆ„ë½ì¸ ì—­ì— ë¶€ì—¬í•  ìµœì†Œ ìŠ¹ì°¨ ì¸ì›\n",
    "min_alight  = 1      # í•˜ì°¨ê°€ 0/ëˆ„ë½ì¸ ì—­ì— ë¶€ì—¬í•  ìµœì†Œ í•˜ì°¨ ì¸ì›\n",
    "epsilon_od  = 1      # ìœ íš¨ OD(ìŠ¹Â·í•˜ì°¨>0)ì— ì‹¬ì„ ìµœì†Œ í†µí–‰ëŸ‰\n",
    "max_iter    = 50\n",
    "eps_conv    = 1e-6\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1. ë°ì´í„° ì½ê¸° -----------------------------------------------------------\n",
    "bal    = pd.read_excel(\n",
    "            file_path, sheet_name=\"BOARD_ALIGHT\",\n",
    "            usecols=[\"node_id\", \"board_1d\", \"alight_1d\"]\n",
    "        )\n",
    "demand = pd.read_excel(file_path, sheet_name=\"DEMAND\")\n",
    "\n",
    "# 1â€‘a. Origin / Destination â‡’ ì •ìˆ˜ node_id\n",
    "demand[\"O_id\"] = demand[\"Origin\"].str.lstrip(\"n\").astype(int)\n",
    "demand[\"D_id\"] = demand[\"Destination\"].str.lstrip(\"n\").astype(int)\n",
    "\n",
    "# 2. BOARD_ALIGHT ëˆ„ë½/ì¤‘ë³µ ì²˜ë¦¬ ------------------------------------------\n",
    "#   2â€‘a. ì¤‘ë³µ node_id í•©ì‚°\n",
    "bal_agg = (bal.groupby(\"node_id\", as_index=False)\n",
    "               .agg(board=(\"board_1d\", \"sum\"),\n",
    "                    alight=(\"alight_1d\", \"sum\")))\n",
    "\n",
    "#   2â€‘b. DEMAND ì— ë“±ì¥í•˜ì§€ë§Œ bal ì— ì—†ëŠ” ë…¸ë“œ ì¶”ê°€\n",
    "all_nodes = pd.unique(demand[[\"O_id\", \"D_id\"]].values.ravel())\n",
    "bal_full  = pd.DataFrame({\"node_id\": all_nodes}).merge(\n",
    "                bal_agg, on=\"node_id\", how=\"left\"\n",
    "            )\n",
    "\n",
    "#   2â€‘c. ìŠ¹Â·í•˜ì°¨ 0/NaN â†’ ìµœì†Œê°’ ì£¼ì…\n",
    "bal_full[\"board\"]  = pd.to_numeric(bal_full[\"board\"],  errors=\"coerce\").fillna(0)\n",
    "bal_full[\"alight\"] = pd.to_numeric(bal_full[\"alight\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "bal_full.loc[bal_full[\"board\"]  == 0, \"board\"]  = min_board\n",
    "bal_full.loc[bal_full[\"alight\"] == 0, \"alight\"] = min_alight\n",
    "\n",
    "# 3. ì´ ìŠ¹Â·í•˜ì°¨ëŸ‰ ë§¤í•‘ ------------------------------------------------------\n",
    "board_map  = bal_full.set_index(\"node_id\")[\"board\"].to_dict()\n",
    "alight_map = bal_full.set_index(\"node_id\")[\"alight\"].to_dict()\n",
    "\n",
    "demand[\"o_total\"] = demand[\"O_id\"].map(board_map)\n",
    "demand[\"d_total\"] = demand[\"D_id\"].map(alight_map)\n",
    "\n",
    "# 4. ì´ˆê¸° OD í–‰ë ¬ + Îµ ì£¼ì… ---------------------------------------------------\n",
    "f = 1.0 / demand[\"Timestep\"].replace(0, np.nan)\n",
    "demand[\"T\"] = (demand[\"o_total\"] * demand[\"d_total\"] * f).fillna(0.0)\n",
    "\n",
    "valid_od = (demand[\"o_total\"] > 0) & (demand[\"d_total\"] > 0)\n",
    "demand.loc[valid_od, \"T\"] += epsilon_od      # ìµœì†Œ í†µí–‰ëŸ‰ ì‹¬ê¸°\n",
    "\n",
    "# 5. IPF (Iterative Proportional Fitting) ----------------------------------\n",
    "for _ in range(max_iter):\n",
    "    row_sum = demand.groupby(\"O_id\")[\"T\"].transform(\"sum\").replace(0, np.nan)\n",
    "    demand[\"T\"] *= demand[\"o_total\"] / row_sum\n",
    "\n",
    "    col_sum = demand.groupby(\"D_id\")[\"T\"].transform(\"sum\").replace(0, np.nan)\n",
    "    demand[\"T\"] *= demand[\"d_total\"] / col_sum\n",
    "\n",
    "    if max((row_sum - demand[\"o_total\"]).abs().max(),\n",
    "           (col_sum - demand[\"d_total\"]).abs().max()) < eps_conv:\n",
    "        break\n",
    "\n",
    "# 6. journeys ê³„ì‚° ë° í›„ì²˜ë¦¬ -------------------------------------------------\n",
    "demand[\"journeys\"] = demand[\"T\"].round(0).astype(int)   # ì •ìˆ˜(ëª…)ë¡œ ë°˜ì˜¬ë¦¼\n",
    "out = demand.drop(columns=[\"O_id\", \"D_id\", \"o_total\", \"d_total\", \"T\"])\n",
    "\n",
    "# 7. ê²°ê³¼ ì €ì¥ --------------------------------------------------------------\n",
    "if output_path.exists():\n",
    "    mode, sheet_opt = \"a\", \"overlay\"\n",
    "else:\n",
    "    mode, sheet_opt = \"w\", None                 # ìƒˆ íŒŒì¼ â€” ì‹œíŠ¸ ì¡´ì¬ ì•ˆ í•˜ë¯€ë¡œ ì˜µì…˜ ë¶ˆí•„ìš”\n",
    "\n",
    "with pd.ExcelWriter(output_path,\n",
    "                    engine=\"openpyxl\",\n",
    "                    mode=mode,\n",
    "                    if_sheet_exists=sheet_opt) as wr:\n",
    "    out.to_excel(wr, sheet_name=\"DEMAND\", index=False)\n",
    "\n",
    "print(\"âœ… journeys ì—´ì´ ì±„ì›Œì§„ íŒŒì¼:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b83a59b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modified file saved to: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export_journeys_fixed.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "file_path = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export.xlsx\")\n",
    "output_path = file_path.with_stem(file_path.stem + \"_journeys_fixed\")\n",
    "\n",
    "# DEMAND ì‹œíŠ¸ ì½ê¸°\n",
    "demand = pd.read_excel(file_path, sheet_name=\"DEMAND\")\n",
    "\n",
    "# journeys ì—´ì—ì„œ 0ì¸ ê°’ì„ 1ë¡œ ë³€ê²½\n",
    "demand[\"journeys\"] = demand[\"journeys\"].apply(lambda x: 1 if x == 0 else x)\n",
    "\n",
    "# ìƒˆ íŒŒì¼ë¡œ ì €ì¥\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    demand.to_excel(writer, sheet_name=\"DEMAND\", index=False)\n",
    "\n",
    "print(f\"âœ… Modified file saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d9a7c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ë…¸ì„ ë³„ ìµœëŒ€ íƒ‘ìŠ¹ ì¸ì› =====\n",
      "   Line  MaxLoad\n",
      "KTXê°•ë¦‰ì„ 1      388\n",
      "KTXê°•ë¦‰ì„ 2      426\n",
      "ê²½ë¶€ê³ ì†ì² ë„1    29781\n",
      "ê²½ë¶€ê³ ì†ì² ë„2    29708\n",
      "   ê²½ë¶€ì„ 1    24630\n",
      "   ê²½ë¶€ì„ 2    24591\n",
      "   ê²½ë¶ì„ 1      113\n",
      "   ê²½ë¶ì„ 2      113\n",
      "   ê²½ì „ì„ 1     1655\n",
      "   ê²½ì „ì„ 2     1660\n",
      "   ë™í•´ì„ 1     1966\n",
      "   ë™í•´ì„ 2     2113\n",
      "   ì˜ë™ì„ 1       61\n",
      "   ì˜ë™ì„ 2       66\n",
      "   ì¥í•­ì„ 1     1187\n",
      "   ì¥í•­ì„ 2     1184\n",
      "   ì „ë¼ì„ 1     2868\n",
      "   ì „ë¼ì„ 2     2836\n",
      "   ì¤‘ì•™ì„ 1     5046\n",
      "   ì¤‘ì•™ì„ 2     4975\n",
      "   ì¶©ë¶ì„ 1     1191\n",
      "   ì¶©ë¶ì„ 2     1187\n",
      "í˜¸ë‚¨ê³ ì†ì² ë„1     3031\n",
      "í˜¸ë‚¨ê³ ì†ì² ë„2     3106\n",
      "   í˜¸ë‚¨ì„ 1     3479\n",
      "   í˜¸ë‚¨ì„ 2     3483\n",
      "\n",
      "===== ìµœëŒ€ íƒ‘ìŠ¹ Edge ìƒì„¸(ì„ íƒ) =====\n",
      "   Line From  To  Load\n",
      "KTXê°•ë¦‰ì„ 1  n23 n22   388\n",
      "KTXê°•ë¦‰ì„ 2  n22 n23   426\n",
      "ê²½ë¶€ê³ ì†ì² ë„1   n4  n3 29781\n",
      "ê²½ë¶€ê³ ì†ì² ë„2   n3  n4 29708\n",
      "   ê²½ë¶€ì„ 1   n4  n1 24630\n",
      "   ê²½ë¶€ì„ 2   n1  n4 24591\n",
      "   ê²½ë¶ì„ 1  n38 n41   113\n",
      "   ê²½ë¶ì„ 2  n38 n36   113\n",
      "   ê²½ì „ì„ 1  n66 n71  1655\n",
      "   ê²½ì „ì„ 2  n71 n66  1660\n",
      "   ë™í•´ì„ 1  n69 n74  1966\n",
      "   ë™í•´ì„ 2  n72 n74  2113\n",
      "   ì˜ë™ì„ 1  n55 n54    61\n",
      "   ì˜ë™ì„ 2  n54 n55    66\n",
      "   ì¥í•­ì„ 1  n15 n16  1187\n",
      "   ì¥í•­ì„ 2  n16 n15  1184\n",
      "   ì „ë¼ì„ 1  n33 n45  2868\n",
      "   ì „ë¼ì„ 2  n45 n33  2836\n",
      "   ì¤‘ì•™ì„ 1   n3  n5  5046\n",
      "   ì¤‘ì•™ì„ 2   n5  n3  4975\n",
      "   ì¶©ë¶ì„ 1  n19 n18  1191\n",
      "   ì¶©ë¶ì„ 2  n18 n19  1187\n",
      "í˜¸ë‚¨ê³ ì†ì² ë„1  n13 n18  3031\n",
      "í˜¸ë‚¨ê³ ì†ì² ë„2  n18 n13  3106\n",
      "   í˜¸ë‚¨ì„ 1  n48 n53  3479\n",
      "   í˜¸ë‚¨ì„ 2  n53 n48  3483\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. ì…ë ¥ ê²½ë¡œ ë° ì‹œíŠ¸ ì½ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "file_path = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export.xlsx\")\n",
    "df = pd.read_excel(file_path, sheet_name=\"DEMAND\",\n",
    "                   usecols=[\"Line\", \"Route\", \"journeys\"])\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. Edgeâ€‘ë³„ íƒ‘ìŠ¹ ì¸ì› ëˆ„ì  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "edge_load = defaultdict(int)           # {(Line, from, to): ì´íƒ‘ìŠ¹}\n",
    "\n",
    "for line, route, pax in df.itertuples(index=False):\n",
    "    nodes = route.split(\"-\")           # ex) [\"n4\",\"n3\",\"n1\",...]\n",
    "    for frm, to in zip(nodes[:-1], nodes[1:]):\n",
    "        edge_load[(line, frm, to)] += pax   # ë°©í–¥ êµ¬ë¶„ O (í•„ìš” ì—†ìœ¼ë©´ ì •ë ¬í•´ì„œ key í†µì¼)\n",
    "\n",
    "# DataFrame í™”\n",
    "edge_df = (pd.DataFrame([(l,f,t,c) for (l,f,t),c in edge_load.items()],\n",
    "                        columns=[\"Line\",\"From\",\"To\",\"Load\"]))\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. ë…¸ì„ ë³„ ìµœëŒ€ íƒ‘ìŠ¹ ì¸ì› ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "max_by_line = (edge_df.groupby(\"Line\")[\"Load\"]\n",
    "                        .agg(MaxLoad=\"max\")\n",
    "                        .reset_index())\n",
    "\n",
    "# (ì„ íƒ) ì–´ëŠ Edge ì—ì„œ ìµœëŒ€ê°€ ë‚˜ì™”ëŠ”ì§€ë„ ë³´ê³  ì‹¶ë‹¤ë©´:\n",
    "idx = edge_df.groupby(\"Line\")[\"Load\"].idxmax()\n",
    "edge_peak = edge_df.loc[idx].reset_index(drop=True)   # Line, From, To, Load\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. ê²°ê³¼ ì €ì¥ or ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n===== ë…¸ì„ ë³„ ìµœëŒ€ íƒ‘ìŠ¹ ì¸ì› =====\")\n",
    "print(max_by_line.to_string(index=False))\n",
    "\n",
    "print(\"\\n===== ìµœëŒ€ íƒ‘ìŠ¹ Edge ìƒì„¸(ì„ íƒ) =====\")\n",
    "print(edge_peak.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc6d082b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ë…¸ì„ ë³„ ìµœëŒ€ Edge íƒ‘ìŠ¹Â·í•„ìš” ì—´ì°¨ ëŒ€ìˆ˜ ===\n",
      "KTXê°•ë¦‰ì„ 1          ìµœëŒ€íƒ‘ìŠ¹ =   388ëª…  /  ìš©ëŸ‰ = 381  â†’  ì—´ì°¨ 2ëŒ€\n",
      "KTXê°•ë¦‰ì„ 2          ìµœëŒ€íƒ‘ìŠ¹ =   426ëª…  /  ìš©ëŸ‰ = 381  â†’  ì—´ì°¨ 2ëŒ€\n",
      "ê²½ë¶€ê³ ì†ì² ë„1          ìµœëŒ€íƒ‘ìŠ¹ = 29781ëª…  /  ìš©ëŸ‰ = 515  â†’  ì—´ì°¨ 58ëŒ€\n",
      "ê²½ë¶€ê³ ì†ì² ë„2          ìµœëŒ€íƒ‘ìŠ¹ = 29708ëª…  /  ìš©ëŸ‰ = 515  â†’  ì—´ì°¨ 58ëŒ€\n",
      "ê²½ë¶€ì„ 1             ìµœëŒ€íƒ‘ìŠ¹ = 24630ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 61ëŒ€\n",
      "ê²½ë¶€ì„ 2             ìµœëŒ€íƒ‘ìŠ¹ = 24591ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 60ëŒ€\n",
      "ê²½ë¶ì„ 1             ìµœëŒ€íƒ‘ìŠ¹ =   113ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 1ëŒ€\n",
      "ê²½ë¶ì„ 2             ìµœëŒ€íƒ‘ìŠ¹ =   113ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 1ëŒ€\n",
      "ê²½ì „ì„ 1             ìµœëŒ€íƒ‘ìŠ¹ =  1655ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 5ëŒ€\n",
      "ê²½ì „ì„ 2             ìµœëŒ€íƒ‘ìŠ¹ =  1660ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 5ëŒ€\n",
      "ë™í•´ì„ 1             ìµœëŒ€íƒ‘ìŠ¹ =  1966ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 5ëŒ€\n",
      "ë™í•´ì„ 2             ìµœëŒ€íƒ‘ìŠ¹ =  2113ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 6ëŒ€\n",
      "ì˜ë™ì„ 1             ìµœëŒ€íƒ‘ìŠ¹ =    61ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 1ëŒ€\n",
      "ì˜ë™ì„ 2             ìµœëŒ€íƒ‘ìŠ¹ =    66ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 1ëŒ€\n",
      "ì¥í•­ì„ 1             ìµœëŒ€íƒ‘ìŠ¹ =  1187ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 3ëŒ€\n",
      "ì¥í•­ì„ 2             ìµœëŒ€íƒ‘ìŠ¹ =  1184ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 3ëŒ€\n",
      "ì „ë¼ì„ 1             ìµœëŒ€íƒ‘ìŠ¹ =  2868ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 7ëŒ€\n",
      "ì „ë¼ì„ 2             ìµœëŒ€íƒ‘ìŠ¹ =  2836ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 7ëŒ€\n",
      "ì¤‘ì•™ì„ 1             ìµœëŒ€íƒ‘ìŠ¹ =  5046ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 13ëŒ€\n",
      "ì¤‘ì•™ì„ 2             ìµœëŒ€íƒ‘ìŠ¹ =  4975ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 13ëŒ€\n",
      "ì¶©ë¶ì„ 1             ìµœëŒ€íƒ‘ìŠ¹ =  1191ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 3ëŒ€\n",
      "ì¶©ë¶ì„ 2             ìµœëŒ€íƒ‘ìŠ¹ =  1187ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 3ëŒ€\n",
      "í˜¸ë‚¨ê³ ì†ì² ë„1          ìµœëŒ€íƒ‘ìŠ¹ =  3031ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 8ëŒ€\n",
      "í˜¸ë‚¨ê³ ì†ì² ë„2          ìµœëŒ€íƒ‘ìŠ¹ =  3106ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 8ëŒ€\n",
      "í˜¸ë‚¨ì„ 1             ìµœëŒ€íƒ‘ìŠ¹ =  3479ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 9ëŒ€\n",
      "í˜¸ë‚¨ì„ 2             ìµœëŒ€íƒ‘ìŠ¹ =  3483ëª…  /  ìš©ëŸ‰ = 410  â†’  ì—´ì°¨ 9ëŒ€\n",
      "\n",
      "âœ… ì¤„ë°”ê¿ˆ ìµœì†Œí™”ëœ JSON ì €ì¥ ì™„ë£Œ â†’ D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\json\\demand_split.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, json, math\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "BASE     = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "xlsx_fp  = BASE / \"qgis_export.xlsx\"\n",
    "json_in  = BASE / \"json\" / \"demand.json\"\n",
    "json_out = BASE / \"json\" / \"demand_split.json\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. DEMAND ì‹œíŠ¸ â†’ Edge ìµœëŒ€ íƒ‘ìŠ¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.read_excel(xlsx_fp, sheet_name=\"DEMAND\",\n",
    "                   usecols=[\"Line\", \"Route\", \"journeys\"])\n",
    "\n",
    "edge_load = defaultdict(int)          # {(Line, u, v): ìŠ¹ê° ëˆ„ì }\n",
    "\n",
    "for line, route, pax in df.itertuples(index=False):\n",
    "    nodes = route.split(\"-\")\n",
    "    for u, v in zip(nodes[:-1], nodes[1:]):\n",
    "        edge_load[(line, u, v)] += pax\n",
    "\n",
    "edge_df = (pd.DataFrame([(l,u,v,c) for (l,u,v),c in edge_load.items()],\n",
    "                        columns=[\"Line\",\"From\",\"To\",\"Load\"]))\n",
    "\n",
    "max_load = (edge_df.groupby(\"Line\")[\"Load\"]\n",
    "                     .max()\n",
    "                     .to_dict())      # {Line: ìµœëŒ€ Edge íƒ‘ìŠ¹}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. ë…¸ì„ ë³„ ì—´ì°¨ 1í¸ì„± ìµœëŒ€ ì¢Œì„ìˆ˜ ë§¤í•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def train_capacity(line: str) -> int:\n",
    "    \"\"\"ë…¸ì„  ì´ë¦„ì„ ë°›ì•„ ë³´ìˆ˜ì  1í¸ì„± ìµœëŒ€ ì¢Œì„ìˆ˜ë¥¼ ë°˜í™˜\"\"\"\n",
    "    if line.startswith(\"KTXê°•ë¦‰ì„ \"):\n",
    "        return 381           # KTXâ€‘Eum\n",
    "    if line.startswith(\"ê²½ë¶€ê³ ì†ì² ë„\"):\n",
    "        return 515           # KTXâ€‘ì²­ë£¡ / ì‚°ì²œ\n",
    "    # ê·¸ ì™¸ ì¼ë°˜ì„ Â·í˜¸ë‚¨ê³ ì†ì² ë„ ë“± â†’ ì‚°ì²œ ë³´ìˆ˜ì¹˜\n",
    "    return 410               # KTXâ€‘Sancheon\n",
    "\n",
    "cap_map   = {ln: train_capacity(ln) for ln in max_load}\n",
    "train_cnt = {ln: max(1, math.ceil(max_load[ln] / cap_map[ln]))\n",
    "             for ln in max_load}\n",
    "\n",
    "print(\"\\n=== ë…¸ì„ ë³„ ìµœëŒ€ Edge íƒ‘ìŠ¹Â·í•„ìš” ì—´ì°¨ ëŒ€ìˆ˜ ===\")\n",
    "for ln in sorted(train_cnt):\n",
    "    print(f\"{ln:15s}  ìµœëŒ€íƒ‘ìŠ¹ = {max_load[ln]:5.0f}ëª…  \"\n",
    "          f\"/  ìš©ëŸ‰ = {cap_map[ln]}  â†’  ì—´ì°¨ {train_cnt[ln]}ëŒ€\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. demand.json ë¶ˆëŸ¬ì™€ì„œ ìª¼ê°œê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "with open(json_in, \"r\", encoding=\"utf-8\") as f:\n",
    "    demand_js = json.load(f)\n",
    "\n",
    "split_js = {}   # ìƒˆë¡œìš´ dict\n",
    "\n",
    "for ln, od_list in demand_js.items():\n",
    "    n_train = train_cnt.get(ln, 1)          # ë§¤í•‘ ì•ˆ ë˜ë©´ 1ëŒ€\n",
    "    for idx in range(n_train):\n",
    "        key = f\"{ln}_{idx+1}\"\n",
    "        split_js[key] = []\n",
    "    for o, d, j in od_list:\n",
    "        share = round(j / n_train, 2)\n",
    "        for idx in range(n_train):\n",
    "            split_js[f\"{ln}_{idx+1}\"].append([o, d, share])\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. JSON ì €ì¥ (í•œ ë…¸ì„  = í•œ ì¤„) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "with open(json_out, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"{\\n\")\n",
    "    for i, (line, trips) in enumerate(split_js.items()):\n",
    "        line_str = json.dumps(line, ensure_ascii=False)\n",
    "        trips_str = json.dumps(trips, ensure_ascii=False, separators=(\",\", \":\"))\n",
    "        comma = \",\" if i < len(split_js) - 1 else \"\"\n",
    "        f.write(f\"  {line_str}: {trips_str}{comma}\\n\")\n",
    "    f.write(\"}\\n\")\n",
    "\n",
    "print(f\"\\nâœ… ì¤„ë°”ê¿ˆ ìµœì†Œí™”ëœ JSON ì €ì¥ ì™„ë£Œ â†’ {json_out}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed14966d",
   "metadata": {},
   "source": [
    "ì¶œë°œ timestep ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46944202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 'time_step_15' ì—´ì´ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "file_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\qgis_export.xlsx\"\n",
    "sheet_name = \"EDGE\"\n",
    "\n",
    "# ì—‘ì…€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "# 'time(min)' ì—´ì´ ìˆëŠ”ì§€ í™•ì¸\n",
    "if \"time(min)\" not in df.columns:\n",
    "    raise KeyError(\"'time(min)' ì—´ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ì†Œìˆ«ì  ì˜¬ë¦¼í•˜ì—¬ time_step_15 ê³„ì‚°\n",
    "df[\"time_step_15\"] = df[\"time(min)\"].apply(lambda x: math.ceil(x / 15))\n",
    "\n",
    "# ë®ì–´ì“°ê¸° ì €ì¥\n",
    "with pd.ExcelWriter(file_path, mode=\"a\", if_sheet_exists=\"overlay\", engine=\"openpyxl\") as writer:\n",
    "    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(\"âœ… 'time_step_15' ì—´ì´ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6fe7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… dep_time.json trimmed and saved (cutoff by rounded threshold).\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "base_dir = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\json\"\n",
    "dep_path = os.path.join(base_dir, \"dep_time.json\")\n",
    "demand_path = os.path.join(base_dir, \"demand.json\")\n",
    "routes_path = os.path.join(base_dir, \"routes_nodes.json\")\n",
    "\n",
    "# 1. dep_time.json ë¡œë“œ\n",
    "with open(dep_path, encoding=\"utf-8\") as f:\n",
    "    dep_data = json.load(f)\n",
    "valid_trains = set(dep_data.keys())\n",
    "\n",
    "# 2. demand.json í•„í„°ë§\n",
    "with open(demand_path, encoding=\"utf-8\") as f:\n",
    "    demand_data = json.load(f)\n",
    "filtered_demand = {k: v for k, v in demand_data.items() if k in valid_trains}\n",
    "\n",
    "# 3. routes_nodes.json í•„í„°ë§\n",
    "with open(routes_path, encoding=\"utf-8\") as f:\n",
    "    routes_data = json.load(f)\n",
    "filtered_routes = {k: v for k, v in routes_data.items() if k in valid_trains}\n",
    "\n",
    "# 4. ì €ì¥ (ë®ì–´ì“°ê¸°)\n",
    "with open(demand_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_demand, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(routes_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_routes, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"âœ… demand.jsonê³¼ routes_nodes.jsonì´ dep_time.json ê¸°ì¤€ìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ í•„í„°ë§ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99a754a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¤„ë°”ê¿ˆ í¬ë§· ì •ë¦¬ ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "base_dir = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\json\"\n",
    "demand_path = os.path.join(base_dir, \"demand_filtered.json\")\n",
    "routes_path = os.path.join(base_dir, \"routes_nodes_filtered.json\")\n",
    "\n",
    "def save_single_line_json(data, filepath):\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"{\\n\")\n",
    "        for i, (k, v) in enumerate(data.items()):\n",
    "            line = f'  \"{k}\": {json.dumps(v, ensure_ascii=False)}'\n",
    "            if i < len(data) - 1:\n",
    "                line += \",\"\n",
    "            f.write(line + \"\\n\")\n",
    "        f.write(\"}\")\n",
    "\n",
    "# íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open(demand_path, encoding=\"utf-8\") as f:\n",
    "    demand_data = json.load(f)\n",
    "with open(routes_path, encoding=\"utf-8\") as f:\n",
    "    routes_data = json.load(f)\n",
    "\n",
    "# í•œ ì¤„ë‹¹ ê¸°ì°¨ í•˜ë‚˜ì”© ì €ì¥\n",
    "save_single_line_json(demand_data, demand_path)\n",
    "save_single_line_json(routes_data, routes_path)\n",
    "\n",
    "print(\"âœ… ì¤„ë°”ê¿ˆ í¬ë§· ì •ë¦¬ ì™„ë£Œ.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d2e672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ í•„í„°ë§ ì „ ODìŒ ê°œìˆ˜: 12426\n",
      "ğŸ”¹ í•„í„°ë§ í›„ ODìŒ ê°œìˆ˜: 3607\n",
      "ğŸ”¹ ì œê±°ëœ ODìŒ ê°œìˆ˜: 8819\n",
      "âœ… ì €ì¥ ì™„ë£Œ: D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\json\\demand_filtered.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "file_path = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\json\\demand.json\")\n",
    "output_path = file_path.parent / \"demand_filtered.json\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    demand_data = json.load(f)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3. í•„í„°ë§ ë° í†µê³„\n",
    "original_count = 0\n",
    "filtered_count = 0\n",
    "\n",
    "filtered_data = {}\n",
    "\n",
    "for train_id, od_list in demand_data.items():\n",
    "    original_count += len(od_list)\n",
    "    \n",
    "    # ìˆ˜ìš” 10 ì´ìƒì¸ ODìŒë§Œ ë‚¨ê¸°ê¸°\n",
    "    new_od_list = [od for od in od_list if od[2] >= 10]\n",
    "    filtered_count += len(new_od_list)\n",
    "    \n",
    "    # ê²°ê³¼ê°€ ë‚¨ì•„ìˆëŠ” ê²½ìš°ì—ë§Œ ì €ì¥\n",
    "    if new_od_list:\n",
    "        filtered_data[train_id] = new_od_list\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4. í•„í„°ë§ ê²°ê³¼ ì €ì¥\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 5. ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ğŸ”¹ í•„í„°ë§ ì „ ODìŒ ê°œìˆ˜: {original_count}\")\n",
    "print(f\"ğŸ”¹ í•„í„°ë§ í›„ ODìŒ ê°œìˆ˜: {filtered_count}\")\n",
    "print(f\"ğŸ”¹ ì œê±°ëœ ODìŒ ê°œìˆ˜: {original_count - filtered_count}\")\n",
    "print(f\"âœ… ì €ì¥ ì™„ë£Œ: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15255623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… dep_time í•„í„°ë§: 122 â†’ 106ê°œ ë‚¨ìŒ\n",
      "âœ… routes_nodes í•„í„°ë§: 122 â†’ 106ê°œ ë‚¨ìŒ\n",
      "\n",
      "ğŸ“ ì €ì¥ ì™„ë£Œ:\n",
      "â†’ dep_time_filtered.json\n",
      "â†’ routes_nodes_filtered.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. ê²½ë¡œ ì„¤ì •\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\json\")\n",
    "dep_time_path = base_dir / \"dep_time.json\"\n",
    "routes_nodes_path = base_dir / \"routes_nodes.json\"\n",
    "dep_time_out = base_dir / \"dep_time_filtered.json\"\n",
    "routes_nodes_out = base_dir / \"routes_nodes_filtered.json\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. dep_time.json ë¶ˆëŸ¬ì˜¤ê¸° ë° í•„í„°ë§ (ê°’ì´ 13 ë¯¸ë§Œì¸ ê²ƒë§Œ)\n",
    "with open(dep_time_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    dep_time = json.load(f)\n",
    "\n",
    "filtered_dep_time = {k: v for k, v in dep_time.items() if v < 12}\n",
    "print(f\"âœ… dep_time í•„í„°ë§: {len(dep_time)} â†’ {len(filtered_dep_time)}ê°œ ë‚¨ìŒ\")\n",
    "\n",
    "# ì €ì¥\n",
    "with open(dep_time_out, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_dep_time, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3. routes_nodes.json ë¶ˆëŸ¬ì˜¤ê¸° ë° í•´ë‹¹ í‚¤ë§Œ ë‚¨ê¸°ê¸°\n",
    "with open(routes_nodes_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    routes_nodes = json.load(f)\n",
    "\n",
    "# dep_timeì—ì„œ ë‚¨ì€ í‚¤ë§Œ ìœ ì§€\n",
    "filtered_routes_nodes = {k: v for k, v in routes_nodes.items() if k in filtered_dep_time}\n",
    "print(f\"âœ… routes_nodes í•„í„°ë§: {len(routes_nodes)} â†’ {len(filtered_routes_nodes)}ê°œ ë‚¨ìŒ\")\n",
    "\n",
    "# ì €ì¥\n",
    "with open(routes_nodes_out, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_routes_nodes, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4. ê²°ê³¼ ìš”ì•½\n",
    "print(f\"\\nğŸ“ ì €ì¥ ì™„ë£Œ:\")\n",
    "print(f\"â†’ {dep_time_out.name}\")\n",
    "print(f\"â†’ {routes_nodes_out.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb134c89",
   "metadata": {},
   "source": [
    "#### Capacity\n",
    "- Demand_dataì´ìš©í•´ì„œ ì—£ì§€ë§ˆë‹¤ íë¥´ëŠ” demandì–‘ ê³„ì‚°í•œ íŒŒì¼: 6.edge_journeys_summary.xlsx\n",
    "- e1 n1-n2 1502241\n",
    "- e2 n2-n1 389459.5\n",
    "- e1,e2,e3,e4, .. ë„˜ë²„ë§ qgisì™€ ë‹¤ë¦„ (ì–‘ë°©í–¥ ê³ ë ¤)\n",
    "- ì–‘ë°©í–¥ ì—£ì§€ì— ëŒ€í•´ì„œëŠ” ì„œë¡œ ë™ì¼í•œ capacityë¥¼ ê°–ë„ë¡ í•´ì•¼í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060b668f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capacity summary saved â†’ D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\7.edge_capacity_summary.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "base_dir = Path(r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\")\n",
    "input_path = base_dir / \"6.edge_journeys_summary.xlsx\"\n",
    "df = pd.read_excel(input_path)\n",
    "\n",
    "# 2. ì—¬ìœ  ê³„ìˆ˜ ì„¤ì • (ì˜ˆ: 1.2ë°°)\n",
    "buffer_ratio = 1.2\n",
    "\n",
    "# 3. (u, v) / (v, u) í˜•íƒœë¥¼ ê³ ë ¤í•´ ì–‘ë°©í–¥ í‚¤ ë§Œë“¤ê¸°\n",
    "df[\"pair_key\"] = df.apply(lambda row: tuple(sorted([row[\"from_node_name\"], row[\"to_node_name\"]])), axis=1)\n",
    "\n",
    "# 4. ê°™ì€ pair_key ê·¸ë£¹ ë‚´ì—ì„œ ìµœëŒ€ journeys ì„ íƒ\n",
    "grouped = df.groupby(\"pair_key\", as_index=False).agg({\n",
    "    \"journeys\": \"max\"\n",
    "})\n",
    "grouped[\"capacity\"] = grouped[\"journeys\"] * buffer_ratio\n",
    "\n",
    "# 5. ë‹¤ì‹œ ì›ë˜ ë°©í–¥ì„± edgeì— capacity ì—°ê²°\n",
    "df = df.merge(grouped[[\"pair_key\", \"capacity\"]], on=\"pair_key\", how=\"left\")\n",
    "\n",
    "# 6. ì»¬ëŸ¼ ì •ë¦¬ ë° ì €ì¥\n",
    "df = df.drop(columns=[\"pair_key\"])\n",
    "output_path = base_dir / \"7.edge_capacity_summary.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Capacity summary saved â†’ {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc815f",
   "metadata": {},
   "source": [
    "#### ë…¸ì„ ë³„ ìŠ¹ê° ìˆ˜ìš” ë°ì´í„° -> í•„ìš”í•œ ê¸°ì°¨ìˆ˜ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01187308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      line  cycles_day  train_sets_needed\n",
      "0   KTXê°•ë¦‰ì„           24                  1\n",
      "1   KTXë™í•´ì„           39                  1\n",
      "2      ê²½ê°•ì„           23                  2\n",
      "3   ê²½ë¶€ê³ ì†ì² ë„           8                 23\n",
      "4      ê²½ë¶€ì„            1                 65\n",
      "5      ê²½ë¶ì„           18                  1\n",
      "6      ê²½ì˜ì„           46                  1\n",
      "7      ê²½ì¸ì„           35                  1\n",
      "8      ê²½ì „ì„            5                  3\n",
      "9     ê³µí•­ì² ë„          20                  2\n",
      "10     ëŒ€êµ¬ì„           44                  1\n",
      "11   ë™í•´ë‚¨ë¶€ì„           12                  3\n",
      "12     ë™í•´ì„           16                  1\n",
      "13     ì‚¼ì²™ì„           51                  1\n",
      "14     ì˜ë™ì„           12                  2\n",
      "15     ì¥í•­ì„           11                  2\n",
      "16     ì „ë¼ì„           17                  2\n",
      "17   ì¤‘ë¶€ë‚´ë¥™ì„           36                  1\n",
      "18     ì¤‘ì•™ì„            2                 23\n",
      "19     ì¶©ë¶ì„           11                  1\n",
      "20     íƒœë°±ì„           19                  1\n",
      "21  í˜¸ë‚¨ê³ ì†ì² ë„          20                  1\n",
      "22     í˜¸ë‚¨ì„           10                  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minji Kang\\AppData\\Local\\Temp\\ipykernel_38976\\2930921966.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  result = df.groupby(\"line\").apply(train_stats).reset_index()\n"
     ]
    }
   ],
   "source": [
    "import json, math, pandas as pd, os\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. íŒŒì¼ ì½ê¸°\n",
    "file_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\7.Korea_Full\\5.demand_data_kofull.json\"\n",
    "df = pd.read_json(file_path)\n",
    "df[\"journeys_day\"] = df[\"journeys\"] / 365\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. íŒŒë¼ë¯¸í„°\n",
    "TARGET_LOAD    = 1.0          # 100 % íƒ‘ìŠ¹ë¥ \n",
    "TURNAROUND_MIN = 15           # ì¢…ì  ë²„í¼(ë¶„)\n",
    "HOURS_PER_DAY  = 17\n",
    "DEFAULT_SEAT   = 400          # seat_map ì— ì—†ì„ ë•Œ ì„ì‹œê°’\n",
    "\n",
    "# ë…¸ì„ ë³„ ì¢Œì„ìˆ˜ (ì• ê¸€ì ë§¤ì¹­ìš©)\n",
    "seat_map = {\n",
    "    # ê³ ì†ì—´ì°¨\n",
    "    \"KTXê°•ë¦‰ì„ \":    381,   # KTX-ì´ìŒ (KTX-Eum) 381ì„ :contentReference[oaicite:2]{index=2}\n",
    "    \"KTXê²½ë¶€ì„ \":    955,   # KTX-I 955ì„(935~955) :contentReference[oaicite:3]{index=3}\n",
    "    \"KTXí˜¸ë‚¨ì„ \":    955,\n",
    "    \"ê²½ë¶€ê³ ì†ì² ë„\":   955,   # KTX-ì‚°ì²œ\n",
    "    \"ê²½ë¶€ì„ \":         900,   # SRT í¸ì„±(ì˜ˆì‹œ)\n",
    "    # ITX ê³„ì—´\n",
    "    \"ITX-ìƒˆë§ˆì„\":   376,   # ITX-ìƒˆë§ˆì„\n",
    "    \"ITX-ì²­ì¶˜\":     402,   # ITX-ì²­ì¶˜\n",
    "    # ì¼ë°˜ì—´ì°¨\n",
    "    \"ë¬´ê¶í™”í˜¸\":     920,   # ì¢Œì„+ì…ì„ í—ˆìš©, í¸ì„± ì¢Œì„ 920 ë¶€ê·¼\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def train_stats(group):\n",
    "    line = group.name\n",
    "    seats = next((v for k, v in seat_map.items() if line.startswith(k)), DEFAULT_SEAT)\n",
    "\n",
    "    total_pax = group[\"journeys_day\"].sum()\n",
    "    single_run = group[\"time_min\"].max()\n",
    "    round_trip = single_run + TURNAROUND_MIN\n",
    "    cycles = max(1, (HOURS_PER_DAY * 60) // round_trip)\n",
    "\n",
    "    cap_per_set = seats * TARGET_LOAD * cycles\n",
    "    sets_needed = math.ceil(total_pax / cap_per_set) if cap_per_set else None\n",
    "\n",
    "    return pd.Series({\n",
    "        \"cycles_day\": cycles,\n",
    "        \"train_sets_needed\": sets_needed\n",
    "    })\n",
    "\n",
    "# 4. ê³„ì‚°\n",
    "result = df.groupby(\"line\").apply(train_stats).reset_index()\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mjkang",
   "language": "python",
   "name": "mjkang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
