{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "from shapely.geometry import LineString\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.time() \n",
    "\n",
    "# Define file paths\n",
    "toy_node_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\Korea\\KOREARL_NODE.shp\"\n",
    "toy_edge_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\Korea\\KOREARL_EDGE.shp\"\n",
    "\n",
    "# Load the shapefiles\n",
    "toy_node = gpd.read_file(toy_node_path)\n",
    "toy_edge = gpd.read_file(toy_edge_path)\n",
    "\n",
    "toy_node = toy_node.to_crs(epsg=3857)\n",
    "toy_edge = toy_edge.to_crs(epsg=3857)\n",
    "\n",
    "print(\"ðŸ“„ Node ì†ì„± ì»¬ëŸ¼:\")\n",
    "print(toy_node.columns)\n",
    "print(\"\\nðŸ“„ Edge ì†ì„± ì»¬ëŸ¼:\")\n",
    "print(toy_edge.columns)\n",
    "\n",
    "print(\"\\nðŸ” toy_node ìƒ˜í”Œ:\")\n",
    "print(toy_node.head())\n",
    "print(\"\\nðŸ” toy_edge ìƒ˜í”Œ:\")\n",
    "print(toy_edge.head())\n",
    "\n",
    "# Create a plot with network and basemap\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "toy_edge.plot(ax=ax, color=\"grey\", linewidth=1.8, label=\"Edges\")\n",
    "\n",
    "node_coords = toy_node.geometry.apply(lambda pt: (pt.x, pt.y)).tolist()\n",
    "x_coords, y_coords = zip(*node_coords)\n",
    "ax.scatter(x_coords, y_coords, color=\"black\", s=2.3, label=\"Nodes\", zorder=3, alpha=0.5)\n",
    "\n",
    "ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, zorder=0)\n",
    "plt.legend()\n",
    "plt.title(\"Scotland Railway Network\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db605b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "\n",
    "\n",
    "# 1. Node numbering (n1, n2, ...)\n",
    "round_coord = lambda coord: (round(coord[0], 6), round(coord[1], 6))\n",
    "\n",
    "# 1. node_id â†’ geometry\n",
    "node_info_list = [\n",
    "    (row.node_id, round_coord((row.geometry.x, row.geometry.y)))\n",
    "    for row in toy_node.itertuples()\n",
    "]\n",
    "\n",
    "nodes = {}\n",
    "node_meta = []\n",
    "\n",
    "for node_id, coord in node_info_list:\n",
    "    node_name = f\"n{int(node_id)}\"  # âœ… node_id ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "    nodes[node_name] = coord\n",
    "    node_meta.append({\n",
    "        \"node_id\": int(node_id),\n",
    "        \"node_name\": node_name,\n",
    "        \"geometry\": coord\n",
    "    })\n",
    "\n",
    "# ì¢Œí‘œ â†’ node_name ë§¤í•‘\n",
    "coord_to_node = {coord: node_name for node_name, coord in nodes.items()}\n",
    "\n",
    "# ì¶œë ¥ í™•ì¸\n",
    "print(\"====== Node info (ì§ì ‘ ë§¤í•‘) ======\")\n",
    "for meta in node_meta:\n",
    "    print(f\"{meta['node_name']} (ID: {meta['node_id']}): {meta['geometry']}\")\n",
    "\n",
    "\n",
    "\n",
    "# 2. Edge numbering (e1, e2, ...)\n",
    "nodeid_to_nodename = {meta[\"node_id\"]: meta[\"node_name\"] for meta in node_meta}\n",
    "toy_edge['from_node_name'] = toy_edge['from_node_'].map(nodeid_to_nodename)\n",
    "toy_edge['to_node_name'] = toy_edge['to_node_id'].map(nodeid_to_nodename)\n",
    "\n",
    "edge_pairs = set()\n",
    "\n",
    "for _, row in toy_edge.iterrows():\n",
    "    from_node = row['from_node_name']\n",
    "    to_node = row['to_node_name']\n",
    "    sorted_pair = tuple(sorted([from_node, to_node]))\n",
    "    edge_pairs.add(sorted_pair)\n",
    "\n",
    "sorted_edge_pairs = sorted(edge_pairs, key=lambda x: (x[0], x[1]))\n",
    "print(sorted_edge_pairs)\n",
    "\n",
    "edges = {}\n",
    "edge_number = 1\n",
    "\n",
    "for from_node, to_node in sorted_edge_pairs:\n",
    "    edges[f\"e{edge_number}\"] = (from_node, to_node)\n",
    "    edges[f\"e{edge_number + 1}\"] = (to_node, from_node)\n",
    "    edge_number += 2\n",
    "\n",
    "edge_records = []\n",
    "for edge_name, (from_node, to_node) in edges.items():\n",
    "    match = toy_edge[((toy_edge['from_node_name'] == from_node) & (toy_edge['to_node_name'] == to_node)) |\n",
    "                     ((toy_edge['from_node_name'] == to_node) & (toy_edge['to_node_name'] == from_node))]\n",
    "    \n",
    "    if not match.empty:\n",
    "        journeys = match.iloc[0]['journeys']\n",
    "        geometry = match.iloc[0]['geometry']\n",
    "        edge_id = match.iloc[0]['edge_id']\n",
    "    else:\n",
    "        journeys = None\n",
    "        geometry = None\n",
    "        edge_id = None\n",
    "\n",
    "    edge_records.append({\n",
    "        'edge_id': edge_id,\n",
    "        'edge_name': edge_name,\n",
    "        'from_node_name': from_node,\n",
    "        'to_node_name': to_node,\n",
    "        'journeys': journeys,\n",
    "        'geometry': geometry\n",
    "    })\n",
    "\n",
    "toy_edge_bidirectional = pd.DataFrame(edge_records)\n",
    "\n",
    "toy_edge_bidirectional['edge_num'] = toy_edge_bidirectional['edge_name'].str.extract(r'e(\\d+)').astype(int)\n",
    "toy_edge_bidirectional = toy_edge_bidirectional.sort_values(by='edge_num').reset_index(drop=True)\n",
    "toy_edge_bidirectional = toy_edge_bidirectional.drop(columns='edge_num')\n",
    "\n",
    "print(\"\\n====== Edge info ======\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(toy_edge_bidirectional)\n",
    "\n",
    "\n",
    "\n",
    "# 3. Convert edges to arc format\n",
    "arcs = [(u, v) for _, (u, v) in edges.items()]\n",
    "#print(\"\\nArcs:\", arcs)\n",
    "\n",
    "\n",
    "\n",
    "# 4. Compute Euclidean distances\n",
    "def euclidean_distance(node1, node2):\n",
    "    x1, y1 = nodes[node1]\n",
    "    x2, y2 = nodes[node2]\n",
    "    return round(((x2 - x1)**2 + (y2 - y1)**2)**0.5, 2)\n",
    "\n",
    "arc_distance = {edge_name: euclidean_distance(u, v) for edge_name, (u, v) in edges.items()}\n",
    "#print(\"Arc Distances:\", arc_distance)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Create a network graph\n",
    "# Create the graph using extracted data\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes and edges\n",
    "for node, position in nodes.items():\n",
    "    G.add_node(node, pos=position)\n",
    "\n",
    "for edge_name, (u, v) in edges.items(): \n",
    "    G.add_edge(u, v, weight=arc_distance[edge_name])\n",
    "\n",
    "# Remove duplicate edges\n",
    "unique_edges = set()\n",
    "edge_name_map = {}\n",
    "\n",
    "for edge_name, (u, v) in edges.items():\n",
    "    if (v, u) not in unique_edges:\n",
    "        unique_edges.add((u, v))\n",
    "        \n",
    "        reverse_edge_name = [k for k, (a, b) in edges.items() if (a, b) == (v, u)]\n",
    "        if reverse_edge_name:\n",
    "            journeys = toy_edge_bidirectional[\n",
    "                (toy_edge_bidirectional['from_node_name'] == u) &\n",
    "                (toy_edge_bidirectional['to_node_name'] == v)\n",
    "            ]['journeys'].values\n",
    "\n",
    "            journeys_val = int(journeys[0]) if len(journeys) > 0 else \"?\"\n",
    "            edge_label = f\"{edge_name}, {reverse_edge_name[0]} ({journeys_val})\"\n",
    "        else:\n",
    "            edge_label = edge_name\n",
    "\n",
    "        edge_name_map[(u, v)] = edge_label\n",
    "\n",
    "\n",
    "# Plot the network topology\n",
    "plt.figure(figsize=(7, 7))\n",
    "pos = nx.get_node_attributes(G, 'pos')\n",
    "nx.draw_networkx_nodes(G, pos, node_size=250, node_color=\"lightblue\")\n",
    "nx.draw_networkx_edges(\n",
    "    G, pos,\n",
    "    edgelist=list(unique_edges),  \n",
    "    arrowstyle='-',\n",
    "    min_target_margin=10,\n",
    "    min_source_margin=10\n",
    ")\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_name_map, font_size=6)\n",
    "nx.draw_networkx_labels(G, pos, font_size=7)\n",
    "plt.title(\"Network with Unique Edge Labels\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e29c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import json\n",
    "import copy\n",
    "\n",
    "# Scientific Libraries\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "\n",
    "# Optimization\n",
    "from gurobipy import Model, GRB, quicksum\n",
    "\n",
    "# Graph & Plotting\\\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# MBNpy Modules\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # GUI ì—†ëŠ” í™˜ê²½ì—ì„œë„ ìž‘ë™í•˜ëŠ” ì•ˆì „í•œ backend\n",
    "from mbnpy import brc, cpm, variable, operation, branch, config\n",
    "\n",
    "# Local Module\n",
    "import batch\n",
    "\n",
    "# Clean up memory\n",
    "gc.collect()\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8eb910",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = nodes  \n",
    "edges = edges  \n",
    "arcs = arcs\n",
    "arc_distance = arc_distance \n",
    "\n",
    "\n",
    "\n",
    "# 1. Generate arc failure probabilities based on arc distances (longer distance -> higher failure probability)\n",
    "# Get the minimum and maximum arc distances\n",
    "min_dist = min(arc_distance.values())\n",
    "max_dist = max(arc_distance.values())\n",
    "\n",
    "# Failure probability range (0.01 ~ 0.3)\n",
    "min_prob = 0.01\n",
    "max_prob = 0.3\n",
    "\n",
    "def compute_failure_probability(distance, min_dist, max_dist, min_prob, max_prob):\n",
    "    normalized_dist = (distance - min_dist) / (max_dist - min_dist) # Normalize to [0,1]\n",
    "    return round(min_prob + normalized_dist * (max_prob - min_prob), 4)\n",
    "\n",
    "# Generate failure probability for each edge\n",
    "probs_dynamic = {\n",
    "    edge: {\n",
    "        0: compute_failure_probability(dist, min_dist, max_dist, min_prob, max_prob),\n",
    "        1: round(1 - compute_failure_probability(dist, min_dist, max_dist, min_prob, max_prob), 4)\n",
    "    }\n",
    "    for edge, dist in arc_distance.items()\n",
    "}\n",
    "\n",
    "# Sort edges by numeric order\n",
    "def numeric_sort(edge):\n",
    "    return int(edge[1:])  # Extract numeric part from \"eX\"\n",
    "\n",
    "probs_sorted = {k: probs_dynamic[k] for k in sorted(probs_dynamic, key=numeric_sort)}\n",
    "\n",
    "# Print formatted probabilities\n",
    "#print(json.dumps(probs_sorted, indent=4, separators=(\",\", \": \")))\n",
    "probs = probs_sorted\n",
    "probs_cpm = copy.deepcopy(probs)\n",
    "#print(probs_cpm)\n",
    "\n",
    "\n",
    "\n",
    "# 2. Assign capacities to each arcs\n",
    "# Initial intact capacity (Unchanged from original)\n",
    "intact_capacity = {}\n",
    "\n",
    "for edge_name, (u, v) in edges.items():\n",
    "    match = toy_edge[((toy_edge['from_node_name'] == u) & (toy_edge['to_node_name'] == v)) |\n",
    "                     ((toy_edge['from_node_name'] == v) & (toy_edge['to_node_name'] == u))]\n",
    "\n",
    "    if not match.empty:\n",
    "        intact_capacity[edge_name] = match.iloc[0]['journeys']\n",
    "    else:\n",
    "        intact_capacity[edge_name] = None  \n",
    "\n",
    "print(\"Intact Capacities:\", intact_capacity)\n",
    "\n",
    "# Function to generate random component states (0 or 1) based on failure probabilities\n",
    "def generate_comps_st(probs):\n",
    "    comps_st = {}\n",
    "\n",
    "    for edge, prob in probs.items():\n",
    "        if isinstance(prob, dict) and 0 in prob and 1 in prob:  # Ensure correct structure\n",
    "            comps_st[edge] = np.random.choice([0, 1], p=[prob[0], prob[1]])\n",
    "        else:\n",
    "            print(f\"Warning: Invalid probability format for edge {edge}: {prob}\")  \n",
    "\n",
    "    return comps_st\n",
    "\n",
    "# Compute arc capacities\n",
    "comps_st = generate_comps_st(probs_sorted)  \n",
    "\n",
    "\n",
    "\n",
    "# 3. Compute maximum allowable distance\n",
    "# Demand data\n",
    "json_path = r\"D:\\MINJI\\NETWORK RELIABILITY\\QGIS\\Korea\\demand_data.json\"\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    demand = json.load(f)\n",
    "\n",
    "# Compute max allowable distance\n",
    "avg_velo = 149  # Speed in km/h\n",
    "max_distance = {}\n",
    "commodity_name_map = {}  \n",
    "\n",
    "for idx, item in enumerate(demand, start=1):\n",
    "    origin = item[\"origin\"]\n",
    "    destination = item[\"destination\"]\n",
    "    commodity_key = f\"{origin}->{destination}\"\n",
    "    commodity_name = f\"k{idx}\"  \n",
    "\n",
    "    distance = item[\"distance\"]\n",
    "    max_allowable_time = (distance * 60) / avg_velo + 180\n",
    "    max_distance[commodity_name] = max_allowable_time * avg_velo / 60\n",
    "\n",
    "    commodity_name_map[commodity_name] = {\n",
    "        \"key\": commodity_key,\n",
    "        \"origin\": origin,\n",
    "        \"destination\": destination\n",
    "    }\n",
    "\n",
    "    print(f\"\\nCommodity: {commodity_name}\")\n",
    "    print(f\"  OD Pair: {commodity_key}\")\n",
    "    print(f\"  Distance (from JSON): {distance:.2f} km\")\n",
    "    print(f\"  Maximum allowable time: {max_allowable_time:.2f} minutes\")\n",
    "    print(f\"  Maximum allowable distance: {max_distance[commodity_name]:.2f} km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build directed graph with weighted arcs\n",
    "G = nx.DiGraph()\n",
    "for node, position in nodes.items():\n",
    "    G.add_node(node, pos=position)\n",
    "\n",
    "for edge_id, (u, v) in edges.items():\n",
    "    G.add_edge(u, v, weight=arc_distance[edge_id])\n",
    "\n",
    "# Initialize demand for each arc\n",
    "edge_demand = { (u, v): 0 for u, v in G.edges }\n",
    "\n",
    "# Accumulate demand from all shortest paths\n",
    "for info in demand:\n",
    "    origin = info[\"origin_name\"]         # use node name like 'n18'\n",
    "    destination = info[\"destination_name\"]\n",
    "    amount = info[\"journeys\"]            # amount is stored as 'journeys'\n",
    "\n",
    "    try:\n",
    "        paths = list(nx.all_shortest_paths(G, source=origin, target=destination, weight=\"weight\"))\n",
    "        for path in paths:\n",
    "            for i in range(len(path) - 1):\n",
    "                edge = (path[i], path[i + 1])\n",
    "                if edge in edge_demand:\n",
    "                    edge_demand[edge] += amount\n",
    "                    print(f\"ðŸŸ¦ OD {origin} â†’ {destination}, amount={amount} âžœ edge {edge} += {amount} (total: {edge_demand[edge]})\")\n",
    "    except nx.NetworkXNoPath:\n",
    "        print(f\"âš ï¸ No path found for {origin} â†’ {destination}\")\n",
    "        continue\n",
    "\n",
    "# Log-scaled normalization\n",
    "normalized_demand = {\n",
    "    (u, v): np.log10(d + 1) for (u, v), d in edge_demand.items()\n",
    "}\n",
    "D_max = max(normalized_demand.values())\n",
    "D_min = min(normalized_demand.values())\n",
    "\n",
    "normalized_demand = {\n",
    "    (u, v): (val - D_min) / (D_max - D_min)\n",
    "    for (u, v), val in normalized_demand.items()\n",
    "}\n",
    "\n",
    "# Visualization\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "start_rgb = (245/255, 250/255, 254/255)    \n",
    "mid_rgb   = (100/255, 169/255, 211/255)       \n",
    "end_rgb   = (8/255, 50/255, 110/255)    \n",
    "cmap = LinearSegmentedColormap.from_list(\"custom_3color_gradient\", [start_rgb, mid_rgb, end_rgb])\n",
    "\n",
    "pos = nx.get_node_attributes(G, \"pos\")\n",
    "fig, ax = plt.subplots(figsize=(14, 14))\n",
    "\n",
    "# Nodes\n",
    "# 2. ë¼ë²¨ ì‹œê°í™” (normalized demand ê·¸ë¦¬ëŠ” ì½”ë“œ ì´í›„ì— ì‚½ìž…)\n",
    "\n",
    "# 1. ì—£ì§€ ë¼ë²¨ ì •ì˜ (ê°’ì´ 0ë³´ë‹¤ í° ê²½ìš°ë§Œ í‘œì‹œ)\n",
    "edge_labels = {\n",
    "    (u, v): f\"{edge_demand[(u, v)]:.0f}\"\n",
    "    for (u, v) in G.edges\n",
    "    if edge_demand[(u, v)] > 0\n",
    "}\n",
    "\n",
    "nx.draw_networkx_edge_labels(\n",
    "    G,\n",
    "    pos,\n",
    "    edge_labels=edge_labels,\n",
    "    font_size=8,\n",
    "    font_color=\"darkred\",\n",
    "    rotate=False,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "\n",
    "# Edges with normalized demand\n",
    "for (u, v), value in normalized_demand.items():\n",
    "    color = cmap(value)\n",
    "    nx.draw_networkx_edges(\n",
    "        G, pos, edgelist=[(u, v)],\n",
    "        width=1.8,\n",
    "        edge_color=[color],\n",
    "        arrowstyle=\"->\",\n",
    "        arrowsize=8,\n",
    "        alpha=1,\n",
    "        ax=ax,\n",
    "        connectionstyle=\"arc3,rad=0.07\"\n",
    "    )\n",
    "\n",
    "ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, crs=\"EPSG:3857\", zorder=0)\n",
    "ax.tick_params(labelbottom=True, labelleft=True)\n",
    "ax.set_axis_on()\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "\n",
    "# Colorbar\n",
    "norm = mpl.colors.Normalize(vmin=D_min, vmax=D_max)\n",
    "sm = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label(\"Edge Demand Intensity (normalized)\")\n",
    "\n",
    "# Grid\n",
    "ax.grid(True, which='major', linestyle='--', linewidth=0.5, color='gray', alpha=0.5)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14, direction='out')\n",
    "ax.set_axisbelow(True)  \n",
    "\n",
    "plt.title(\"OD Demands for Scotland Railway Network\", fontsize=18)\n",
    "plt.xlabel(\"Longitude\", fontsize=14)\n",
    "plt.ylabel(\"Latitude\", fontsize=14)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCNF_od_systemfunc(arcs, comps_st, edges, arc_capacity, demand,max_distance, arc_distance, target_od):\n",
    "    \n",
    "    from gurobipy import Model, GRB, quicksum\n",
    "    import networkx as nx\n",
    "\n",
    "    # Construct a graph for shortest path calculations\n",
    "    G = nx.Graph()\n",
    "    for e, (i, j) in edges.items():\n",
    "        G.add_edge(i, j, weight=arc_distance.get(e, 1)) \n",
    "\n",
    "    # Create Gurobi model\n",
    "    model = Model(\"Network Flow Optimization\")\n",
    "    model.setParam('OutputFlag', 0) \n",
    "\n",
    "    # Define decision variables\n",
    "    flow = {}\n",
    "    unmet_demand = {}\n",
    "\n",
    "    for k, info in demand.items():\n",
    "        unmet_demand[k] = model.addVar(lb=0, vtype=GRB.CONTINUOUS, name=f\"unsatisfied_{k}\")\n",
    "        for i, j in arcs:\n",
    "            arc_key = next((e for e, v in edges.items() if v == (i, j) or v == (j, i)), None)\n",
    "            capacity = arc_capacity.get(arc_key, 0)\n",
    "            flow[k, i, j] = model.addVar(lb=0, ub=capacity, vtype=GRB.CONTINUOUS, name=f\"flow_{k}_{i}_{j}\")\n",
    "\n",
    "    # Objective: minimize total unmet demand\n",
    "    model.setObjective(\n",
    "        quicksum(unmet_demand[k] for k in demand),\n",
    "        GRB.MINIMIZE\n",
    "    )\n",
    "\n",
    "    nodes = set(node for edge in edges.values() for node in edge)\n",
    "\n",
    "    # Constraint 1: Flow conservation\n",
    "    for k, info in demand.items():\n",
    "        origin = info['origin']\n",
    "        destination = info['destination']\n",
    "        amount = info['amount']\n",
    "        for node in nodes: \n",
    "            inflow = quicksum(flow[k, i, j] for i, j in arcs if j == node)\n",
    "            outflow = quicksum(flow[k, i, j] for i, j in arcs if i == node)\n",
    "            if node == origin:\n",
    "                model.addConstr(outflow - inflow == amount - unmet_demand[k])\n",
    "            elif node == destination:\n",
    "                model.addConstr(outflow - inflow == - amount + unmet_demand[k])\n",
    "            else:\n",
    "                model.addConstr(outflow - inflow == 0)\n",
    "\n",
    "    # Constraint 2: Arc capacity limits\n",
    "    for i, j in arcs:\n",
    "        arc_key = next((e for e, v in edges.items() if v == (i, j) or v == (j, i)), None)\n",
    "        model.addConstr(quicksum(flow[k, i, j] for k in demand if (k, i, j) in flow) <= arc_capacity.get(arc_key, 0))\n",
    "\n",
    "    # Constraint 3: Distance constraints for each commodity\n",
    "    for k, info in demand.items():\n",
    "        origin = info['origin']\n",
    "        distance_expr = quicksum(arc_distance.get(e, 0) * flow[k, i, j] for e, (i, j) in edges.items() if (k, i, j) in flow)\n",
    "        total_flow = quicksum(flow[k, i, j] for i, j in arcs if (k, i, j) in flow and i == origin)\n",
    "        \n",
    "        model.addConstr(distance_expr <= max_distance[k] * total_flow)\n",
    "\n",
    "    model.optimize()\n",
    "    \n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        origin = demand[target_od]['origin']\n",
    "        destination = demand[target_od]['destination']\n",
    "        amount = demand[target_od]['amount']\n",
    "\n",
    "        # Sum of flow into destination\n",
    "        flow_to_dest = sum(\n",
    "            flow[target_od, i, destination].x\n",
    "            for i, j in arcs\n",
    "            if j == destination and (target_od, i, j) in flow\n",
    "        )\n",
    "\n",
    "        flow_ratio = flow_to_dest / amount if amount > 0 else 0\n",
    "        if flow_ratio > 0.9:\n",
    "            sys_st = 's'\n",
    "\n",
    "            min_comps_st = {}\n",
    "            for (k, i, j), var in flow.items():\n",
    "                if k == target_od and var.x > 0:\n",
    "                    link_name = next((e for e, v in edges.items() if v == (i, j) or v == (j, i)), None)\n",
    "                    if link_name:\n",
    "                        min_comps_st[link_name] = 1\n",
    "\n",
    "        else:\n",
    "            sys_st = 'f'\n",
    "            min_comps_st = None    \n",
    "        \n",
    "        print(f\"Used Components: {min_comps_st}\")\n",
    "\n",
    "        return flow_ratio, sys_st, min_comps_st\n",
    "    \n",
    "    else:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCNF_systemfunc(arcs, comps_st, edges, arc_capacity, demand, max_distance, arc_distance):\n",
    "    from gurobipy import Model, GRB, quicksum\n",
    "    import networkx as nx\n",
    "\n",
    "    # Create a graph for shortest path calculations\n",
    "    G = nx.Graph()\n",
    "    for e, (i, j) in edges.items():\n",
    "        G.add_edge(i, j, weight=arc_distance.get(e, 1))  # Set edge weights based on distance\n",
    "\n",
    "    # Create Gurobi optimization model\n",
    "    model = Model(\"Network Flow Optimization\")\n",
    "    model.setParam('OutputFlag', 0) \n",
    "\n",
    "    # Define variables\n",
    "    flow = {}\n",
    "    unmet_demand = {}\n",
    "\n",
    "    for k, info in demand.items():\n",
    "        unmet_demand[k] = model.addVar(lb=0, vtype=GRB.CONTINUOUS, name=f\"unsatisfied_{k}\")\n",
    "        for i, j in arcs:\n",
    "            arc_key = next((e for e, v in edges.items() if v == (i, j) or v == (j, i)), None)\n",
    "            capacity = arc_capacity.get(arc_key, 0)\n",
    "            flow[k, i, j] = model.addVar(lb=0, ub=capacity, vtype=GRB.CONTINUOUS, name=f\"flow_{k}_{i}_{j}\")\n",
    "\n",
    "    # Objective function: Minimize expected loss\n",
    "    model.setObjective(\n",
    "        quicksum(unmet_demand[k] for k in demand),\n",
    "        GRB.MINIMIZE\n",
    "    )\n",
    "\n",
    "    # Extract all nodes from edge values\n",
    "    nodes = set(node for edge in edges.values() for node in edge)\n",
    "\n",
    "    # Constraint 1: Flow conservation\n",
    "    for k, info in demand.items():\n",
    "        origin = info['origin']\n",
    "        destination = info['destination']\n",
    "        amount = info['amount']\n",
    "        for node in nodes: \n",
    "            inflow = quicksum(flow[k, i, j] for i, j in arcs if j == node)\n",
    "            outflow = quicksum(flow[k, i, j] for i, j in arcs if i == node)\n",
    "            if node == origin:\n",
    "                model.addConstr(outflow - inflow == amount - unmet_demand[k])\n",
    "            elif node == destination:\n",
    "                model.addConstr(outflow - inflow == - amount + unmet_demand[k])\n",
    "            else:\n",
    "                model.addConstr(outflow - inflow == 0)\n",
    "\n",
    "    # Constraint 2: Arc capacity limits\n",
    "    for i, j in arcs:\n",
    "        arc_key = next((e for e, v in edges.items() if v == (i, j) or v == (j, i)), None)\n",
    "        model.addConstr(quicksum(flow[k, i, j] for k in demand if (k, i, j) in flow) <= arc_capacity.get(arc_key, 0))\n",
    "\n",
    "    # Constraint 3: Commodityë³„ max_distance ì ìš©\n",
    "    for k, info in demand.items():\n",
    "        origin = info['origin']\n",
    "        distance_expr = quicksum(arc_distance.get(e, 0) * flow[k, i, j] for e, (i, j) in edges.items() if (k, i, j) in flow)\n",
    "        total_flow = quicksum(flow[k, i, j] for i, j in arcs if (k, i, j) in flow and i == origin)\n",
    "        \n",
    "        model.addConstr(distance_expr <= max_distance[k] * total_flow)\n",
    "\n",
    "    # Perform optimization\n",
    "    model.optimize()\n",
    "\n",
    "    # Process results\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        expected_loss = model.objVal\n",
    "\n",
    "        total_demand = sum(info['amount'] for info in demand.values())\n",
    "        expected_loss = max(0.0, min(expected_loss, total_demand))  # [0, total_demand] ë²”ìœ„ë¡œ ë³´ì •\n",
    "\n",
    "        if expected_loss < 127364:\n",
    "            sys_st = 's'\n",
    "\n",
    "            # We can infer an associated minimum survival rule in case of network connectivity.\n",
    "            min_comps_st = {}\n",
    "\n",
    "            # Extract used links from optimization result\n",
    "            for (k, i, j), var in flow.items():\n",
    "                if var.x > 0:  # If flow is greater than 0, the edge is used in the solution\n",
    "                    link_name = next((e for e, v in edges.items() if v == (i, j) or v == (j, i)), None)\n",
    "                    if link_name:\n",
    "                        min_comps_st[link_name] = 1  # Store as {e1: 1, e2: 1}\n",
    "\n",
    "        else:\n",
    "            sys_st = 'f'\n",
    "            min_comps_st = None  # No survival rule needed for failed state\n",
    "        \n",
    "        return expected_loss, sys_st, min_comps_st\n",
    "\n",
    "    else:\n",
    "        return None, None, None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84abab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.flow import shortest_augmenting_path\n",
    "\n",
    "def shortestpath_systemfunc(arcs, comps_st, edges, arc_capacity, demand, max_distance, arc_distance):\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    for e, (i, j) in edges.items():\n",
    "        if comps_st.get(e, 0) > 0:\n",
    "            cap = arc_capacity.get(e, 1)\n",
    "            dist = arc_distance.get(e, 1)\n",
    "            G.add_edge(i, j, capacity=cap, weight=dist, link_id=e)\n",
    "            G.add_edge(j, i, capacity=cap, weight=dist, link_id=e)\n",
    "\n",
    "    expected_loss = 0.0\n",
    "    used_links_set = set()\n",
    "\n",
    "    for k, info in demand.items():\n",
    "        origin = info[\"origin\"]\n",
    "        destination = info[\"destination\"]\n",
    "        amount = info[\"amount\"]\n",
    "        max_dist = max_distance.get(k, float('inf'))\n",
    "\n",
    "        if origin not in G.nodes or destination not in G.nodes:\n",
    "            expected_loss += amount\n",
    "            continue\n",
    "\n",
    "        G_temp = G.copy()\n",
    "        G_temp.add_edge(destination, 'sink', capacity=1)  # ê°€ìƒ ëª©ì ì§€\n",
    "\n",
    "        try:\n",
    "            flow_value, flow_dict = nx.maximum_flow(\n",
    "                G_temp, origin, 'sink', capacity='capacity', flow_func=shortest_augmenting_path\n",
    "            )\n",
    "        except Exception as e:\n",
    "            flow_value = 0\n",
    "\n",
    "        if flow_value == 0:\n",
    "            expected_loss += amount\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            path = nx.shortest_path(G, source=origin, target=destination, weight='weight')\n",
    "            path_length = nx.shortest_path_length(G, source=origin, target=destination, weight='weight')\n",
    "\n",
    "            if path_length > max_dist:\n",
    "                expected_loss += amount\n",
    "            else:\n",
    "                for u, v in zip(path[:-1], path[1:]):\n",
    "                    edge_id = G[u][v]['link_id']\n",
    "                    used_links_set.add(edge_id)\n",
    "        except nx.NetworkXNoPath:\n",
    "            expected_loss += amount\n",
    "\n",
    "    total_demand = sum(info[\"amount\"] for info in demand.values())\n",
    "    expected_loss = max(0.0, min(expected_loss, total_demand))\n",
    "\n",
    "    if expected_loss < 127364:\n",
    "        sys_st = 's'\n",
    "        min_comps_st = {e: 1 for e in used_links_set}\n",
    "    else:\n",
    "        sys_st = 'f'\n",
    "        min_comps_st = None\n",
    "\n",
    "    return expected_loss, sys_st, total_demand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_dict = {}\n",
    "\n",
    "for idx, item in enumerate(demand, start=1):\n",
    "    key = f\"k{idx}\"\n",
    "    demand_dict[key] = {\n",
    "        \"origin\": item[\"origin_name\"],\n",
    "        \"destination\": item[\"destination_name\"],\n",
    "        \"amount\": item[\"journeys\"],\n",
    "        \"distance\": item[\"distance\"]\n",
    "    }\n",
    "\n",
    "# 2. ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ì •ìƒ ìƒíƒœ\n",
    "comps_st = {edge: 1 for edge in intact_capacity}\n",
    "\n",
    "# 3. arc capacity ì„¤ì •\n",
    "arc_capacity = {edge: intact_capacity[edge] * comps_st[edge] for edge in intact_capacity}\n",
    "\n",
    "# 4. MCNF ì‹¤í–‰\n",
    "expected_loss, sys_st, total_demand = shortestpath_systemfunc(\n",
    "    arcs=arcs,\n",
    "    comps_st=comps_st,\n",
    "    edges=edges,\n",
    "    arc_capacity=arc_capacity,\n",
    "    demand=demand_dict,\n",
    "    max_distance=max_distance,\n",
    "    arc_distance=arc_distance\n",
    ")\n",
    "\n",
    "# 5. ê²°ê³¼ ì¶œë ¥\n",
    "print(\"âœ… Expected Loss:\", expected_loss)\n",
    "print(\"ðŸ“Œ System State:\", sys_st)\n",
    "print(\"ðŸ“Š Total Demand:\", total_demand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0910a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_fun_mcnf = lambda comps_st: MCNF_systemfunc(\n",
    "    arcs=arcs,\n",
    "    comps_st=comps_st,\n",
    "    edges=edges,\n",
    "    arc_capacity={e: intact_capacity[e] * comps_st[e] for e in comps_st},\n",
    "    demand=demand_dict,\n",
    "    max_distance=max_distance,\n",
    "    arc_distance=arc_distance\n",
    ")\n",
    "\n",
    "sys_fun_shortest = lambda comps_st: shortestpath_systemfunc(\n",
    "    arcs=arcs,\n",
    "    comps_st=comps_st,\n",
    "    edges=edges,\n",
    "    arc_capacity={e: intact_capacity[e] * comps_st[e] for e in comps_st},\n",
    "    demand=demand_dict,\n",
    "    max_distance=max_distance,\n",
    "    arc_distance=arc_distance\n",
    ")\n",
    "\n",
    "\n",
    "# Print input values\n",
    "print(\"\\nðŸ”¹ Input Values:\")\n",
    "print(\"Component States (comps_st):\", comps_st)\n",
    "print(\"Edges:\", edges)\n",
    "print(\"Arc Capacity:\", arc_capacity)\n",
    "print(\"Demand:\", demand_dict)\n",
    "print(\"Max Distance:\", max_distance)\n",
    "print(\"Arc Distance:\", arc_distance)\n",
    "\n",
    "# Run the function and capture outputs\n",
    "expected_loss_mcnf, sys_st_mcnf, min_comps_st_mcnf = sys_fun_mcnf(comps_st)\n",
    "expected_loss_shortest, sys_st_shortest, min_comps_st_shortest = sys_fun_shortest(comps_st)\n",
    "\n",
    "# Print output values\n",
    "print(\"\\nðŸ”¹ Output Values:\")\n",
    "print(\"System State (MCNF):\", sys_st_mcnf)\n",
    "print(\"System State (Shortest):\", sys_st_shortest)\n",
    "print(\"Minimum component state (MCNF):\", min_comps_st_mcnf) \n",
    "print(\"Minimum component state (Shortest):\", min_comps_st_shortest) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc7df3e",
   "metadata": {},
   "source": [
    "# Expected Loss Evaluation\n",
    "By BRC algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a8d7fc",
   "metadata": {},
   "source": [
    "### Shortest path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
